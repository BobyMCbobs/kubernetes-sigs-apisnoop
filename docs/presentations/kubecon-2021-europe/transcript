
hello and welcome to "contributing to kubernetes conformance coverage
i'm with ii and we are a coding cooperative in new zealand with a focus on
cooperative coding.  pairing is sharing for us and anytime two or more of us are
together cooperating on things then we're iii is there right. 

so the people of the co-op or myself and my friend
caleb who is co-hosting this talk with me and our friend zach who
down in wellington focuses on the ui and the database and
many other pieces stephen haywood does a lot of test
writing and the kleinhands brothers separated by continents during coven are
collaborating on the prowl and the project management

we're going to focus on two major components the intro and the deep dive
and in the intro we're going to ask some questions about what kubernetes
performance is and how to participate and wrap up at the end by showing
conformance submission passing.


first question you might have is what is kubernetes conformance?

great question it's good to have shared
expectations about the kubernetes api so it can behave the
same way regardless of who's hosting it for you

i know it's important to me to have my workloads run everywhere that i see the
kubernetes logo luckily we have a conformance website that walks everyone through the process
of understanding what it is that kubernetes certification provides.

and how to participate our deep dive will go a little further into that during this
intro we're going to go through the conformance repo and
create a new folder underneath one of these starting back at 1.9 through
1.19 though we only i think allow the last few releases
uh to be certified as long as they're still supported

um why is kubernetes conformance important
because vendors shouldn't matter about well clothes 

that's fair i would expect my stuff to run anywhere
regardless of vendor the cognates
conformance program kind of insures this
for us

but now that you've got these cake expectations
who might be able to meet them for you yeah oh there's about 67 or more

quite a few that's great cncf actually has a landscape where you can
go to the website and click on the certified case providers link on the
left and look at this long list of providers
that can meet your kids expectations if you're wanting to.

get on that list you might be asking well how do i certify my
kate's distribution it's a great question so
does some public instructions on this if

this is if this is you um so what you'll need is four different
files one of them being documentation on how to
make this um reproducible there'll be some product metadata and
then there'll be two types of logs that you need um why
don't we go through and get some stuff
set up

i like that i uh we have the the readme from the kind sig that submitted their
four files about seven months ago for 118 and their documentation includes how to
run it we will go ahead and change our view to include that and
walk through the steps for them so we've just created a new sono boy so we're
gonna look at the logs for that as well and the logs will allow us to probably
see that test running and we can see that set up the pod
creating the watch deleting the pods and verifying so all
those verification steps were run as part of the sonuboy test suite
and they will create some output for us

but while we're waiting for the output
maybe we could look at the um
the coup cuddle the sono boy namespace
well let's look and see what's there
in the watch you can note that there's a
sona boy pod running along with all the
normal expedited environments including oh this api snoop
that might come important later yeah remember that
subtle boy will export some results uh
including the two log files that you
will need and we'll do a quick check to make sure
that those log files do exist and they do excellent so
combining the files we need to submit our conformance results the instructions
that they provide 

and i will go ahead
and focus on the website here that shows
uploading the files and the fields that you'll need to fill in your 
product panel 
that will be part of our pr that we
upload
in order to create that pr we're going
to need to go back into
our terminal window and show our
forking of the case conformance
repository
as well as adding a remote to push our
changes to
the branch um doesn't really matter but
usually based on the name of your
product and the version because that
will be the results that we
do submit the next step is to copy those
results
into place and combine them with your
get your readme and your product yaml
and if we push those
through that will allow us to create a
branch to create a
pr 

so this is the example pr that
includes our
not kind version with some url and
information for our logo
as well as our readme that doesn't yet
include nice instructions and those two
logs
so if we click on create pull request
there's a pre-submission checklist that
you can go through that's already filled
out for case conformance
but for our demo here i'm actually going
to file this against
the cncf infrared case conformance and
go ahead and look at the pull requests
that we're creating based on that
we'll come back to this a little bit
later in the demo

but this contents of the pr
contain these four files that are part
of the documentation
and we'll visit that again after our
deep dive

thanks for that caleb our deep dive is
going to consist of
several things regarding the gaps that
we have in kubernetes conformance
coverage three main things identifying
those gaps closing those gaps
and preventing the gap so we can color
in
all of the parts that are missing
first identifying the gaps in kubernetes
coverage

is going to require filling in
our thank you for filling in our
graph here apisnoop.cncf.io
is built on top of a database that
looks at the entire surface area of the
kubernetes api and lets us see the operations that have
conformance coverage which is the darker color
and test coverage that's not yet conformant which is a lighter color
and the gray areas which have no test coverage
at all you can see that there are quite a few gaps we'd like to fill in
particularly in the green stable area
these are the areas that we focus on
as far as the gaps 

the underlying
database that we use to create that
graph
is called snoop db and it has a few
schemas that are populated from public
data sets
first of all we pull in the swagger json
that is from the kubernetes repository
usually for the branch that we're
focused on getting data for
and conformance ci jobs that we have to
configure to generate
text json file logs that are
including policies logging all the
events we're interested in
auditing the last part is some testing
schemas that will help us when we're
trying to write tests or get data in a live cluster
situation

you might be asking yourself how i can
ask and answer my own questions
deploying snoop db
it's a great question well turns out
there's actually many ways to deploy
api snoop you can use your own clusters
or if you want to do some local
testing with it and figure out the
endpoints that you care about
then you can deploy it with kind using
this configuration that we have
if you climb the api snip repo check out
the kind folder
there's a neat little configuration that
just might be for you
which would bring up apis loop and auto
logo straight away
what's great about having this local to
you is you can
ask any of the questions we're asking in
the db and modify them
to ask your own questions and get
results
without having to wait for us to come up
with a solution

the schemas that we're going to focus on
first are the audit events and the open
api
the open api is pulled from that swagger
json
that's in the kubernetes repository i
think it weighs in at around two megs
normally
but once it's loaded into the database
with all of the
indexes and extra data it weighs in at
around
five megs on the other hand the audit
event
table is pulling from probably
two to five gigs depending on how many
reposit how many
ci jobs you're pulling from but tends to
consolidate down
fairly nicely because of the the amount
09:47
of overlap in
09:48
fields we load
09:52
the swagger json directly from the
09:54
github repository for kubernetes
09:58
and this allows us to have a table based
10:01
on just the shape of the kubernetes api
10:04
to be really clear and precise about
10:07
what it is we're trying to make sure
10:09
that we cover
10:10
without having any logs this allows us
10:13
to do
10:14
as you could an example psql query
10:18
that focuses on the release
10:21
upcoming called 120 and the stable
10:24
endpoints to just
10:25
show us what's brand new and stable
10:29
in this next release let's keep an eye
10:31
on this get internal api server group
10:33
because it'll be important later in the
10:35
presentation when we have some ui
10:37
elements to show
10:40
in addition to the surface area so we
10:42
have this big gray
10:43
underlying thing we need to color in the
10:45
areas that we
10:47
are actually testing snoop db has a
10:50
second phase it goes through
10:52
instead of beyond loading just the
10:56
api definition it also loads
11:00
test deck data the
11:03
kind conformance audit job was created
11:06
this week
11:06
in order to create an audit log
11:10
you can see that the audit log that it
11:12
creates there is
11:14
brought in to our api snoop db so we can
11:17
have all of these tests and see all the
11:19
endpoints
11:20
that it hits the database table
11:23
underlying that that ingests those logs
11:27
allows us to know and query the test
11:30
whether that test was a conformance test
11:33
or not
11:34
and all of the raw json data
11:38
that is part of that audit log entry so
11:40
we have access to everything that's
11:42
available
11:43
in the kubernetes audit logs
11:46
to query and combine with the surface
11:49
area
11:52
as of this morning we were only using a
11:55
couple of jobs
11:56
to inform our
12:00
our coverage and that was the ci
12:03
kubernetes gce conformance latest
12:05
and the ede gci gce job
12:10
if you look tomorrow it'll include the
12:12
kind
12:13
job as well those are all available
12:17
publicly on crowd
12:18
so when you load up snoop db it will
12:20
retrieve them and put them into your
12:22
local instance
12:23
of snoop db
12:26
we had to create some changes
12:30
to the ede test framework and the api
12:33
server in order to have our tests
12:37
show up in these audit logs
12:41
first of all we had to ensure that the
12:43
ede framework
12:44
submitted a user agent that changed
12:47
based on
12:47
the current context of the ginkgo test
12:51
that it was
12:51
executing that allowed the user agent to
12:55
be transmitted and picked up by api
12:57
server
12:58
which previously did not include the
13:00
user agent in its logs
13:03
so our changes there enabled the user
13:05
agent to be written
13:07
all the way through so we could pick it
13:08
up in the database
13:12
the conformance tests are now available
13:14
to be queried by just
13:15
looking through the audit event table
13:17
and finding where we
13:18
have unique tests that have conformance
13:22
for example if you remember earlier we
13:25
had that
13:26
give us the new endpoint in 120 that's
13:28
stable
13:29
this is the front page of api snoop that
13:32
if you go
13:33
down to the bottom of any of the
13:35
releases that you can select from
13:37
you'll see that list of new endpoints
13:39
it's pretty
13:40
obvious that there is a new category
13:42
being brought in in 120 called
13:44
internal api server which has a slew
13:48
of alpha endpoints which will need to
13:51
eventually as they progress from alpha
13:53
to beta to stable
13:55
to reach table will need conformance
13:57
tests
13:58
but for now this allows us to have some
14:00
anticipation and communication with them
14:04
probably with whatever stick is part of
14:06
internal api server to let them know
14:08
hey we're going to need to have
14:09
conformance tests
14:11
before it's part of the public release
14:14
of kubernetes
14:17
historically we have about three years
14:20
of the conformance program it started
14:23
back in one
14:24
nine and we began to label
14:28
in text the conformance tag
14:31
for our test and we gained in quite a
14:33
few
14:34
red areas anytime you see red that's new
14:36
conformance tests
14:37
that take care of old gray debt
14:41
the orange areas are where we introduced
14:44
new endpoints and didn't include any
14:47
test
14:48
this makes it hard as it makes the whole
14:51
we're digging deeper while we're trying
14:53
to fill
14:54
fill it in so we we're lucky
14:58
in that from 115 onward we don't really
15:01
see a lot of new endpoints being
15:02
promoted without test
15:04
and we'll show a little bit later when
15:06
we're ensuring that that will
15:08
never happen again the red
15:11
is where we have written tests for old
15:14
endpoints and erase that debt
15:16
and we color in that gray area with red
15:19
and that
15:19
reduces our gaps in coverage
15:23
the last slide around identifying is
15:27
showing our current conformance debt all
15:29
the way back to 1-5
15:31
we hope to clear all of our debt back to
15:33
111 by the time we cut
15:35
120. finally we're going to go through
15:39
closing gaps in kubernetes performance
15:42
coverage and i'm going to turn that over
15:43
to caleb
15:44
yeah so we've got this flow for
15:47
uh we're going through and finding those
15:50
endpoints that
15:51
need those tests and enclosing that
15:54
that as a gap so we start off with this
15:56
query to focus on the specific untested
15:59
endpoints
16:00
here we're searching for five
16:04
stable core endpoints that are eligible
16:06
for conformance but are lacking in tests
16:09
um once we get the end point we we want
16:13
to go to the reference docs
16:14
um to understand the api endpoint and um
16:18
yeah shout out to sig docs doing great
16:20
work
16:21
we want to understand the the way that
16:24
we can talk to the resource and
16:26
all of its function handlers so we we go
16:28
to client go for that
16:30
which is uh really useful and we look in
16:32
the core v1 folder
16:34
here's an outline of the test and the
16:37
way that we'll write the test
16:38
so this is often a life cycle of the
16:41
the resource we use this quite often
16:44
because we want to hit more endpoints
16:46
this is allows discussion of the
16:49
approach of the test without needing to
16:50
write out a fully fleshed
16:52
test or even any mock test just high
16:54
level discussions for
16:55
uh the conformance sub project um
16:59
yeah and once we've gone to that point
17:01
in the same
17:02
ticket we're able to um to show an
17:04
example
17:05
um because at this point we don't want
17:07
to use the e2e test suite because we
17:09
want we want to be able to
17:11
display what we want to do as tickets to
17:13
make it really easy to discuss
17:16
so that is all before creating a pr um
17:19
and then next on um we
17:23
we run mock tests in our local clusters
17:27
and we make sure that our user agent is
17:30
set to live test writing
17:32
this allows us to see the new untested
17:35
endpoints
17:36
which we want to target in our tests and
17:39
then
17:40
following on we we
17:43
we've noticed that this test wasn't
17:45
effective enough uh creating a pod
17:47
um because pods they're already covered
17:50
in conformance so
17:52
we we don't get any changing coverage
17:54
there which is fine
17:55
so we'll look again for more endpoints
17:57
later on
17:59
now that we've got a ticket it's the
18:02
by this point you should have um
18:04
endpoints which
18:05
uh unhit and you've proven that you can
18:08
hit them and you've gotten
18:10
some code that actually does do that
18:14
now we can submit a ticket and um in
18:17
this screenshot right here
18:19
um we have a whole bunch of issues on
18:22
github that are
18:23
submitted as tickets and they're
18:24
exported as markdown
18:27
and they're all ready for review so
18:30
that that's what it looks like to um
18:34
find those uh endpoints which haven't
18:36
been heard and create a test for it
18:38
it's great to have a team focused on
18:41
filling in all of those gaps i know that
18:43
caleb myself
18:44
and steven and a few people within the
18:46
team
18:47
have been able to to write those tests
18:49
and fill it in
18:50
but the next thing we do is making sure
18:52
that our preventing new gaps from
18:54
forming
18:55
in kubernetes coverage we work a bit
18:58
with
18:58
the testing and pro infrastructure
19:01
and particularly test grid and creating
19:04
some dashboards
19:05
for the cigar performance subgroup of
19:07
sig arch
19:08
and that allows us to have proud jobs
19:12
that focus on conformance in order to
19:16
do two things our conformance
19:19
audit is the new proud job
19:23
that generates audit logs but we also
19:27
have the conformance
19:28
gate and the api snoop conformance
19:31
gate job will be sending emails to the
19:35
group of folks
19:36
interested in conformance test failures
19:39
so that we can
19:40
eventually filter this to a release
19:43
blocking conformance job so that we can
19:46
signal to the release
19:49
sig release that there is a new api
19:52
that has come through without
19:55
conformance test
19:56
we do that so that there's time to
19:58
either revert that
20:00
back into beta or ensure that the tests
20:03
are fully written in conformance before
20:06
that new api
20:07
can be part of a release to summarize
20:11
our deep dive
20:12
was all about the gaps in kubernetes
20:15
conformance coverage
20:16
where we would identify the gaps using
20:19
api snoop.cncf.io
20:22
with the underlying snoop db we were
20:25
able to
20:25
close those gaps using qmax and our in
20:29
cluster workflow that the ii team
20:31
uses and we were able to prevent
20:35
gaps by creating our release blocking
20:38
jobs so let's back out of the deep dive
20:42
for a moment
20:44
to verifying the community's conformance
20:47
submissions
20:48
um we're using a bit of proud at cncf.io
20:51
for that note that that is the cncfs
20:54
prow instance versus the kubernetes
20:56
communities instance
20:57
but this is our about our pr submission
21:00
from earlier the results get submitted
21:04
to the
21:05
cncf kate's conformance repository
21:09
and initially were reviewed by humans
21:13
and it's it's a lot of work and then we
21:15
wanted to make sure that we
21:16
validated that it was ready for just a
21:19
thumbs up approval
21:20
that was had metadata around it
21:23
and our bot that is powered by
21:27
a pro plug-in that we wrote goes through
21:30
and validates that the title
21:32
and the logs and the tests are all
21:35
following the protocols and they're all
21:37
run in this case
21:39
we have a required test missing
21:42
label and that's because in order to
21:45
speed things up
21:46
the test that we ran earlier uh for sono
21:49
boy against our
21:50
not quite kind deployment was
21:54
only for one test so obviously it didn't
21:56
pass
21:58
the communication might be please try
21:59
again and here's the directions for
22:01
running it
22:02
but fear not many other certified
22:04
distributions have been successfully
22:06
adding the label of tests
22:08
verified for the release they were
22:10
interested in which allows the cncf to
22:12
go through and approve those
22:14
merges and let you to use the certified
22:18
logo for kubernetes
22:21
that's pretty much it here's the main
22:23
links that we talked about
22:25
during this talk for the cncf certified
22:28
kubernetes repository
22:30
the api snoop website the test grid
22:35
the two repositories within the cncf for
22:38
submitting your conformance results and
22:40
the work that the
22:41
api's team does we'll open
22:45
up the q a now and caleb and i will see
22:47
you in the talk 
