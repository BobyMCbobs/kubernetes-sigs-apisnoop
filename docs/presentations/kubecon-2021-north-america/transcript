
hello and welcome to "contributing to kubernetes conformance coverage
i'm with ii and we are a coding cooperative in new zealand with a focus on
cooperative coding.  pairing is sharing for us and anytime two or more of us are
together cooperating on things then we're ii is there right.

so the people of the co-op or myself and my friend
Caleb who is co-hosting this talk with me and our friend Zach who
down in Wellington focuses on the ui and the database and
many other pieces Stephen heywood does a lot of test
writing and the Kleinhans brothers separated by continents during coven are
collaborating on the prowl and the project management

we're going to focus on two major components the intro and the deep dive
and in the intro we're going to ask some questions about what kubernetes
performance is and how to participate and wrap up at the end by showing
conformance submission passing.


first question you might have is what is kubernetes conformance?

great question it's good to have shared
expectations about the kubernetes api so it can behave the
same way regardless of who's hosting it for you

i know it's important to me to have my workloads run everywhere that i see the
kubernetes logo luckily we have a conformance website that walks everyone through the process
of understanding what it is that kubernetes certification provides.

and how to participate our deep dive will go a little further into that during this
intro we're going to go through the conformance repo and
create a new folder underneath one of these starting back at 1.9 through
1.19 though we only i think allow the last few releases
uh to be certified as long as they're still supported

um why is kubernetes conformance important
because vendors shouldn't matter about well clothes 

that's fair i would expect my stuff to run anywhere
regardless of vendor the cognates
conformance program kind of insures this
for us

but now that you've got these cake expectations
who might be able to meet them for you yeah oh there's about 67 or more

quite a few that's great cncf actually has a landscape where you can
go to the website and click on the certified case providers link on the
left and look at this long list of providers
that can meet your kids expectations if you're wanting to.

get on that list you might be asking well how do i certify my
kate's distribution it's a great question so
does some public instructions on this if

this is if this is you um so what you'll need is four different
files one of them being documentation on how to
make this um reproducible there'll be some product metadata and
then there'll be two types of logs that you need um why
don't we go through and get some stuff
set up

i like that i uh we have the the readme from the kind sig that submitted their
four files about seven months ago for 118 and their documentation includes how to
run it we will go ahead and change our view to include that and
walk through the steps for them so we've just created a new sono boy so we're
gonna look at the logs for that as well and the logs will allow us to probably
see that test running and we can see that set up the pod
creating the watch deleting the pods and verifying so all
those verification steps were run as part of the sonuboy test suite
and they will create some output for us

but while we're waiting for the output
maybe we could look at the um
the coup cuddle the sono boy namespace
well let's look and see what's there
in the watch you can note that there's a
sona boy pod running along with all the
normal expedited environments including oh this api snoop
that might come important later yeah remember that
subtle boy will export some results uh
including the two log files that you
will need and we'll do a quick check to make sure
that those log files do exist and they do excellent so
combining the files we need to submit our conformance results the instructions
that they provide 

and i will go ahead
and focus on the website here that shows
uploading the files and the fields that you'll need to fill in your 
product panel 
that will be part of our pr that we
upload
in order to create that pr we're going
to need to go back into
our terminal window and show our
forking of the case conformance
repository
as well as adding a remote to push our
changes to
the branch um doesn't really matter but
usually based on the name of your
product and the version because that
will be the results that we
do submit the next step is to copy those
results
into place and combine them with your
get your readme and your product yaml
and if we push those
through that will allow us to create a
branch to create a
pr 

so this is the example pr that
includes our
not kind version with some url and
information for our logo
as well as our readme that doesn't yet
include nice instructions and those two
logs
so if we click on create pull request
there's a pre-submission checklist that
you can go through that's already filled
out for case conformance
but for our demo here i'm actually going
to file this against
the cncf infrared case conformance and
go ahead and look at the pull requests
that we're creating based on that
we'll come back to this a little bit
later in the demo

but this contents of the pr
contain these four files that are part
of the documentation
and we'll visit that again after our
deep dive

thanks for that Caleb our deep dive is
going to consist of
several things regarding the gaps that
we have in kubernetes conformance
coverage three main things identifying
those gaps closing those gaps
and preventing the gap so we can color
in
all of the parts that are missing
first identifying the gaps in kubernetes
coverage

is going to require filling in
our thank you for filling in our
graph here apisnoop.cncf.io
is built on top of a database that
looks at the entire surface area of the
kubernetes api and lets us see the operations that have
conformance coverage which is the darker color
and test coverage that's not yet conformant which is a lighter color
and the gray areas which have no test coverage
at all you can see that there are quite a few gaps we'd like to fill in
particularly in the green stable area
these are the areas that we focus on
as far as the gaps 

the underlying
database that we use to create that
graph
is called snoop db and it has a few
schemas that are populated from public
data sets
first of all we pull in the swagger json
that is from the kubernetes repository
usually for the branch that we're
focused on getting data for
and conformance ci jobs that we have to
configure to generate
text json file logs that are
including policies logging all the
events we're interested in
auditing the last part is some testing
schemas that will help us when we're
trying to write tests or get data in a live cluster
situation

you might be asking yourself how i can
ask and answer my own questions
deploying snoop db
it's a great question well turns out
there's actually many ways to deploy
api snoop you can use your own clusters
or if you want to do some local
testing with it and figure out the
endpoints that you care about
then you can deploy it with kind using
this configuration that we have
if you climb the api snip repo check out
the kind folder
there's a neat little configuration that
just might be for you
which would bring up apis loop and auto
logo straight away
what's great about having this local to
you is you can
ask any of the questions we're asking in
the db and modify them
to ask your own questions and get
results
without having to wait for us to come up
with a solution

the schemas that we're going to focus on
first are the audit events and the open
api
the open api is pulled from that swagger
json
that's in the kubernetes repository i
think it weighs in at around two megs
normally
but once it's loaded into the database
with all of the
indexes and extra data it weighs in at
around
five MBs on the other hand the audit
event
table is pulling from probably
two to five gigs depending on how many
reposit how many
ci jobs you're pulling from but tends to
consolidate down
fairly nicely because of the the amount
of overlap in
fields we load
the swagger json directly from the
github repository for kubernetes
and this allows us to have a table based
on just the shape of the kubernetes api
to be really clear and precise about
what it is we're trying to make sure
that we cover
without having any logs this allows us
to do
as you could an example psql query
that focuses on the release
upcoming called 1.20 and the stable
endpoints to just
show us what's brand new and stable
in this next release let's keep an eye
on this get internal api server group
because it'll be important later in the
presentation when we have some ui
elements to show
in addition to the surface area so we
have this big gray
underlying thing we need to color in the
areas that we
are actually testing snoop db has a
second phase it goes through
instead of beyond loading just the
api definition it also loads
test deck data the
kind conformance audit job was created
this week
in order to create an audit log
you can see that the audit log that it
creates there is
brought in to our api snoop db so we can
have all of these tests and see all the
endpoints
that it hits the database table
underlying that that ingests those logs
allows us to know and query the test
whether that test was a conformance test
or not
and all of the raw json data
that is part of that audit log entry so
we have access to everything that's
available
in the kubernetes audit logs
to query and combine with the surface
area
as of this morning we were only using a
couple of jobs
to inform our
our coverage and that was the ci
kubernetes gce conformance latest
and the e2e gci gce job
if you look tomorrow it'll include the
kind
job as well those are all available
publicly on Prow
so when you load up snoopdb it will
retrieve them and put them into your
local instance
of snoop db
we had to create some changes
to the e2e test framework and the api
server in order to have our tests
show up in these audit logs
first of all we had to ensure that the
e2e framework
submitted a user agent that changed
based on
the current context of the ginkgo test
that it was
executing that allowed the user agent to
be transmitted and picked up by api
server
which previously did not include the
user agent in its logs
so our changes there enabled the user
agent to be written
all the way through so we could pick it
up in the database
the conformance tests are now available
to be queried by just
looking through the audit event table
and finding where we
have unique tests that have conformance
for example if you remember earlier we
had that
give us the new endpoint in 1.20 that's
stable
this is the front page of api snoop that
if you go
down to the bottom of any of the
releases that you can select from
you'll see that list of new endpoints
it's pretty
obvious that there is a new category
being brought in in 1.20 called
internal api server which has a slew
of alpha endpoints which will need to
eventually as they progress from alpha
to beta to stable
to reach table will need conformance
tests
but for now this allows us to have some
anticipation and communication with them
probably with whatever stick is part of
internal api server to let them know
hey we're going to need to have
conformance tests
before it's part of the public release
of kubernetes
historically we have about three years
of the conformance program it started
back in one
nine and we began to label
in text the conformance tag
for our test and we gained in quite a
few
red areas anytime you see red that's new
conformance tests
that take care of old gray debt
the orange areas are where we introduced
new endpoints and didn't include any
test
this makes it hard as it makes the whole
we're digging deeper while we're trying
to fill
fill it in so we we're lucky
in that from 1.15 onward we don't really
see a lot of new endpoints being
promoted without test
and we'll show a little bit later when
we're ensuring that that will
never happen again the red
is where we have written tests for old
endpoints and erase that debt
and we color in that gray area with red
and that
reduces our gaps in coverage
the last slide around identifying is
showing our current conformance debt all
the way back to 1.5
we hope to clear all of our debt back to
1.11 by the time we cut
120. finally we're going to go through
closing gaps in kubernetes performance
coverage and i'm going to turn that over
to Caleb
yeah so we've got this flow for
we're going through and finding those
endpoints that
need those tests and enclosing that
that as a gap so we start off with this
query to focus on the specific untested
endpoints
here we're searching for five
stable core endpoints that are eligible
for conformance but are lacking in tests
once we get the endpoint we we want
to go to the reference docs
to understand the api endpoint and um
yeah (shoutout to sig docs doing great
work)
we want to understand the the way that
we can talk to the resource and
all of its function handlers so we we go
to client go for that
which is really useful and we look in
the core v1 folder
here's an outline of the test and the
way that we'll write the test
so this is often a life cycle of the
the resource we use this quite often
because we want to hit more endpoints
this is allows discussion of the
approach of the test without needing to
write out a fully fleshed
test or even any mock test just high
level discussions for
uh the conformance sub project
yeah and once we've gone to that point
in the same
ticket we're able to to show an
example
because at this point we don't want
to use the e2e test suite because we
want we want to be able to
display what we want to do as tickets to
make it really easy to discuss
so that is all before creating a pr
and then next on we
we run mock tests in our local clusters
and we make sure that our user agent is
set to live test writing
this allows us to see the new untested
endpoints
which we want to target in our tests and
then
following on we we
we've noticed that this test wasn't
effective enough creating a pod
because pods they're already covered
in conformance so
we we don't get any changing coverage
there which is fine
so we'll look again for more endpoints
later on
now that we've got a ticket it's the
by this point you should have um
endpoints which
unhit and you've proven that you can
hit them and you've gotten
some code that actually does do that
now we can submit a ticket and um in
this screenshot right here
we have a whole bunch of issues on
github that are
submitted as tickets and they're
exported as markdown
and they're all ready for review so
that that's what it looks like to um
find those uh endpoints which haven't
been heard and create a test for it
it's great to have a team focused on
filling in all of those gaps i know that
Caleb myself
and Stephen and a few people within the
team
have been able to to write those tests
and fill it in
but the next thing we do is making sure
that our preventing new gaps from
forming
in kubernetes coverage we work a bit
with
the testing and Prow infrastructure
and particularly test grid and creating
some dashboards
for the sig-arch-performance subgroup of
sig-arch
and that allows us to have Prow jobs
that focus on conformance in order to
do two things our conformance
audit is the new Prow job
that generates audit logs but we also
have the conformance
gate and the APISnoop conformance
gate job will be sending emails to the
group of folks
interested in conformance test failures
so that we can
eventually filter this to a release
blocking conformance job so that we can
signal to the release
sig release that there is a new api
that has come through without
conformance test
we do that so that there's time to
either revert that
back into beta or ensure that the tests
are fully written in conformance before
that new api
can be part of a release to summarize
our deep dive
was all about the gaps in kubernetes
conformance coverage
where we would identify the gaps using
apisnoop.cncf.io
with the underlying snoopdb we were
able to
close those gaps using Humacs and our in
cluster workflow that the ii team
uses and we were able to prevent
gaps by creating our release blocking
jobs so let's back out of the deep dive
for a moment
to verifying the community's conformance
submissions
 we're using a bit of proud at cncf.io
20:51
for that note that that is the cncf's
20:54
Prow instance versus the kubernetes
community's instance
but this is our about our pr submission
from earlier the results get submitted
cncf K8s conformance repository
and initially were reviewed by humans
and it's it's a lot of work and then we
wanted to make sure that we
validated that it was ready for just a
thumbs up approval
that was had metadata around it
and our bot that is powered by
a pro plug-in that we wrote goes through
and validates that the title
and the logs and the tests are all
following the protocols and they're all
run in this case
we have a required test missing
label and that's because in order to
speed things up
the test that we ran earlier for sonoboy
against our
not quite kind deployment was
only for one test so obviously it didn't
pass
the communication might be please try
again and here's the directions for
running it
but fear not many other certified
distributions have been successfully
adding the label of tests
verified for the release they were
interested in which allows the cncf to
go through and approve those
merges and let you to use the certified
logo for kubernetes
that's pretty much it here's the main
links that we talked about
during this talk for the cncf certified
kubernetes repository
the APISnoop website the test grid
the two repositories within the cncf for
submitting your conformance results and
the work that the
api's team does we'll open
up the Q&A now and Caleb and i will see
you in the talk
