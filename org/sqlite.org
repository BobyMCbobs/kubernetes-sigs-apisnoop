#+TITLE: SQLite Raiinbows
#+AUTHOR: ii team
#+DATE: 5 September 2019
#+INCLUDE: "config.org"
#+TODO: TODO(t) NEXT(n) IN-PROGRESS(i) BLOCKED(b) | TADA(d)
#+ARCHIVE: archive/sqlite.archive.org::
#+PROPERTY: header-args:sql-mode+ :results silent :product sqlite :session raiinbow

* Purpose

Port PostgreSQL / Hasura setup to SQLite.

* Welcome, ii dev!
  :PROPERTIES:
  :header-args:sql-mode+: :results silent
  :header-args:sql-mode+: :product sqlite
  :header-args:sql-mode+: :session raiinbow
  :header-args:sqlite+: :db (concat (file-name-directory buffer-file-name) "../apps/sqlite/raiinbow.db")
  :header-args:sqlite+: :colnames yes
  :header-args:sqlite+: :results table replace
  :END:

If you're reading this org file, from within spacemacs, and expecting to do your work from within an org-file...then welcome, fellow ii dev (or honorary ii dev)!

To ensure you're set up properly, you want to run down this checklist:
** TADA [0%] Ready to Work!
    :PROPERTIES:
    :RESET_CHECK_BOXES: t
    :LOGGING: nil
    :END:
- [ ] Ensure you are reading this, and working, from within a tmate session on sharing.io.
  how do to do this is outside scope of this org, but ensure you've ssh'ed into sharing.io, and started a tmate session.

- [ ] Start up dev environment with the ii env variables
  : open a new tmate pane (ctrl+b c) or run `, ,` within the block to run the following:

  #+NAME: start docker containers
  #+BEGIN_SRC tmate :noweb eval :session apisnoop:docker
    # These  sequences are to allow you to use this as an iteration loop
    
    
    
    cd ~/ii/apisnoop/apps # docker-compose.yaml is here
    # Retangle / export code from org/documentation usually into ./apps/*
    # the eval: local vars set this emacs instance server-name to apisnoop
    emacsclient -s apisnoop -e "(org-babel-tangle-file \"../org/sqlite.org\")"
    # We have a sharing.io check to ensure everyone get's there own PORTS
    . .loadenv
  #+END_SRC

- [ ] Open to your sqlite db from within this file using sqlite3
  You'll want execute this code block by moving your cursor within and typing =,,=
  
  #+NAME: Connect org to postgres
  #+BEGIN_SRC emacs-lisp :results silent
    (sql-connect "raiinbow" (concat "*SQL: sqlite:raiinbow*"))
  #+END_SRC

- [ ] Test your connection works
  You can run this sql block, and it see a message in your minbuffer like:
  : You are connected to database "apisnoop" as user "apisnoop" on host "localhost" at port "10041".

  #+NAME: Test Connection
  #+BEGIN_SRC sqlite :results code verbatim
    .databases
    -- PRAGMA compile_options; -- FTS5 and JSON1 are default in sqlite3.9
    -- .dbinfo main
    -- .fullschema
    -- .tables
    -- select count(*) from api_swagger;
  #+END_SRC

  #+RESULTS: Test Connection
  #+begin_src sqlite
  main: /zfs/home/hh/ii/apisnoop/org/raiinbow.db
  #+end_src


- [ ] perform migrations (if not using .cli-migrations hasura image)

  #+NAME: start docker containers
  #+BEGIN_SRC tmate :noweb eval :session apisnoop:migrations
    cd ~/ii/apisnoop/apps/hasura
    hasura migrate apply
    hasura migrate status
  #+END_SRC


- [ ] Load cached audit events
  It is highly likely that a teammate has already run through a db setup, and loaded, named, and indexed their audit events. You can use their cached sql for your own db, speeding up the setup time considerably. 

  To do this, you want to:
  #+NAME: start docker containers
  #+BEGIN_SRC tmate :session apisnoop:load_events
    cd ~/ii/apisnoop/apps
    . .loadenv
    sqlite3 raiinbow.sqlite < /tmp/ci-kubernetes-e2e-gci-gce.1165794879855398916.sql
  #+END_SRC
 
  This will load audit events from bucket =ci-kubernetes-e2e-gci-gce= and job =1165794879855398916=
  If you want to use another bucket/job, check out the longer setup checklist later on.

  The process should take around 30 seconds.  It may throw errors about tables or indexes already existing, but otherwise finish successfully.  

- [ ] Test that audit events loaded.
  
  Now that we are connected to our db, we can run sql queries, like checking if the loading of cached audit events work.
  The following query should return a count of =305025=. You may need to run this twice to ensure your reconnected.
  #+NAME: Number of distinct audit events
  #+BEGIN_SRC sql-mode
  select count(distinct audit_id) from audit_event;
  #+END_SRC

  #+RESULTS: Number of distinct audit events
  #+begin_src sql-mode
   count  
  --------
   305025
  (1 row)

  #+end_src
  
  If this didn't work, check out the longer setup below.
  
- [ ] Start up a psql interpreter with the ii env variables
  It's useful to have psql up to run queries directly in the interpreter.
  : open a new tmate pane (ctrl+b c), or navigate to one used to load cached audit event

  #+NAME: start docker containers
  #+BEGIN_SRC tmate :noweb eval :session apisnoop:sqlite3
    cd ~/ii/apisnoop/apps # docker-compose.yaml is here
    . .loadenv
    sqlite3 $SQLITE_DB
    .databases
    .tables
    .dbinfo main
    .fullschema
  #+END_SRC

- [ ] Test your  hasura endpoint is up
  If all is working right, you should be able to visit =$YOURUSERNAME-hasura.sharing.io=
  You will see many views and all should have data.
  
- [ ] If cached sql not available, load audit events.
  We have a long process as [[*901: update_audit_events.up.sql][part 901: update_audit_events.up.sql]].  You can click enter on that link and then execute each code block within this heading in order.  This process will take about a half hour.

- [ ] Get a drink of water and mark this todo as DONE
  You're all set up and ready to go, but hydration is important!  Get a drink of water, stretch, and recharge before you crush it today!  
  Also, =gh gh gh= to go back to the top then =,TTd= to mark this task as DONE!

* json1
  :PROPERTIES:
  :header-args:sql-mode+: :results silent
  :header-args:sql-mode+: :product sqlite
  :header-args:sql-mode+: :session raiinbow
  :header-args:sqlite+: :db (concat (file-name-directory buffer-file-name) "../apps/sqlite/test-raiinbow.db")
  :header-args:sqlite+: :colnames yes
  :header-args:sqlite+: :results table replace
  :END:

#+BEGIN_SRC sqlite
delete from api_swagger;
#+END_SRC

#+BEGIN_SRC sqlite
select JSON_EXTRACT(data, '$.
from api_swagger, json_each(api_swagger.data, '$.paths') limit 1;
#+END_SRC

#+RESULTS:
| key                 | type   | atom |     id |
|---------------------+--------+------+--------|
| definitions         | object |      |      2 |
| info                | object |      |  28384 |
| paths               | object |      |  28390 |
| security            | array  |      | 158969 |
| securityDefinitions | object |      | 158974 |
| swagger             | text   |  2.0 | 158986 |

#+BEGIN_SRC sqlite
.table api_swagger
#+END_SRC

#+RESULTS:
| CREATE TABLE api_swagger (                      |   |
|-------------------------------------------------+---|
| version text NOT NULL                           |   |
| gitref text NOT NULL                            |   |
| ingested_at timestamp DEFAULT CURRENT_TIMESTAMP |   |
| data jsonb NOT NULL                             |   |
| );                                              |   |

** table
#+BEGIN_SRC sqlite
.dbinfo
#+END_SRC

#+RESULTS:
| database page size:  4096     |
|-------------------------------|
| write format:        1        |
| read format:         1        |
| reserved bytes:      0        |
| file change counter: 1        |
| database page count: 2        |
| freelist page count: 0        |
| schema cookie:       1        |
| schema format:       4        |
| default cache size:  0        |
| autovacuum top root: 0        |
| incremental vacuum:  0        |
| text encoding:       1 (utf8) |
| user version:        0        |
| application id:      0        |
| software version:    3022000  |
| number of tables:    1        |
| number of indexes:   0        |
| number of triggers:  0        |
| number of views:     0        |
| schema size:         158      |

** t
#+BEGIN_SRC sqlite :results scalar :colnames no
select 
#+END_SRC

#+RESULTS:
: "{""ex"":""[52,3.14159]""}"

* Raw Swaggers Table, and Helper Functions
  :PROPERTIES:
  :header-args:sql-mode+: :results silent
  :header-args:sql-mode+: :product sqlite
  :header-args:sql-mode+: :session raiinbow
  :header-args:sqlite+: :db (concat (file-name-directory buffer-file-name) "../apps/sqlite/raiinbow.db")
  :header-args:sqlite+: :colnames yes
  :header-args:sqlite+: :results table silent
  :END:
  These are jsonb indexed loads of swagger.json from github k8s commits or releases.
  Eventually these will also be populated on the fly when running within/against a cluster.
** 100: API Swagger Table
  :PROPERTIES:
  :header-args:sqlite+: :tangle ../apps/sqlite/100_table_api_swagger.up.sql
  :END:
*** Create Table
#+NAME: api_swagger
#+BEGIN_SRC sqlite
CREATE TABLE IF NOT EXISTS api_swagger (
    version text NOT NULL,
    gitref text NOT NULL,
    ingested_at timestamp DEFAULT CURRENT_TIMESTAMP,
    data jsonb NOT NULL
);
#+END_SRC
** 120: Function for load swagger via github
  :PROPERTIES:
  :header-args:python+: :tangle ../apps/sqlite/120_function_load_swagger_via_github.py
  :END:

https://docs.python.org/3/library/sqlite3.html

#+NAME: load_swagger_via_curl.py
#+BEGIN_SRC python :exports code :dir (concat (file-name-directory buffer-file-name) "../apps/sqlite") :results output
  # should probably sanitize branch_or_tag
  import sqlite3
  import requests
  def load_swagger_via_github(cursor, branch_or_tag):
      swagger_url = '/'.join([
          'https://raw.githubusercontent.com/kubernetes/kubernetes',
          branch_or_tag,
          'api/openapi-spec/swagger.json'])
      r = requests.get(swagger_url)
      if r.status_code != 200:
          raise 'hand'
      insert_query = """insert into 'api_swagger'
      (version, gitref, data)
      VALUES (?, ?, json(?))"""
      insert_tuple = ('master', branch_or_tag, r.text)
      cursor.execute(insert_query, insert_tuple)
      con.commit()

  con = sqlite3.connect('raiinbow.db')
  # con.create_function('load_swagger_for_ref',1,load_swagger_via_github)
  # con.text_factory = str
  # conn = sqlite3.connect(":memory:")
  # con.enable_load_extension(False)
  con.isolation_level = None
  c = con.cursor()
  load_swagger_via_github(c,'master')
  con.close()
#+END_SRC

#+RESULTS: load_swagger_via_curl.py


* Explore
  :PROPERTIES:
  :header-args:sql-mode+: :results silent
  :header-args:sql-mode+: :product sqlite
  :header-args:sql-mode+: :session raiinbow
  :header-args:sqlite+: :db (concat (file-name-directory buffer-file-name) "../apps/sqlite/raiinbow.db")
  :header-args:sqlite+: :colnames yes
  :header-args:sqlite+: :results table replace
  :END:

https://www.sqlite.org/json1.html#jeach

#+BEGIN_SRC sql-mode
CREATE TABLE json_tree(
    key ANY,             -- key for current element relative to its parent
    value ANY,           -- value for the current element
    type TEXT,           -- 'object','array','string','integer', etc.
    atom ANY,            -- value for primitive types, null for array & object
    id INTEGER,          -- integer ID for this element
    parent INTEGER,      -- integer ID for the parent of this element
    fullkey TEXT,        -- full path describing the current element
    path TEXT,           -- path to the container of the current row
    json JSON HIDDEN,    -- 1st input parameter: the raw JSON
    root TEXT HIDDEN     -- 2nd input parameter: the PATH at which to start
);
#+END_SRC

** top level keys
*** keys
#+NAME: top level keys
#+BEGIN_SRC sqlite
select j.key, j.type, j.atom, j.id from api_swagger, json_each(api_swagger.data) as j limit 10;
-- select j.key from api_swagger, json_tree(api_swagger.data) as j;
-- from api_swagger, json_each(api_swagger.data, '$.paths') as paths limit 1;
#+END_SRC

#+RESULTS: top level keys
| key                 | type   | atom |     id |
|---------------------+--------+------+--------|
| definitions         | object |      |      2 |
| info                | object |      |  28384 |
| paths               | object |      |  28390 |
| security            | array  |      | 158969 |
| securityDefinitions | object |      | 158974 |
| swagger             | text   |  2.0 | 158986 |

*** info - title:Kubernetes version:v1.17.0

#+NAME: info
#+BEGIN_SRC sqlite
select j.key, j.type, j.atom, j.id from api_swagger, json_each(api_swagger.data, '$.info') as j limit 10;
-- select j.key from api_swagger, json_tree(api_swagger.data) as j;
-- from api_swagger, json_each(api_swagger.data, '$.paths') as paths limit 1;
#+END_SRC

#+RESULTS: info
| key     | type | atom       |    id |
|---------+------+------------+-------|
| title   | text | Kubernetes | 28386 |
| version | text | v1.17.0    | 28388 |

*** paths

#+NAME: paths
#+BEGIN_SRC sqlite
-- select paths.key, paths.type, paths.atom, paths.value
select ops.key, ops.type, ops.atom, ops.value
from api_swagger
  , json_tree(api_swagger.data, '$.paths') as ops
limit 1;
-- select j.key from api_swagger, json_tree(api_swagger.data) as j;
-- from api_swagger, json_each(api_swagger.data, '$.paths') as paths limit 1;
#+END_SRC

#+RESULTS: paths
| key   | type   | atom |
|-------+--------+------|
| paths | object |      |


* Footnotes

# Local Variables:
# eval: (org-babel-do-load-languages (quote org-babel-load-languages) (quote ((sqlite . t))))
# End:
