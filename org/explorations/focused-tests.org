#+TITLE: Focused Tests

* Purpose
 Investigate tests based on the number of distinct endpionts they hit.  Tests that are only hitting a small proprotion of endpoints are likely written with a focus on them, instead of doing blanket hits.   From here, we can look at tests tat are not conformance, that are hitting stable/core endpoints that are _also_ not hit by any conformance test.  These would likely be good tests to investigate for promotion
* Process
** Take a look at tests and the unique endpoints they hit
   Our audit event view has all the useragents, we can reduce these down to just those that start with `e2e` to grab our tests.
   
   #+NAME: Number of tests
   #+begin_src sql-mode
     SELECT
       COUNT(DISTINCT useragent)
       FROM
           audit_event
      WHERE
        useragent LIKE 'e2e.test%'
        AND job != 'live'
        ;
   #+end_src

   #+RESULTS:
   #+begin_src sql-mode
    count 
   -------
      834
   (1 row)

   #+end_src
   
   IF we look at a sampling of this, we can see how the useragent is structured.  The test is always given after '--'.
   
   
   #+NAME: Test Sample
   #+begin_src sql-mode
     SELECT
       DISTINCT useragent
       FROM
           audit_event
      WHERE
             useragent LIKE 'e2e.test%'
         AND job != 'live'
      LIMIT 25
            ;
   #+end_src

   #+RESULTS: Test Sample
   #+begin_src sql-mode
                                                                                                                                            useragent                                                                                                                                         
   -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
    e2e.test/v1.17.0 (linux/amd64) kubernetes/7d13dfe
    e2e.test/v1.17.0 (linux/amd64) kubernetes/7d13dfe -- [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]
    e2e.test/v1.17.0 (linux/amd64) kubernetes/7d13dfe -- [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]
    e2e.test/v1.17.0 (linux/amd64) kubernetes/7d13dfe -- [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]
    e2e.test/v1.17.0 (linux/amd64) kubernetes/7d13dfe -- [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]
    e2e.test/v1.17.0 (linux/amd64) kubernetes/7d13dfe -- [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
    e2e.test/v1.17.0 (linux/amd64) kubernetes/7d13dfe -- [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
    e2e.test/v1.17.0 (linux/amd64) kubernetes/7d13dfe -- [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
    e2e.test/v1.17.0 (linux/amd64) kubernetes/7d13dfe -- [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
    e2e.test/v1.17.0 (linux/amd64) kubernetes/7d13dfe -- [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] if TerminationMessagePath is set [NodeConformance]
    e2e.test/v1.17.0 (linux/amd64) kubernetes/7d13dfe -- [k8s.io] Container Runtime blackbox test when running a container with a new image should be able to pull from private registry with secret [NodeConformance]
    e2e.test/v1.17.0 (linux/amd64) kubernetes/7d13dfe -- [k8s.io] Container Runtime blackbox test when running a container with a new image should be able to pull image [NodeConformance]
    e2e.test/v1.17.0 (linux/amd64) kubernetes/7d13dfe -- [k8s.io] Container Runtime blackbox test when running a container with a new image should not be able to pull from private registry without secret [NodeConformance]
    e2e.test/v1.17.0 (linux/amd64) kubernetes/7d13dfe -- [k8s.io] Container Runtime blackbox test when running a container with a new image should not be able to pull image from invalid registry [NodeConformance]
    e2e.test/v1.17.0 (linux/amd64) kubernetes/7d13dfe -- [k8s.io] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]
    e2e.test/v1.17.0 (linux/amd64) kubernetes/7d13dfe -- [k8s.io] Docker Containers should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
    e2e.test/v1.17.0 (linux/amd64) kubernetes/7d13dfe -- [k8s.io] Docker Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]
    e2e.test/v1.17.0 (linux/amd64) kubernetes/7d13dfe -- [k8s.io] Docker Containers should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
    e2e.test/v1.17.0 (linux/amd64) kubernetes/7d13dfe -- [k8s.io] Docker Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]
    e2e.test/v1.17.0 (linux/amd64) kubernetes/7d13dfe -- [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]
    e2e.test/v1.17.0 (linux/amd64) kubernetes/7d13dfe -- [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]
    e2e.test/v1.17.0 (linux/amd64) kubernetes/7d13dfe -- [k8s.io] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
    e2e.test/v1.17.0 (linux/amd64) kubernetes/7d13dfe -- [k8s.io] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
    e2e.test/v1.17.0 (linux/amd64) kubernetes/7d13dfe -- [k8s.io] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
    e2e.test/v1.17.0 (linux/amd64) kubernetes/7d13dfe -- [k8s.io] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]
   (25 rows)

   #+end_src
   
 This means we can split this to get just the test name
 
 
   #+NAME: Test Name Sample
   #+begin_src sql-mode
     SELECT
       DISTINCT split_part(useragent, '--', 2) as test
       FROM
           audit_event
      WHERE
             useragent LIKE 'e2e.test%'
         AND job != 'live'
      LIMIT 10
            ;
   #+end_src

   #+RESULTS: Test Name Sample
   #+begin_src sql-mode
                                                                                                                    test                                                                                                                  
   ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

     [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]
     [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]
     [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]
     [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]
     [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
     [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
     [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
     [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
     [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] if TerminationMessagePath is set [NodeConformance]
   (10 rows)

   #+end_src
   
   Sweet, we have cleanly displayed tests.  Next is to see how many endpoints these tests hit.
   
** See if there are already focused tests.
   
   For each test, I want a count of the distinct endpoints it hits.  We can do this with a postgres count filter.
   
   #+NAME: Test and Count
   #+begin_src sql-mode
     SELECT DISTINCT
       COUNT(distinct operation_id) FILTER(where useragent = audit_event.useragent) as distinct_endpoints,
       split_part(useragent, '--', 2) as test
       FROM
           audit_event
      WHERE
             useragent LIKE 'e2e.test%'
         AND job != 'live'
        GROUP BY useragent
            ORDER BY distinct_endpoints DESC
      LIMIT 25
            ;
   #+end_src

   #+RESULTS: Test and Count
   #+begin_src sql-mode
    distinct_endpoints |                                                                                          test                                                                                           
   --------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
                    60 |  [sig-api-machinery] Aggregator Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
                    58 |  [sig-network] Services should create endpoints for unready pods
                    37 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works
                    34 |  [sig-storage] CSI mock volume CSI attach test using mock driver should not require VolumeAttach for drivers without attachment
                    34 |  [sig-storage] CSI mock volume CSI attach test using mock driver should require VolumeAttach for drivers with attachment
                    34 |  [sig-storage] CSI mock volume CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on
                    34 |  [sig-storage] CSI mock volume CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on
                    34 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it
                    34 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works
                    34 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod
                    34 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it
                    34 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source
                    34 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod
                    34 |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod
                    33 |  [sig-storage] CSI mock volume CSI workload information using mock driver should be passed when podInfoOnMount=true
                    33 |  [sig-storage] CSI mock volume CSI workload information using mock driver should not be passed when podInfoOnMount=false
                    33 |  [sig-storage] CSI mock volume CSI workload information using mock driver should not be passed when podInfoOnMount=nil
                    33 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data
                    33 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted
                    33 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource
                    33 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory
                    33 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]
                    33 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]
                    33 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path
                    33 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount
   (25 rows)

   #+end_src

   #+RESULTS: Test and Count, DESC
   #+begin_src sql-mode
    distinct_endpoints |                                                                                          test                                                                                           
   --------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
                    60 |  [sig-api-machinery] Aggregator Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
                    58 |  [sig-network] Services should create endpoints for unready pods
                    37 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works
                    34 |  [sig-storage] CSI mock volume CSI attach test using mock driver should not require VolumeAttach for drivers without attachment
                    34 |  [sig-storage] CSI mock volume CSI attach test using mock driver should require VolumeAttach for drivers with attachment
                    34 |  [sig-storage] CSI mock volume CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on
                    34 |  [sig-storage] CSI mock volume CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on
                    34 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it
                    34 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works
                    34 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod
                    34 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it
                    34 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source
                    34 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod
                    34 |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod
                    33 |  [sig-storage] CSI mock volume CSI workload information using mock driver should be passed when podInfoOnMount=true
                    33 |  [sig-storage] CSI mock volume CSI workload information using mock driver should not be passed when podInfoOnMount=false
                    33 |  [sig-storage] CSI mock volume CSI workload information using mock driver should not be passed when podInfoOnMount=nil
                    33 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data
                    33 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted
                    33 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource
                    33 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory
                    33 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]
                    33 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]
                    33 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path
                    33 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount
   (25 rows)

   #+end_src

   #+RESULTS: Test and Count, ASC
   #+begin_src sql-mode
    distinct_endpoints |                                                                                                      test                                                                                                       
   --------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
                     6 |  [sig-auth] PodSecurityPolicy should forbid pod creation when no PSP is available
                     7 |  [k8s.io] Probing container should be restarted with a docker exec liveness probe with timeout 
                     7 |  [k8s.io] [sig-node] crictl should be able to run crictl on the node
                     7 |  [k8s.io] [sig-node] SSH should SSH to all nodes and run commands
                     7 |  [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]
                     7 |  [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]
                     7 |  [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]
                     7 |  [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]
                     7 |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]
                     7 |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]
                     7 |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]
                     7 |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]
                     7 |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]
                     7 |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]
                     7 |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]
                     7 |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]
                     7 |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]
                     7 |  [sig-api-machinery] Discovery Custom resource should have storage version hash
                     7 |  [sig-api-machinery] Garbage collector should support cascading deletion of custom resources
                     7 |  [sig-api-machinery] Garbage collector should support orphan deletion of custom resources
                     7 |  [sig-api-machinery] Servers with support for Table transformation should return generic metadata details across all namespaces for nodes
                     7 |  [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]
                     7 |  [sig-cli] Kubectl client Kubectl apply apply set/view last-applied
                     7 |  [sig-cli] Kubectl client Kubectl apply should reuse port when apply to an existing SVC
                     7 |  [sig-cli] Kubectl client Kubectl client-side validation should create/apply a CR with unknown fields for CRD with no validation schema
   (25 rows)

   #+end_src
   
   So this looks like the lowest # of distinct endpoints hit by a test is 6.  If we swich the order to DESC, the highest # being hit is 60.  I want to do a quick sanity check, to validate this count filter.  I'll grab two tests from the above views and list their distinct operation_id's.  The number of records should match the count.
   
   #+NAME: Test with distinct_endpoint count of 6
   #+begin_src sql-mode
     select distinct
       operation_id
       from audit_event
      where useragent like '%[sig-auth] PodSecurityPolicy should forbid pod creation when no PSP is available'
            and job != 'live'
            ;
-- records returns should be 6
   #+end_src

   #+RESULTS: Test with distinct_endpoint count of 6
   #+begin_src sql-mode
                   operation_id                 
   ---------------------------------------------
    createCoreV1Namespace
    createRbacAuthorizationV1ClusterRoleBinding
    deleteCoreV1Namespace
    listCoreV1NamespacedServiceAccount
    listCoreV1Node
    readCoreV1Namespace
   (6 rows)

   #+end_src
   
   #+NAME: Test with distinct_endpoint count of 33
   #+begin_src sql-mode
     select distinct
       operation_id
       from audit_event
      where useragent like '%[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path'
            and job != 'live'
            ;
-- records returns should be 33
   #+end_src

   #+RESULTS: Test with distinct_endpoint count of 33
   #+begin_src sql-mode
                     operation_id                  
   ------------------------------------------------
    createAppsV1NamespacedStatefulSet
    createAuthorizationV1SubjectAccessReview
    createCoreV1Namespace
    createCoreV1NamespacedPersistentVolumeClaim
    createCoreV1NamespacedPod
    createCoreV1NamespacedService
    createCoreV1NamespacedServiceAccount
    createRbacAuthorizationV1ClusterRole
    createRbacAuthorizationV1ClusterRoleBinding
    createRbacAuthorizationV1NamespacedRole
    createRbacAuthorizationV1NamespacedRoleBinding
    createStorageV1beta1CSIDriver
    createStorageV1StorageClass
    deleteAppsV1NamespacedStatefulSet
    deleteCoreV1Namespace
    deleteCoreV1NamespacedPersistentVolumeClaim
    deleteCoreV1NamespacedPod
    deleteCoreV1NamespacedService
    deleteCoreV1NamespacedServiceAccount
    deleteRbacAuthorizationV1ClusterRole
    deleteRbacAuthorizationV1ClusterRoleBinding
    deleteRbacAuthorizationV1NamespacedRole
    deleteRbacAuthorizationV1NamespacedRoleBinding
    deleteStorageV1beta1CSIDriver
    deleteStorageV1StorageClass
    listCoreV1NamespacedPod
    listCoreV1NamespacedServiceAccount
    listCoreV1Node
    readCoreV1Namespace
    readCoreV1NamespacedPersistentVolumeClaim
    readCoreV1NamespacedPod
    readCoreV1NamespacedPodLog
    readCoreV1PersistentVolume
   (33 rows)

   #+end_src

   
   The numbers match, and the logic is simple enough, that I feel confident in the approach.
** Check out Distribution of distinct endpoints
   
   I am curious  on the distribution in the tests, if there's a common number of endpoints that are hit.  I can run some quick stats using the query from above, but focused to only the stable|core endpoints.
   #+NAME: stats for tests that hit stable|core endpoints
   #+begin_src sql-mode
     select
       count(distinct test) as total_tests,
       MAX(distinct_endpoints) as max_endpoints_hit_by_test,
       MIN(distinct_endpoints) as min_endpoints_hit_by_test,
       AVG(distinct_endpoints) as avg_endpoints_hit_by_test
           FROM (
     SELECT 
       COUNT(distinct ae.operation_id) FILTER(where useragent = ae.useragent) as distinct_endpoints,
       split_part(useragent, '--', 2) as test,
       useragent
       FROM
           audit_event ae
      WHERE
         useragent LIKE 'e2e.test%'
         AND ae.job != 'live'
        GROUP BY useragent
            ORDER BY distinct_endpoints DESC
           ) as tests
            ;
   #+end_src

   #+RESULTS: stats for tests that hit stable|core endpoints
   #+begin_src sql-mode
    total_tests | max_endpoints_hit_by_test | min_endpoints_hit_by_test | avg_endpoints_hit_by_test 
   -------------+---------------------------+---------------------------+---------------------------
            834 |                        60 |                         6 |       14.1990407673860911
   (1 row)

   #+end_src

   Now i wnat to see endpoints hit by a few amount of tests
** Check out low-tested endpoints
   
   #+NAME: Low Tested Endpoints
   #+begin_src sql-mode
     SELECT
          COUNT(distinct ae.useragent) FILTER(where ae.operation_id = ae.operation_id) as distinct_tests,
            ae.operation_id
            FROM
            audit_event ae
            JOIN endpoint_coverage ec on (ae.operation_id = ec.operation_id)
            WHERE
            useragent LIKE 'e2e.test%'
            AND ae.job != 'live'
            AND ec.level = 'stable'
            GROUP BY ae.operation_id 
            ORDER BY distinct_tests DESC
            ;
   #+end_src

   #+RESULTS: Low Tested Endpoints
   #+begin_src sql-mode
    distinct_tests |                             operation_id                              
   ----------------+-----------------------------------------------------------------------
               834 | listCoreV1Node
               833 | listCoreV1NamespacedServiceAccount
               833 | deleteCoreV1Namespace
               832 | readCoreV1Namespace
               832 | createAuthorizationV1SubjectAccessReview
               832 | createCoreV1Namespace
               832 | createRbacAuthorizationV1NamespacedRoleBinding
               589 | readCoreV1NamespacedPod
               565 | createCoreV1NamespacedPod
               460 | deleteCoreV1NamespacedPod
               403 | listCoreV1NamespacedPod
               312 | readCoreV1NamespacedPodLog
               250 | deleteCoreV1NamespacedPersistentVolumeClaim
               246 | createCoreV1NamespacedPersistentVolumeClaim
               242 | readCoreV1NamespacedPersistentVolumeClaim
               221 | readCoreV1PersistentVolume
               205 | readCoreV1Node
               160 | deleteCoreV1PersistentVolume
               160 | createCoreV1PersistentVolume
               126 | deleteStorageV1StorageClass
               125 | createStorageV1StorageClass
               105 | createCoreV1NamespacedService
                76 | deleteCoreV1NamespacedService
                69 | createRbacAuthorizationV1ClusterRoleBinding
                67 | deleteRbacAuthorizationV1NamespacedRoleBinding
                65 | deleteRbacAuthorizationV1ClusterRoleBinding
                61 | createCoreV1NamespacedConfigMap
                56 | deleteAppsV1NamespacedStatefulSet
                56 | createAppsV1NamespacedStatefulSet
                50 | createCoreV1NamespacedServiceAccount
                49 | createRbacAuthorizationV1NamespacedRole
                49 | createRbacAuthorizationV1ClusterRole
                48 | deleteCoreV1NamespacedServiceAccount
                48 | deleteRbacAuthorizationV1ClusterRole
                48 | createCoreV1NamespacedSecret
                47 | deleteRbacAuthorizationV1NamespacedRole
                33 | createAppsV1NamespacedDeployment
                33 | listAppsV1NamespacedReplicaSet
                32 | readCoreV1NamespacedService
                32 | readAppsV1NamespacedDeployment
                31 | listCoreV1NamespacedEndpoints
                30 | createCoreV1NamespacedReplicationController
                30 | listRbacAuthorizationV1ClusterRole
                26 | deleteAppsV1NamespacedDeployment
                26 | deleteCoreV1NamespacedSecret
                22 | createCoreV1NamespacedEndpoints
                22 | deleteCoreV1NamespacedEndpoints
                19 | replaceCoreV1NamespacedPersistentVolumeClaim
                17 | replaceCoreV1Namespace
                17 | readCoreV1NamespacedReplicationController
                17 | readCoreV1NamespacedResourceQuota
                17 | readStorageV1StorageClass
                16 | deleteCoreV1NamespacedReplicationController
                16 | deleteCoreV1NamespacedConfigMap
                15 | createCoreV1NamespacedResourceQuota
                14 | createAppsV1NamespacedReplicaSet
                12 | replaceCoreV1NamespacedService
                12 | replaceCoreV1NamespacedConfigMap
                12 | listAppsV1NamespacedDeployment
                11 | replaceCoreV1NamespacedPod
                11 | readBatchV1NamespacedJob
                10 | listCoreV1NamespacedResourceQuota
                10 | createAppsV1NamespacedDaemonSet
                10 | deleteAppsV1NamespacedDaemonSet
                 9 | replaceAppsV1NamespacedStatefulSet
                 9 | readAppsV1NamespacedStatefulSet
                 9 | listCoreV1NamespacedPersistentVolumeClaim
                 9 | createBatchV1NamespacedJob
                 9 | createAdmissionregistrationV1ValidatingWebhookConfiguration
                 9 | listAppsV1NamespacedStatefulSet
                 9 | listCoreV1PersistentVolume
                 8 | createAdmissionregistrationV1MutatingWebhookConfiguration
                 8 | deleteAdmissionregistrationV1ValidatingWebhookConfiguration
                 8 | readCoreV1NamespacedEndpoints
                 8 | createCoreV1NamespacedPodEviction
                 7 | readCoreV1NamespacedConfigMap
                 7 | deleteAdmissionregistrationV1MutatingWebhookConfiguration
                 7 | listStorageV1StorageClass
                 6 | listCoreV1NamespacedConfigMap
                 5 | replaceAppsV1NamespacedDeployment
                 5 | getAPIVersions
                 5 | listBatchV1NamespacedJob
                 5 | listCoreV1NamespacedReplicationController
                 4 | readAppsV1NamespacedReplicaSet
                 4 | deleteBatchV1NamespacedJob
                 3 | getAdmissionregistrationV1APIResources
                 3 | readCoreV1NamespacedServiceAccount
                 3 | getApiextensionsV1APIResources
                 3 | getCoreAPIVersions
                 3 | readCoordinationV1NamespacedLease
                 2 | deleteCoreV1NamespacedResourceQuota
                 2 | replaceCoreV1NamespacedSecret
                 2 | replaceCoreV1NamespacedResourceQuota
                 2 | replaceCoreV1NamespacedReplicationController
                 2 | listCoreV1NamespacedPodTemplate
                 2 | readCoreV1NamespacedSecret
                 2 | getCoreV1APIResources
                 2 | patchCoreV1Node
                 2 | patchCoreV1NamespacedPod
                 2 | getNetworkingV1APIResources
                 2 | getCoordinationV1APIResources
                 2 | getRbacAuthorizationV1APIResources
                 2 | getSchedulingV1APIResources
                 2 | getStorageV1APIResources
                 2 | createCoreV1NamespacedPodTemplate
                 2 | getAutoscalingV1APIResources
                 2 | getAuthorizationV1APIResources
                 2 | getAuthenticationV1APIResources
                 2 | getAppsV1APIResources
                 2 | getApiregistrationV1APIResources
                 2 | getBatchV1APIResources
                 1 | replaceCoreV1NodeStatus
                 1 | createApiextensionsV1CustomResourceDefinition
                 1 | createApiregistrationV1APIService
                 1 | createAuthenticationV1TokenReview
                 1 | createAuthorizationV1SelfSubjectAccessReview
                 1 | createCoordinationV1NamespacedLease
                 1 | createCoreV1NamespacedLimitRange
                 1 | createSchedulingV1PriorityClass
                 1 | deleteAdmissionregistrationV1CollectionMutatingWebhookConfiguration
                 1 | deleteAdmissionregistrationV1CollectionValidatingWebhookConfiguration
                 1 | deleteApiextensionsV1CollectionCustomResourceDefinition
                 1 | deleteApiextensionsV1CustomResourceDefinition
                 1 | deleteApiregistrationV1APIService
                 1 | deleteAppsV1NamespacedReplicaSet
                 1 | deleteCoordinationV1CollectionNamespacedLease
                 1 | deleteCoordinationV1NamespacedLease
                 1 | deleteCoreV1NamespacedLimitRange
                 1 | deleteSchedulingV1PriorityClass
                 1 | getAdmissionregistrationAPIGroup
                 1 | getApiextensionsAPIGroup
                 1 | listAdmissionregistrationV1MutatingWebhookConfiguration
                 1 | listAdmissionregistrationV1ValidatingWebhookConfiguration
                 1 | listApiextensionsV1CustomResourceDefinition
                 1 | listAppsV1NamespacedDaemonSet
                 1 | listCoordinationV1NamespacedLease
                 1 | listCoreV1Namespace
                 1 | listCoreV1NamespacedLimitRange
                 1 | listCoreV1NamespacedSecret
                 1 | listCoreV1PodForAllNamespaces
                 1 | logFileListHandler
                 1 | patchAdmissionregistrationV1MutatingWebhookConfiguration
                 1 | patchAdmissionregistrationV1ValidatingWebhookConfiguration
                 1 | patchApiextensionsV1CustomResourceDefinition
                 1 | patchApiextensionsV1CustomResourceDefinitionStatus
                 1 | patchCoordinationV1NamespacedLease
                 1 | patchCoreV1NamespacedConfigMap
                 1 | patchCoreV1NamespacedPodStatus
                 1 | readAdmissionregistrationV1MutatingWebhookConfiguration
                 1 | readAdmissionregistrationV1ValidatingWebhookConfiguration
                 1 | readApiextensionsV1CustomResourceDefinition
                 1 | readApiextensionsV1CustomResourceDefinitionStatus
                 1 | readApiregistrationV1APIService
                 1 | readAppsV1NamespacedStatefulSetScale
                 1 | readCoreV1NamespacedLimitRange
                 1 | readCoreV1NamespacedReplicationControllerScale
                 1 | replaceAdmissionregistrationV1MutatingWebhookConfiguration
                 1 | replaceAdmissionregistrationV1ValidatingWebhookConfiguration
                 1 | replaceApiextensionsV1CustomResourceDefinition
                 1 | replaceApiextensionsV1CustomResourceDefinitionStatus
                 1 | replaceAppsV1NamespacedReplicaSet
                 1 | replaceAppsV1NamespacedStatefulSetScale
                 1 | replaceCoordinationV1NamespacedLease
                 1 | replaceCoreV1NamespacedLimitRange
                 1 | replaceCoreV1NamespacedReplicationControllerScale
                 1 | replaceCoreV1NamespacedServiceAccount
                 1 | replaceCoreV1Node
   (167 rows)

   #+end_src
   
   #+begin_src sql-mode
     SELECT
       useragent
       FROM
           audit_event
      WHERE
        operation_id = 'createApiextensionsV1CustomResourceDefinition'
        AND useragent like 'e2e.test%'
        ;
   #+end_src
** List the focused tests
   This is to create a query we can join with our list of endpoints that are hit by less than 5 (kinda arbitrary) to start to find some focused test\endpoint pariings.
   #+NAME: focused tests
   #+begin_src sql-mode
     SELECT DISTINCT
       COUNT(distinct operation_id) FILTER(where useragent = audit_event.useragent) as distinct_endpoints,
       split_part(useragent, '--', 2) as test
       FROM
           audit_event
      WHERE
              useragent LIKE 'e2e.test%'
          AND job != 'live'
         GROUP BY useragent
      ;
   #+end_src

   #+RESULTS: focused tests
   #+begin_src sql-mode
    distinct_endpoints |                                                                                                                 test                                                                                                                  
   --------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
                     6 |  [sig-auth] PodSecurityPolicy should forbid pod creation when no PSP is available
                     7 |  [k8s.io] Probing container should be restarted with a docker exec liveness probe with timeout 
                     7 |  [k8s.io] [sig-node] crictl should be able to run crictl on the node
                     7 |  [k8s.io] [sig-node] SSH should SSH to all nodes and run commands
                     7 |  [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]
                     7 |  [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]
                     7 |  [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]
                     7 |  [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]
                     7 |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]
                     7 |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]
                     7 |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]
                     7 |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]
                     7 |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]
                     7 |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]
                     7 |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]
                     7 |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]
                     7 |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]
                     7 |  [sig-api-machinery] Discovery Custom resource should have storage version hash
                     7 |  [sig-api-machinery] Garbage collector should support cascading deletion of custom resources
                     7 |  [sig-api-machinery] Garbage collector should support orphan deletion of custom resources
                     7 |  [sig-api-machinery] Servers with support for Table transformation should return generic metadata details across all namespaces for nodes
                     7 |  [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]
                     7 |  [sig-cli] Kubectl client Kubectl apply apply set/view last-applied
                     7 |  [sig-cli] Kubectl client Kubectl apply should reuse port when apply to an existing SVC
                     7 |  [sig-cli] Kubectl client Kubectl client-side validation should create/apply a CR with unknown fields for CRD with no validation schema
                     7 |  [sig-cli] Kubectl client Kubectl client-side validation should create/apply a valid CR for CRD with validation schema
                     7 |  [sig-cli] Kubectl client Kubectl client-side validation should create/apply a valid CR with arbitrary-extra properties for CRD with partially-specified validation schema
                     7 |  [sig-cli] Kubectl client Kubectl cluster-info dump should check if cluster-info dump succeeds
                     7 |  [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes master services is included in cluster-info  [Conformance]
                     7 |  [sig-cli] Kubectl client Kubectl create quota should reject quota with invalid scopes
                     7 |  [sig-cli] Kubectl client Kubectl get componentstatuses should get componentstatuses
                     7 |  [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]
                     7 |  [sig-cli] Kubectl client Proxy server should support 
                     7 |  [sig-cli] Kubectl client Proxy server should support proxy with 
                     7 |  [sig-instrumentation] MetricsGrabber should grab all metrics from API server.
                     7 |  [sig-network] [sig-windows] Networking Granular Checks: Pods should function for intra-pod communication: http
                     7 |  [sig-network] [sig-windows] Networking Granular Checks: Pods should function for intra-pod communication: udp
                     7 |  [sig-network] [sig-windows] Networking Granular Checks: Pods should function for node-pod communication: http
                     7 |  [sig-network] [sig-windows] Networking Granular Checks: Pods should function for node-pod communication: udp
                     7 |  [sig-scheduling] Multi-AZ Clusters should spread the pods of a replication controller across zones
                     7 |  [sig-scheduling] Multi-AZ Clusters should spread the pods of a service across zones
                     7 |  [sig-scheduling] Multi-AZ Cluster Volumes [sig-storage] should only be allowed to provision PDs in zones where nodes exist
                     7 |  [sig-scheduling] Multi-AZ Cluster Volumes [sig-storage] should schedule pods in the same zones as statically provisioned PVs
                     7 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options
                     7 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume
                     7 |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod
                     7 |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (block volmode)] volumes should store data
                     7 |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options
                     7 |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source
                     7 |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume
                     7 |  [sig-storage] Dynamic Provisioning Invalid AWS KMS key should report an error and create no PV
                     7 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source
                     7 |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod
                     7 |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data
                     7 |  [sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume
                     7 |  [sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume
                     7 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod
                     7 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data
                     7 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod
                     7 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data
                     7 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod
                     7 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data
                     7 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod
                     7 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data
                     7 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod
                     7 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data
                     7 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod
                     7 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data
                     7 |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod
                     7 |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (block volmode)] volumes should store data
                     7 |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source
                     7 |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod
                     7 |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data
                     7 |  [sig-storage] PersistentVolumes:vsphere should test that deleting a PVC before the pod does not cause pod deletion to fail on vsphere volume detach
                     7 |  [sig-storage] PersistentVolumes:vsphere should test that deleting the Namespace of a PVC and Pod causes the successful detach of vsphere volume
                     7 |  [sig-storage] PersistentVolumes:vsphere should test that deleting the PV before the pod does not cause pod deletion to fail on vspehre volume detach
                     7 |  [sig-storage] Pod Disks should be able to delete a non-existent PD without error
                     7 |  [sig-storage] Volume limits should verify that all nodes have volume limits
                     7 |  [sig-storage] Volume Placement should create and delete pod with multiple volumes from different datastore
                     7 |  [sig-storage] Volume Placement should create and delete pod with multiple volumes from same datastore
                     7 |  [sig-storage] Volume Placement should create and delete pod with the same volume source attach/detach to different worker nodes
                     7 |  [sig-storage] Volume Placement should create and delete pod with the same volume source on the same worker node
                     7 |  [sig-storage] Volume Placement test back to back pod creation and deletion with different volume sources on the same worker node
                     7 |  [sig-storage] vsphere statefulset vsphere statefulset testing
                     7 |  [sig-storage] Zone Support Verify a pod fails to get scheduled when conflicting volume topology (allowedTopologies) and pod scheduling constraints(nodeSelector) are specified
                     7 |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on allowed zones specified in storage class 
                     7 |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on a VSAN capability, datastore and compatible zone specified in storage class
                     7 |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on multiple zones specified in storage class 
                     7 |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on multiple zones specified in the storage class. (No shared datastores exist among both zones)
                     7 |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on the allowed zones and datastore specified in storage class
                     7 |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on the allowed zones and storage policy specified in storage class
                     7 |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on the allowed zones, datastore and storage policy specified in storage class
                     7 |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV with storage policy specified in storage class in waitForFirstConsumer binding mode
                     7 |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV with storage policy specified in storage class in waitForFirstConsumer binding mode with allowedTopologies
                     7 |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV with storage policy specified in storage class in waitForFirstConsumer binding mode with multiple allowedTopologies
                     7 |  [sig-storage] Zone Support Verify a pod is created on a non-Workspace zone and attached to a dynamically created PV, based on the allowed zones and storage policy specified in storage class
                     7 |  [sig-storage] Zone Support Verify dynamically created pv with allowed zones specified in storage class, shows the right zone information on its labels
                     7 |  [sig-storage] Zone Support Verify dynamically created pv with multiple zones specified in the storage class, shows both the zones on its labels
                     7 |  [sig-storage] Zone Support Verify PVC creation fails if no zones are specified in the storage class (No shared datastores exist among all the nodes)
                     7 |  [sig-storage] Zone Support Verify PVC creation fails if only datastore is specified in the storage class (No shared datastores exist among all the nodes)
                     7 |  [sig-storage] Zone Support Verify PVC creation fails if only storage policy is specified in the storage class (No shared datastores exist among all the nodes)
                     7 |  [sig-storage] Zone Support Verify PVC creation fails if the availability zone specified in the storage class have no shared datastores under it.
                     7 |  [sig-storage] Zone Support Verify PVC creation with an invalid VSAN capability along with a compatible zone combination specified in storage class fails
                     7 |  [sig-storage] Zone Support Verify PVC creation with compatible policy and datastore without any zones specified in the storage class fails (No shared datastores exist among all the nodes)
                     7 |  [sig-storage] Zone Support Verify PVC creation with incompatible datastore and zone combination specified in storage class fails
                     7 |  [sig-storage] Zone Support Verify PVC creation with incompatible storage policy along with compatible zone and datastore combination specified in storage class fails
                     7 |  [sig-storage] Zone Support Verify PVC creation with incompatible storagePolicy and zone combination specified in storage class fails
                     7 |  [sig-storage] Zone Support Verify PVC creation with incompatible zone along with compatible storagePolicy and datastore combination specified in storage class fails
                     7 |  [sig-storage] Zone Support Verify PVC creation with invalid zone specified in storage class fails
                     8 |  [k8s.io] NodeLease when the NodeLease feature is enabled the kubelet should create and update a lease in the kube-node-lease namespace
                     8 |  [k8s.io] Security Context When creating a container with runAsNonRoot should not run with an explicit root user ID [LinuxOnly]
                     8 |  [k8s.io] Security Context When creating a container with runAsNonRoot should not run without a specified user ID
                     8 |  [k8s.io] Sysctls [LinuxOnly] [NodeFeature:Sysctls] should not launch unsafe, but not explicitly enabled sysctls on the node
                     8 |  [k8s.io] Sysctls [LinuxOnly] [NodeFeature:Sysctls] should reject invalid sysctls
                     8 |  [sig-api-machinery] Secrets should fail to create secret due to empty secret key [Conformance]
                     8 |  [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]
                     8 |  [sig-cli] Kubectl client Kubectl apply should apply a new configuration to an existing RC
                     8 |  [sig-cli] Kubectl client Kubectl copy should copy a file from a running Pod
                     8 |  [sig-cli] Kubectl client Kubectl create quota should create a quota without scopes
                     8 |  [sig-cli] Kubectl client Kubectl create quota should create a quota with scopes
                     8 |  [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for cronjob
                     8 |  [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]
                     8 |  [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]
                     8 |  [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]
                     8 |  [sig-cli] Kubectl client Kubectl run 
                     8 |  [sig-cli] Kubectl client Kubectl run default should create an rc or deployment from an image  [Conformance]
                     8 |  [sig-cli] Kubectl client Kubectl run job should create a job from an image when restart is OnFailure  [Conformance]
                     8 |  [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]
                     8 |  [sig-cli] Kubectl client Simple pod should contain last line of the log
                     8 |  [sig-cli] Kubectl client Simple pod should support exec
                     8 |  [sig-cli] Kubectl client Simple pod should support exec through an HTTP proxy
                     8 |  [sig-cli] Kubectl client Simple pod should support exec through kubectl proxy
                     8 |  [sig-cli] Kubectl client Simple pod should support exec using resource/name
                     8 |  [sig-cli] Kubectl client Simple pod should support port-forward
                     8 |  [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]
                     8 |  [sig-cli] Kubectl client Update Demo should do a rolling update of a replication controller  [Conformance]
                     8 |  [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]
                     8 |  [sig-instrumentation] Cadvisor should be healthy on every node.
                     8 |  [sig-instrumentation] MetricsGrabber should grab all metrics from a ControllerManager.
                     8 |  [sig-instrumentation] MetricsGrabber should grab all metrics from a Kubelet.
                     8 |  [sig-instrumentation] MetricsGrabber should grab all metrics from a Scheduler.
                     8 |  [sig-network] Firewall rule should have correct firewall rules for e2e cluster
                     8 |  [sig-network] Proxy version v1 should proxy logs on node using proxy subresource  [Conformance]
                     8 |  [sig-network] Proxy version v1 should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
                     8 |  [sig-network] Services should provide secure master service  [Conformance]
                     8 |  [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]
                     8 |  [sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass
                     9 |  [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]
                     9 |  [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]
                     9 |  [k8s.io] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
                     9 |  [k8s.io] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
                     9 |  [k8s.io] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
                     9 |  [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]
                     9 |  [k8s.io] NodeLease when the NodeLease feature is enabled the kubelet should report node status infrequently
                     9 |  [k8s.io] Pods should get a host IP [NodeConformance] [Conformance]
                     9 |  [k8s.io] Pods should support remote command execution over websockets [NodeConformance] [Conformance]
                     9 |  [k8s.io] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
                     9 |  [k8s.io] PrivilegedPod [NodeConformance] should enable privileged commands [LinuxOnly]
                     9 |  [k8s.io] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
                     9 |  [k8s.io] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
                     9 |  [k8s.io] Security Context When creating a container with runAsUser should run the container with uid 0 [LinuxOnly] [NodeConformance]
                     9 |  [k8s.io] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
                     9 |  [k8s.io] Security Context When creating a pod with readOnlyRootFilesystem should run the container with readonly rootfs when readOnlyRootFilesystem=true [LinuxOnly] [NodeConformance]
                     9 |  [k8s.io] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
                     9 |  [k8s.io] [sig-node] NodeProblemDetector [DisabledForLargeClusters] should run without error
                     9 |  [k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
                     9 |  [sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls
                     9 |  [sig-api-machinery] Servers with support for Table transformation should return chunks of table results for list calls
                     9 |  [sig-api-machinery] Servers with support for Table transformation should return pod details
                     9 |  [sig-apps] DisruptionController should create a PodDisruptionBudget
                     9 |  [sig-apps] Job should fail when exceeds active deadline
                     9 |  [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
                     9 |  [sig-apps] Job should run a job to completion when tasks sometimes fail and are not locally restarted
                     9 |  [sig-auth] Metadata Concealment should run a check-metadata-concealment job to completion
                     9 |  [sig-cli] Kubectl alpha client Kubectl run CronJob should create a CronJob
                     9 |  [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]
                     9 |  [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]
                     9 |  [sig-cli] Kubectl client Kubectl rolling-update should support rolling-update to same image  [Conformance]
                     9 |  [sig-cli] Kubectl client Kubectl run CronJob should create a CronJob
                     9 |  [sig-cli] Kubectl client Kubectl run deployment should create a deployment from an image  [Conformance]
                     9 |  [sig-cli] Kubectl client Simple pod should handle in-cluster config
                     9 |  [sig-cli] Kubectl client Simple pod should return command exit codes
                     9 |  [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
                     9 |  [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
                     9 |  [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
                     9 |  [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
                     9 |  [sig-network] Services should prevent NodePort collisions
                     9 |  [sig-node] RuntimeClass should reject a Pod requesting a RuntimeClass with an unconfigured handler
                     9 |  [sig-node] RuntimeClass should reject a Pod requesting a RuntimeClass with conflicting node selector
                     9 |  [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]
                    10 |  [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
                    10 |  [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
                    10 |  [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
                    10 |  [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
                    10 |  [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] if TerminationMessagePath is set [NodeConformance]
                    10 |  [k8s.io] Container Runtime blackbox test when running a container with a new image should be able to pull image [NodeConformance]
                    10 |  [k8s.io] Container Runtime blackbox test when running a container with a new image should not be able to pull from private registry without secret [NodeConformance]
                    10 |  [k8s.io] Container Runtime blackbox test when running a container with a new image should not be able to pull image from invalid registry [NodeConformance]
                    10 |  [k8s.io] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]
                    10 |  [k8s.io] Docker Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]
                    10 |  [k8s.io] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]
                    10 |  [k8s.io] Kubelet when scheduling a busybox Pod with hostAliases should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
                    10 |  [k8s.io] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
                    10 |  [k8s.io] Pods should support pod readiness gates [NodeFeature:PodReadinessGate]
                    10 |  [k8s.io] Probing container should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
                    10 |  [k8s.io] Probing container should be restarted with a local redirect http liveness probe
                    10 |  [k8s.io] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]
                    10 |  [k8s.io] Probing container should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
                    10 |  [k8s.io] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
                    10 |  [k8s.io] Probing container should *not* be restarted with a non-local redirect http liveness probe
                    10 |  [k8s.io] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance]
                    10 |  [k8s.io] Security Context When creating a container with runAsNonRoot should run with an explicit non-root user ID [LinuxOnly]
                    10 |  [k8s.io] Security Context When creating a container with runAsNonRoot should run with an image specified user ID
                    10 |  [k8s.io] Security Context When creating a pod with privileged should run the container as privileged when true [LinuxOnly] [NodeFeature:HostAccess]
                    10 |  [k8s.io] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
                    10 |  [k8s.io] Security Context when creating containers with AllowPrivilegeEscalation should allow privilege escalation when not explicitly set and uid != 0 [LinuxOnly] [NodeConformance]
                    10 |  [k8s.io] Security Context when creating containers with AllowPrivilegeEscalation should allow privilege escalation when true [LinuxOnly] [NodeConformance]
                    10 |  [k8s.io] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
                    10 |  [k8s.io] [sig-node] Mount propagation should propagate mounts to the host
                    10 |  [k8s.io] [sig-node] PreStop should call prestop when killing a pod  [Conformance]
                    10 |  [k8s.io] Sysctls [LinuxOnly] [NodeFeature:Sysctls] should support sysctls
                    10 |  [k8s.io] Sysctls [LinuxOnly] [NodeFeature:Sysctls] should support unsafe sysctls which are actually whitelisted
                    10 |  [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]
                    10 |  [sig-api-machinery] Generated clientset should create v1beta1 cronJobs, delete cronJobs, watch cronJobs
                    10 |  [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
                    10 |  [sig-apps] DisruptionController evictions: no PDB => should allow an eviction
                    10 |  [sig-apps] Job should fail to exceed backoffLimit
                    10 |  [sig-apps] Job should run a job to completion when tasks succeed
                    10 |  [sig-apps] ReplicaSet should serve a basic image on each replica with a private image
                    10 |  [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]
                    10 |  [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]
                    10 |  [sig-apps] ReplicationController should serve a basic image on each replica with a private image
                    10 |  [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]
                    10 |  [sig-auth] Certificates API should support building a client with a CSR
                    10 |  [sig-auth] ServiceAccounts should ensure a single API token exists
                    10 |  [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]
                    10 |  [sig-cli] Kubectl client Kubectl run rc should create an rc from an image  [Conformance]
                    10 |  [sig-cli] Kubectl client Simple pod should support inline execution and attach
                    10 |  [sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 that expects a client request should support a client that connects, sends NO DATA, and disconnects
                    10 |  [sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 that expects NO client request should support a client that connects, sends DATA, and disconnects
                    10 |  [sig-cli] Kubectl Port forwarding With a server listening on localhost should support forwarding over websockets
                    10 |  [sig-cli] Kubectl Port forwarding With a server listening on localhost that expects a client request should support a client that connects, sends DATA, and disconnects
                    10 |  [sig-cli] Kubectl Port forwarding With a server listening on localhost that expects a client request should support a client that connects, sends NO DATA, and disconnects
                    10 |  [sig-cli] Kubectl Port forwarding With a server listening on localhost that expects NO client request should support a client that connects, sends DATA, and disconnects
                    10 |  [sig-network] DNS should provide DNS for the cluster [Provider:GCE]
                    10 |  [sig-network] DNS should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
                    10 |  [sig-network] DNS should resolve DNS of partial qualified names for the cluster [LinuxOnly]
                    10 |  [sig-network] DNS should support configurable pod DNS nameservers [Conformance]
                    10 |  [sig-network] DNS should support configurable pod resolv.conf
                    10 |  [sig-network] Networking should provide unchanging, static URL paths for kubernetes api services
                    10 |  [sig-network] Services should be rejected when no endpoints exist
                    10 |  [sig-node] ConfigMap should update ConfigMap successfully
                    10 |  [sig-node] RuntimeClass should run a Pod requesting a RuntimeClass with a configured handler [NodeFeature:RuntimeHandler]
                    10 |  [sig-storage] Ephemeralstorage When pod refers to non-existent ephemeral storage should allow deletion of pod with invalid volume : configmap
                    10 |  [sig-storage] Ephemeralstorage When pod refers to non-existent ephemeral storage should allow deletion of pod with invalid volume : projected
                    10 |  [sig-storage] Ephemeralstorage When pod refers to non-existent ephemeral storage should allow deletion of pod with invalid volume : secret
                    10 |  [sig-storage] Flexvolumes should be mountable when attachable
                    10 |  [sig-storage] Flexvolumes should be mountable when non-attachable
                    10 |  [sig-storage] GCP Volumes NFSv3 should be mountable for NFSv3
                    10 |  [sig-storage] GCP Volumes NFSv4 should be mountable for NFSv4
                    10 |  [sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support existing directories when readOnly specified in the volumeSource
                    10 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (delayed binding)] topology should fail to schedule a pod which has topologies that conflict with AllowedTopologies
                    10 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (immediate binding)] topology should fail to schedule a pod which has topologies that conflict with AllowedTopologies
                    10 |  [sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support existing directories when readOnly specified in the volumeSource
                    10 |  [sig-storage] PV Protection Verify "immediate" deletion of a PV that is not bound to a PVC
                    10 |  [sig-storage] Zone Support Verify a PVC creation fails when multiple zones are specified in the storage class without shared datastores among the zones in waitForFirstConsumer binding mode
                    11 |  [k8s.io] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
                    11 |  [k8s.io] Pods should be updated [NodeConformance] [Conformance]
                    11 |  [k8s.io] [sig-node] Events should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
                    11 |  [k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period should be submitted and removed [Conformance]
                    11 |  [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]
                    11 |  [sig-api-machinery] Generated clientset should create pods, set the deletionTimestamp and deletionGracePeriodSeconds of the pod
                    11 |  [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]
                    11 |  [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]
                    11 |  [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]
                    11 |  [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]
                    11 |  [sig-apps] DisruptionController should update PodDisruptionBudget status
                    11 |  [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]
                    11 |  [sig-apps] Job should delete a job [Conformance]
                    11 |  [sig-apps] Job should remove pods when job is deleted
                    11 |  [sig-apps] ReplicationController should release no longer matching pods [Conformance]
                    11 |  [sig-auth] PodSecurityPolicy should allow pods under the privileged policy.PodSecurityPolicy
                    11 |  [sig-auth] PodSecurityPolicy should enforce the restricted policy.PodSecurityPolicy
                    11 |  [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]
                    11 |  [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]
                    11 |  [sig-network] Networking Granular Checks: Services should function for client IP based session affinity: http [LinuxOnly]
                    11 |  [sig-network] Networking Granular Checks: Services should function for client IP based session affinity: udp [LinuxOnly]
                    11 |  [sig-network] Networking Granular Checks: Services should function for endpoint-Service: http
                    11 |  [sig-network] Networking Granular Checks: Services should function for endpoint-Service: udp
                    11 |  [sig-network] Networking Granular Checks: Services should function for node-Service: http
                    11 |  [sig-network] Networking Granular Checks: Services should function for node-Service: udp
                    11 |  [sig-network] Networking Granular Checks: Services should function for pod-Service: http
                    11 |  [sig-network] Networking Granular Checks: Services should function for pod-Service: udp
                    11 |  [sig-network] Networking should check kube-proxy urls
                    11 |  [sig-network] Service endpoints latency should not be very high  [Conformance]
                    11 |  [sig-network] Services should check NodePort out-of-range
                    11 |  [sig-network] Services should release NodePorts on delete
                    11 |  [sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass
                    11 |  [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]
                    11 |  [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]
                    11 |  [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]
                    11 |  [sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should be able to unmount after the subpath directory is deleted
                    11 |  [sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume
                    11 |  [sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should be able to unmount after the subpath directory is deleted
                    11 |  [sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support existing directories when readOnly specified in the volumeSource
                    11 |  [sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should be able to unmount after the subpath directory is deleted
                    11 |  [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]
                    11 |  [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]
                    12 |  [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]
                    12 |  [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]
                    12 |  [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]
                    12 |  [k8s.io] Container Runtime blackbox test when running a container with a new image should be able to pull from private registry with secret [NodeConformance]
                    12 |  [k8s.io] Docker Containers should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
                    12 |  [k8s.io] Docker Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]
                    12 |  [k8s.io] Docker Containers should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
                    12 |  [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]
                    12 |  [k8s.io] Pods should be submitted and removed [NodeConformance] [Conformance]
                    12 |  [k8s.io] [sig-node] AppArmor load AppArmor profiles can disable an AppArmor profile, using unconfined
                    12 |  [k8s.io] [sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile
                    12 |  [k8s.io] [sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly]
                    12 |  [k8s.io] [sig-node] Security Context should support container.SecurityContext.RunAsUser [LinuxOnly]
                    12 |  [k8s.io] [sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly]
                    12 |  [k8s.io] [sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser [LinuxOnly]
                    12 |  [k8s.io] [sig-node] Security Context should support pod.Spec.SecurityContext.SupplementalGroups [LinuxOnly]
                    12 |  [k8s.io] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]
                    12 |  [k8s.io] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]
                    12 |  [k8s.io] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]
                    12 |  [k8s.io] Variable Expansion should allow substituting values in a volume subpath [sig-storage]
                    12 |  [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
                    12 |  [sig-api-machinery] Garbage collector should orphan pods created by rc if deleteOptions.OrphanDependents is nil
                    12 |  [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a custom resource.
                    12 |  [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a persistent volume claim. [sig-storage]
                    12 |  [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a persistent volume claim with a storage class. [sig-storage]
                    12 |  [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]
                    12 |  [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]
                    12 |  [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]
                    12 |  [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]
                    12 |  [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]
                    12 |  [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]
                    12 |  [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
                    12 |  [sig-apps] CronJob should delete successful/failed finished jobs with limit of one job
                    12 |  [sig-apps] CronJob should not emit unexpected warnings
                    12 |  [sig-apps] CronJob should replace jobs when ReplaceConcurrent
                    12 |  [sig-apps] CronJob should schedule multiple jobs concurrently
                    12 |  [sig-apps] DisruptionController evictions: enough pods, absolute => should allow an eviction
                    12 |  [sig-apps] DisruptionController evictions: enough pods, replicaSet, percentage => should allow an eviction
                    12 |  [sig-apps] DisruptionController evictions: maxUnavailable allow single eviction, percentage => should allow an eviction
                    12 |  [sig-apps] DisruptionController evictions: maxUnavailable deny evictions, integer => should not allow an eviction
                    12 |  [sig-apps] DisruptionController evictions: too few pods, absolute => should not allow an eviction
                    12 |  [sig-apps] DisruptionController evictions: too few pods, replicaSet, percentage => should not allow an eviction
                    12 |  [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]
                    12 |  [sig-apps] ReplicaSet should surface a failure condition on a common issue like exceeded quota
                    12 |  [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]
                    12 |  [sig-network] DNS should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
                    12 |  [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]
                    12 |  [sig-network] DNS should provide DNS for services  [Conformance]
                    12 |  [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
                    12 |  [sig-network] Network should set TCP CLOSE_WAIT timeout
                    12 |  [sig-network] Services should allow pods to hairpin back to themselves through services
                    12 |  [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
                    12 |  [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
                    12 |  [sig-node] Downward API should provide host IP and pod IP as an env var if pod uses host network [LinuxOnly]
                    12 |  [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]
                    12 |  [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
                    12 |  [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]
                    12 |  [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]
                    12 |  [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]
                    12 |  [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]
                    12 |  [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]
                    12 |  [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]
                    12 |  [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
                    12 |  [sig-storage] Downward API volume should provide podname as non-root with fsgroup and defaultMode [LinuxOnly] [NodeFeature:FSGroup]
                    12 |  [sig-storage] Downward API volume should provide podname as non-root with fsgroup [LinuxOnly] [NodeFeature:FSGroup]
                    12 |  [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]
                    12 |  [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
                    12 |  [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
                    12 |  [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
                    12 |  [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
                    12 |  [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
                    12 |  [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
                    12 |  [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
                    12 |  [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
                    12 |  [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
                    12 |  [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
                    12 |  [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
                    12 |  [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
                    12 |  [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
                    12 |  [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
                    12 |  [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
                    12 |  [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
                    12 |  [sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] [NodeFeature:FSGroup] files with FSGroup ownership should support (root,0644,tmpfs)
                    12 |  [sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] [NodeFeature:FSGroup] new files should be created with FSGroup ownership when container is non-root
                    12 |  [sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] [NodeFeature:FSGroup] new files should be created with FSGroup ownership when container is root
                    12 |  [sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] [NodeFeature:FSGroup] nonexistent volume subPath should have the correct mode and owner using FSGroup
                    12 |  [sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] [NodeFeature:FSGroup] volume on default medium should have the correct mode using FSGroup
                    12 |  [sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] [NodeFeature:FSGroup] volume on tmpfs should have the correct mode using FSGroup
                    12 |  [sig-storage] GCP Volumes GlusterFS should be mountable
                    12 |  [sig-storage] HostPath should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
                    12 |  [sig-storage] HostPath should support r/w [NodeConformance]
                    12 |  [sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] volumes should store data
                    12 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Inline-volume (default fs)] volumes should store data
                    12 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Inline-volume (ext3)] volumes should store data
                    12 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Inline-volume (ext4)] volumes should store data
                    12 |  [sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] volumes should store data
                    12 |  [sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] volumes should store data
                    12 |  [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]
                    12 |  [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]
                    12 |  [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]
                    12 |  [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]
                    12 |  [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]
                    12 |  [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
                    12 |  [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
                    12 |  [sig-storage] Projected downwardAPI should provide podname as non-root with fsgroup and defaultMode [LinuxOnly] [NodeFeature:FSGroup]
                    12 |  [sig-storage] Projected downwardAPI should provide podname as non-root with fsgroup [LinuxOnly] [NodeFeature:FSGroup]
                    12 |  [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]
                    12 |  [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
                    12 |  [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
                    12 |  [sig-storage] Volumes ConfigMap should be mountable
                    13 |  [k8s.io] Pods should contain environment variables for services [NodeConformance] [Conformance]
                    13 |  [k8s.io] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
                    13 |  [sig-api-machinery] Garbage collector should delete jobs and pods created by cronjob
                    13 |  [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]
                    13 |  [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
                    13 |  [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]
                    13 |  [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
                    13 |  [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]
                    13 |  [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]
                    13 |  [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]
                    13 |  [sig-api-machinery] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]
                    13 |  [sig-api-machinery] Secrets should be consumable via the environment [NodeConformance] [Conformance]
                    13 |  [sig-apps] Deployment deployment reaping should cascade to its replica sets and pods
                    13 |  [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]
                    13 |  [sig-apps] Deployment test Deployment ReplicaSet orphaning and adoption regarding controllerRef
                    13 |  [sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it
                    13 |  [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]
                    13 |  [sig-autoscaling] DNS horizontal autoscaling [DisabledForLargeClusters] kube-dns-autoscaler should scale kube-dns pods in both nonfaulty and faulty scenarios
                    13 |  [sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 should support forwarding over websockets
                    13 |  [sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 that expects a client request should support a client that connects, sends DATA, and disconnects
                    13 |  [sig-network] DNS should provide DNS for the cluster  [Conformance]
                    13 |  [sig-network] Services should be able to create a functioning NodePort service [Conformance]
                    13 |  [sig-network] Services should serve a basic endpoint from pods  [Conformance]
                    13 |  [sig-network] Services should serve multiport endpoints from pods  [Conformance]
                    13 |  [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]
                    13 |  [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]
                    13 |  [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]
                    13 |  [sig-storage] ConfigMap should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
                    13 |  [sig-storage] ConfigMap should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeFeature:FSGroup]
                    13 |  [sig-storage] ConfigMap should be consumable from pods in volume as non-root with FSGroup [LinuxOnly] [NodeFeature:FSGroup]
                    13 |  [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]
                    13 |  [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
                    13 |  [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
                    13 |  [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
                    13 |  [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root with FSGroup [LinuxOnly] [NodeFeature:FSGroup]
                    13 |  [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
                    13 |  [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
                    13 |  [sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support existing directory
                    13 |  [sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support existing single file [LinuxOnly]
                    13 |  [sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support file as subpath [LinuxOnly]
                    13 |  [sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support non-existent path
                    13 |  [sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support readOnly directory specified in the volumeMount
                    13 |  [sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]
                    13 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Inline-volume (ext3)] volumes should allow exec of files on the volume
                    13 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Inline-volume (ext4)] volumes should allow exec of files on the volume
                    13 |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Inline-volume (default fs)] subPath should be able to unmount after the subpath directory is deleted
                    13 |  [sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support existing directory
                    13 |  [sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support existing single file [LinuxOnly]
                    13 |  [sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support file as subpath [LinuxOnly]
                    13 |  [sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support non-existent path
                    13 |  [sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support readOnly directory specified in the volumeMount
                    13 |  [sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]
                    13 |  [sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support existing directory
                    13 |  [sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support existing single file [LinuxOnly]
                    13 |  [sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support file as subpath [LinuxOnly]
                    13 |  [sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support non-existent path
                    13 |  [sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support readOnly directory specified in the volumeMount
                    13 |  [sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]
                    13 |  [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]
                    13 |  [sig-storage] Projected configMap should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
                    13 |  [sig-storage] Projected configMap should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeFeature:FSGroup]
                    13 |  [sig-storage] Projected configMap should be consumable from pods in volume as non-root with FSGroup [LinuxOnly] [NodeFeature:FSGroup]
                    13 |  [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]
                    13 |  [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
                    13 |  [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
                    13 |  [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
                    13 |  [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root with FSGroup [LinuxOnly] [NodeFeature:FSGroup]
                    13 |  [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
                    13 |  [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
                    13 |  [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]
                    13 |  [sig-storage] Projected secret should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance]
                    13 |  [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
                    13 |  [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
                    13 |  [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
                    13 |  [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
                    13 |  [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
                    13 |  [sig-storage] PV Protection Verify that PV bound to a PVC is not removed immediately
                    13 |  [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]
                    13 |  [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
                    13 |  [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
                    13 |  [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]
                    13 |  [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
                    13 |  [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
                    13 |  [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
                    13 |  [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
                    14 |  [k8s.io] Lease lease API should be available [Conformance]
                    14 |  [k8s.io] [sig-node] kubelet [k8s.io] [sig-node] Clean up pods on node kubelet should be able to delete 10 pods per node in 1m0s.
                    14 |  [sig-apps] CronJob should remove from active list jobs that have been deleted
                    14 |  [sig-apps] Deployment deployment should delete old replica sets [Conformance]
                    14 |  [sig-apps] Deployment iterative rollouts should eventually progress
                    14 |  [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]
                    14 |  [sig-network] DNS should provide DNS for ExternalName services [Conformance]
                    14 |  [sig-network] Networking Granular Checks: Services should update endpoints: http
                    14 |  [sig-network] Networking Granular Checks: Services should update endpoints: udp
                    14 |  [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied.
                    14 |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Inline-volume (default fs)] volumes should store data
                    14 |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Inline-volume (default fs)] volumes should store data
                    14 |  [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
                    14 |  [sig-storage] PVC Protection Verify "immediate" deletion of a PVC that is not in active use by a pod
                    14 |  [sig-storage] PVC Protection Verify that PVC in active use by a pod is not removed immediately
                    14 |  [sig-storage] PVC Protection Verify that scheduling of a pod that uses PVC that is being deleted fails and the pod becomes Unschedulable
                    14 |  [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
                    14 |  [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [LinuxOnly] [Conformance]
                    14 |  [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [LinuxOnly] [Conformance]
                    14 |  [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [LinuxOnly] [Conformance]
                    15 |  [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]
                    15 |  [sig-apps] Deployment deployment should support proportional scaling [Conformance]
                    15 |  [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]
                    15 |  [sig-network] Services should implement service.kubernetes.io/headless
                    15 |  [sig-network] Services should implement service.kubernetes.io/service-proxy-name
                    15 |  [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
                    15 |  [sig-storage] HostPath should support subPath [NodeConformance]
                    15 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (block volmode)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property
                    15 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (default fs)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property
                    15 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (delayed binding)] topology should provision a volume and schedule a pod with AllowedTopologies
                    15 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (immediate binding)] topology should provision a volume and schedule a pod with AllowedTopologies
                    15 |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Inline-volume (default fs)] subPath should support existing directories when readOnly specified in the volumeSource
                    15 |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Inline-volume (default fs)] subPath should support existing directory
                    15 |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Inline-volume (default fs)] subPath should support existing single file [LinuxOnly]
                    15 |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Inline-volume (default fs)] subPath should support file as subpath [LinuxOnly]
                    15 |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Inline-volume (default fs)] subPath should support non-existent path
                    15 |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Inline-volume (default fs)] subPath should support readOnly directory specified in the volumeMount
                    15 |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Inline-volume (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]
                    15 |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume
                    15 |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume
                    16 |  [sig-apps] Deployment deployment should support rollover [Conformance]
                    16 |  [sig-apps] Deployment should not disrupt a cloud load-balancer's connectivity during rollout
                    16 |  [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]
                    16 |  [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]
                    16 |  [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]
                    16 |  [sig-network] Services should be able to update service type to NodePort listening on same port number but different protocols
                    16 |  [sig-storage] Dynamic Provisioning [k8s.io] GlusterDynamicProvisioner should create and delete persistent volumes [fast]
                    16 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod
                    16 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod
                    16 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume
                    16 |  [sig-storage] PersistentVolumes GCEPD should test that deleting a PVC before the pod does not cause pod deletion to fail on PD detach
                    16 |  [sig-storage] PersistentVolumes GCEPD should test that deleting the PV before the pod does not cause pod deletion to fail on PD detach
                    16 |  [sig-storage] PersistentVolumes NFS when invoking the Recycle reclaim policy should test that a PV becomes Available and is clean after the PVC is deleted.
                    16 |  [sig-storage] PersistentVolumes NFS with multiple PVs and PVCs all in same ns should create 2 PVs and 4 PVCs: test write access
                    16 |  [sig-storage] PersistentVolumes NFS with multiple PVs and PVCs all in same ns should create 3 PVs and 3 PVCs: test write access
                    16 |  [sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test write access
                    16 |  [sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and a pre-bound PV: test write access
                    16 |  [sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and non-pre-bound PV: test write access
                    16 |  [sig-storage] PersistentVolumes NFS with Single PV - PVC pairs should create a non-pre-bound PV and PVC: test write access 
                    16 |  [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]
                    17 |  [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]
                    17 |  [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]
                    17 |  [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]
                    17 |  [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]
                    17 |  [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]
                    17 |  [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]
                    17 |  [sig-network] Services should be able to up and down services
                    17 |  [sig-network] Services should preserve source pod IP for traffic thru service cluster IP [LinuxOnly]
                    17 |  [sig-scheduling] PreemptionExecutionPath runs ReplicaSets to verify preemption running path
                    17 |  [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]
                    17 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (block volmode)] volumes should store data
                    17 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (default fs)] volumes should store data
                    17 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (ext3)] volumes should store data
                    17 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (ext4)] volumes should store data
                    17 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod
                    17 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod
                    17 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted
                    17 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod
                    17 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod
                    17 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted
                    17 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: block] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod
                    17 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted
                    17 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod
                    17 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted
                    17 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod
                    17 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted
                    17 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod
                    17 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted
                    17 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod
                    17 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted
                    17 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod
                    17 |  [sig-storage] PersistentVolumes GCEPD should test that deleting the Namespace of a PVC and Pod causes the successful detach of Persistent Disk
                    17 |  [sig-storage] PersistentVolumes-local  Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeAffinity
                    17 |  [sig-storage] PersistentVolumes-local  Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeSelector
                    17 |  [sig-storage] PersistentVolumes-local  [Volume type: blockfswithformat] Set fsGroup for local volume should set different fsGroup for second pod if first pod is deleted
                    17 |  [sig-storage] PersistentVolumes-local  [Volume type: blockfswithoutformat] Set fsGroup for local volume should set different fsGroup for second pod if first pod is deleted
                    17 |  [sig-storage] PersistentVolumes-local  [Volume type: block] Set fsGroup for local volume should set different fsGroup for second pod if first pod is deleted
                    17 |  [sig-storage] PersistentVolumes-local  [Volume type: dir-bindmounted] Set fsGroup for local volume should set different fsGroup for second pod if first pod is deleted
                    17 |  [sig-storage] PersistentVolumes-local  [Volume type: dir-link-bindmounted] Set fsGroup for local volume should set different fsGroup for second pod if first pod is deleted
                    17 |  [sig-storage] PersistentVolumes-local  [Volume type: dir-link] Set fsGroup for local volume should set different fsGroup for second pod if first pod is deleted
                    17 |  [sig-storage] PersistentVolumes-local  [Volume type: dir] Set fsGroup for local volume should set different fsGroup for second pod if first pod is deleted
                    17 |  [sig-storage] PersistentVolumes-local  [Volume type: tmpfs] Set fsGroup for local volume should set different fsGroup for second pod if first pod is deleted
                    17 |  [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [LinuxOnly] [Conformance]
                    18 |  [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]
                    18 |  [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications with PVCs
                    18 |  [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should provide basic identity
                    18 |  [sig-network] Services should have session affinity work for NodePort service [LinuxOnly]
                    18 |  [sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly]
                    18 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it
                    18 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works
                    18 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it
                    18 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works
                    18 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource
                    18 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory
                    18 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]
                    18 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]
                    18 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path
                    18 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount
                    18 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]
                    18 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume
                    18 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (ext3)] volumes should allow exec of files on the volume
                    18 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (ext4)] volumes should allow exec of files on the volume
                    18 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data
                    18 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data
                    18 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Pre-provisioned PV (ext3)] volumes should store data
                    18 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Pre-provisioned PV (ext4)] volumes should store data
                    18 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data
                    18 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data
                    18 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data
                    18 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: block] [Testpattern: Pre-provisioned PV (ext4)] volumes should store data
                    18 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data
                    18 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data
                    18 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data
                    18 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data
                    18 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data
                    18 |  [sig-storage] PersistentVolumes-local  [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1
                    18 |  [sig-storage] PersistentVolumes-local  [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1
                    18 |  [sig-storage] PersistentVolumes-local  [Volume type: blockfswithformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2
                    18 |  [sig-storage] PersistentVolumes-local  [Volume type: blockfswithformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2
                    18 |  [sig-storage] PersistentVolumes-local  [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1
                    18 |  [sig-storage] PersistentVolumes-local  [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1
                    18 |  [sig-storage] PersistentVolumes-local  [Volume type: blockfswithoutformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2
                    18 |  [sig-storage] PersistentVolumes-local  [Volume type: blockfswithoutformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2
                    18 |  [sig-storage] PersistentVolumes-local  [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and read from pod1
                    18 |  [sig-storage] PersistentVolumes-local  [Volume type: block] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2
                    18 |  [sig-storage] PersistentVolumes-local  [Volume type: block] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2
                    18 |  [sig-storage] PersistentVolumes-local  [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1
                    18 |  [sig-storage] PersistentVolumes-local  [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1
                    18 |  [sig-storage] PersistentVolumes-local  [Volume type: dir-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2
                    18 |  [sig-storage] PersistentVolumes-local  [Volume type: dir-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2
                    18 |  [sig-storage] PersistentVolumes-local  [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1
                    18 |  [sig-storage] PersistentVolumes-local  [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1
                    18 |  [sig-storage] PersistentVolumes-local  [Volume type: dir-link-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2
                    18 |  [sig-storage] PersistentVolumes-local  [Volume type: dir-link-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2
                    18 |  [sig-storage] PersistentVolumes-local  [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and read from pod1
                    18 |  [sig-storage] PersistentVolumes-local  [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and write from pod1
                    18 |  [sig-storage] PersistentVolumes-local  [Volume type: dir-link] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2
                    18 |  [sig-storage] PersistentVolumes-local  [Volume type: dir-link] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2
                    18 |  [sig-storage] PersistentVolumes-local  [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and read from pod1
                    18 |  [sig-storage] PersistentVolumes-local  [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and write from pod1
                    18 |  [sig-storage] PersistentVolumes-local  [Volume type: dir] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2
                    18 |  [sig-storage] PersistentVolumes-local  [Volume type: dir] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2
                    18 |  [sig-storage] PersistentVolumes-local  [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and read from pod1
                    18 |  [sig-storage] PersistentVolumes-local  [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and write from pod1
                    18 |  [sig-storage] PersistentVolumes-local  [Volume type: tmpfs] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2
                    18 |  [sig-storage] PersistentVolumes-local  [Volume type: tmpfs] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2
                    19 |  [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should not deadlock when a pod's predecessor fails
                    19 |  [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]
                    19 |  [sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly]
                    19 |  [sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly]
                    19 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options
                    19 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted
                    19 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume
                    19 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Pre-provisioned PV (ext3)] volumes should allow exec of files on the volume
                    19 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Pre-provisioned PV (ext4)] volumes should allow exec of files on the volume
                    19 |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted
                    19 |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: block] [Testpattern: Pre-provisioned PV (ext3)] volumes should allow exec of files on the volume
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]
                    19 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume
                    19 |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted
                    19 |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod
                    19 |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod
                    20 |  [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should adopt matching orphans and release non-matching pods
                    20 |  [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should implement legacy replacement when the update strategy is OnDelete
                    20 |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should store data
                    20 |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data
                    21 |  [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]
                    21 |  [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]
                    21 |  [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]
                    21 |  [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]
                    21 |  [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]
                    21 |  [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]
                    21 |  [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]
                    21 |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource
                    21 |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]
                    21 |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]
                    21 |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path
                    21 |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount
                    21 |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]
                    21 |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume
                    21 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: block] [Testpattern: Pre-provisioned PV (ext3)] volumes should store data
                    21 |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options
                    21 |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource
                    21 |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory
                    21 |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]
                    21 |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]
                    21 |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path
                    21 |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount
                    21 |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]
                    21 |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume
                    21 |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume
                    21 |  [sig-storage] Mounted volume expand Should verify mounted devices can be resized
                    21 |  [sig-storage] PersistentVolumes-local  [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and write from pod1
                    22 |  [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]
                    22 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: block] [Testpattern: Pre-provisioned PV (ext4)] volumes should allow exec of files on the volume
                    22 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]
                    22 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource
                    22 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path
                    23 | 
                    23 |  [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]
                    23 |  [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]
                    23 |  [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]
                    23 |  [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
                    23 |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data
                    24 |  [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]
                    24 |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory
                    25 |  [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]
                    25 |  [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]
                    26 |  [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]
                    27 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: inline ephemeral CSI volume] ephemeral should create read-only inline ephemeral volume
                    27 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: inline ephemeral CSI volume] ephemeral should create read/write inline ephemeral volume
                    27 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: inline ephemeral CSI volume] ephemeral should support multiple inline ephemeral volumes
                    27 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: inline ephemeral CSI volume] ephemeral should support two pods which share the same volume
                    28 |  [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]
                    28 |  [sig-storage] CSI mock volume CSI workload information using mock driver contain ephemeral=true when using inline volume
                    30 |  [sig-storage] CSI mock volume CSI workload information using mock driver should not be passed when CSIDriver does not exist
                    31 |  [sig-storage] CSI mock volume CSI attach test using mock driver should preserve attachment policy when no CSIDriver present
                    31 |  [sig-storage] CSI mock volume CSI online volume expansion should expand volume without restarting pod if attach=on, nodeExpansion=on
                    31 |  [sig-storage] CSI mock volume CSI Volume expansion should expand volume by restarting pod if attach=on, nodeExpansion=on
                    31 |  [sig-storage] CSI mock volume CSI Volume expansion should expand volume without restarting pod if nodeExpansion=off
                    31 |  [sig-storage] CSI mock volume CSI Volume expansion should not expand volume if resizingOnDriver=off, resizingOnSC=on
                    31 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property
                    31 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property
                    33 |  [sig-storage] CSI mock volume CSI workload information using mock driver should be passed when podInfoOnMount=true
                    33 |  [sig-storage] CSI mock volume CSI workload information using mock driver should not be passed when podInfoOnMount=false
                    33 |  [sig-storage] CSI mock volume CSI workload information using mock driver should not be passed when podInfoOnMount=nil
                    33 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data
                    33 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted
                    33 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource
                    33 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory
                    33 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]
                    33 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]
                    33 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path
                    33 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount
                    33 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]
                    33 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should store data
                    33 |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted
                    33 |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource
                    33 |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory
                    33 |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]
                    33 |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]
                    33 |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path
                    33 |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount
                    33 |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]
                    33 |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (default fs)] volumes should store data
                    34 |  [sig-storage] CSI mock volume CSI attach test using mock driver should not require VolumeAttach for drivers without attachment
                    34 |  [sig-storage] CSI mock volume CSI attach test using mock driver should require VolumeAttach for drivers with attachment
                    34 |  [sig-storage] CSI mock volume CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on
                    34 |  [sig-storage] CSI mock volume CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on
                    34 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it
                    34 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works
                    34 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod
                    34 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it
                    34 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source
                    34 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod
                    34 |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod
                    37 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works
                    58 |  [sig-network] Services should create endpoints for unready pods
                    60 |  [sig-api-machinery] Aggregator Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
   (834 rows)

   #+end_src

   
   Alright, so this view as it is now is not working.  If i list the tests and their operation_id, the distinct_endpoints is always 1.  I need to have that distinct column be static
   The issue seems to be my group by clause.  If I add operation_id to the group by it reduces the distinct_endpints down.  
   
   Here is a working query, without the group by.
   #+NAME: focused tests without group by
   #+begin_src sql-mode
     WITH tests as (
       SELECT DISTINCT
         COUNT(distinct operation_id) FILTER(where useragent = audit_event.useragent) as distinct_endpoints,
         split_part(useragent, '--', 2) as test,
         useragent
         FROM
             audit_event
        WHERE
              useragent LIKE 'e2e.test%'
          AND job != 'live'
        GROUP BY useragent
     )
     SELECT DISTINCT
       audit_event.operation_id,
       test, 
       tests.distinct_endpoints
       FROM tests
         JOIN
         audit_event on (audit_event.useragent = tests.useragent)
      WHERE distinct_endpoints < 8
       ORDER BY distinct_endpoints asc, test
            ;
   #+end_src

   #+RESULTS: focused tests without group by
   #+begin_src sql-mode
                     operation_id                  |                                                                                                       test                                                                                                       | distinct_endpoints 
   ------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------
    createCoreV1Namespace                          |  [sig-auth] PodSecurityPolicy should forbid pod creation when no PSP is available                                                                                                                                |                  6
    createRbacAuthorizationV1ClusterRoleBinding    |  [sig-auth] PodSecurityPolicy should forbid pod creation when no PSP is available                                                                                                                                |                  6
    deleteCoreV1Namespace                          |  [sig-auth] PodSecurityPolicy should forbid pod creation when no PSP is available                                                                                                                                |                  6
    listCoreV1NamespacedServiceAccount             |  [sig-auth] PodSecurityPolicy should forbid pod creation when no PSP is available                                                                                                                                |                  6
    listCoreV1Node                                 |  [sig-auth] PodSecurityPolicy should forbid pod creation when no PSP is available                                                                                                                                |                  6
    readCoreV1Namespace                            |  [sig-auth] PodSecurityPolicy should forbid pod creation when no PSP is available                                                                                                                                |                  6
    createAuthorizationV1SubjectAccessReview       |  [k8s.io] Probing container should be restarted with a docker exec liveness probe with timeout                                                                                                                   |                  7
    createCoreV1Namespace                          |  [k8s.io] Probing container should be restarted with a docker exec liveness probe with timeout                                                                                                                   |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [k8s.io] Probing container should be restarted with a docker exec liveness probe with timeout                                                                                                                   |                  7
    deleteCoreV1Namespace                          |  [k8s.io] Probing container should be restarted with a docker exec liveness probe with timeout                                                                                                                   |                  7
    listCoreV1NamespacedServiceAccount             |  [k8s.io] Probing container should be restarted with a docker exec liveness probe with timeout                                                                                                                   |                  7
    listCoreV1Node                                 |  [k8s.io] Probing container should be restarted with a docker exec liveness probe with timeout                                                                                                                   |                  7
    readCoreV1Namespace                            |  [k8s.io] Probing container should be restarted with a docker exec liveness probe with timeout                                                                                                                   |                  7
    createAuthorizationV1SubjectAccessReview       |  [k8s.io] [sig-node] crictl should be able to run crictl on the node                                                                                                                                             |                  7
    createCoreV1Namespace                          |  [k8s.io] [sig-node] crictl should be able to run crictl on the node                                                                                                                                             |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [k8s.io] [sig-node] crictl should be able to run crictl on the node                                                                                                                                             |                  7
    deleteCoreV1Namespace                          |  [k8s.io] [sig-node] crictl should be able to run crictl on the node                                                                                                                                             |                  7
    listCoreV1NamespacedServiceAccount             |  [k8s.io] [sig-node] crictl should be able to run crictl on the node                                                                                                                                             |                  7
    listCoreV1Node                                 |  [k8s.io] [sig-node] crictl should be able to run crictl on the node                                                                                                                                             |                  7
    readCoreV1Namespace                            |  [k8s.io] [sig-node] crictl should be able to run crictl on the node                                                                                                                                             |                  7
    createAuthorizationV1SubjectAccessReview       |  [k8s.io] [sig-node] SSH should SSH to all nodes and run commands                                                                                                                                                |                  7
    createCoreV1Namespace                          |  [k8s.io] [sig-node] SSH should SSH to all nodes and run commands                                                                                                                                                |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [k8s.io] [sig-node] SSH should SSH to all nodes and run commands                                                                                                                                                |                  7
    deleteCoreV1Namespace                          |  [k8s.io] [sig-node] SSH should SSH to all nodes and run commands                                                                                                                                                |                  7
    listCoreV1NamespacedServiceAccount             |  [k8s.io] [sig-node] SSH should SSH to all nodes and run commands                                                                                                                                                |                  7
    listCoreV1Node                                 |  [k8s.io] [sig-node] SSH should SSH to all nodes and run commands                                                                                                                                                |                  7
    readCoreV1Namespace                            |  [k8s.io] [sig-node] SSH should SSH to all nodes and run commands                                                                                                                                                |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]                      |                  7
    createCoreV1Namespace                          |  [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]                      |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]                      |                  7
    deleteCoreV1Namespace                          |  [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]                      |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]                      |                  7
    listCoreV1Node                                 |  [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]                      |                  7
    readCoreV1Namespace                            |  [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]                      |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]  |                  7
    createCoreV1Namespace                          |  [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]  |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]  |                  7
    deleteCoreV1Namespace                          |  [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]  |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]  |                  7
    listCoreV1Node                                 |  [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]  |                  7
    readCoreV1Namespace                            |  [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]  |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]                                |                  7
    createCoreV1Namespace                          |  [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]                                |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]                                |                  7
    deleteCoreV1Namespace                          |  [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]                                |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]                                |                  7
    listCoreV1Node                                 |  [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]                                |                  7
    readCoreV1Namespace                            |  [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]                                |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]                                           |                  7
    createCoreV1Namespace                          |  [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]                                           |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]                                           |                  7
    deleteCoreV1Namespace                          |  [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]                                           |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]                                           |                  7
    listCoreV1Node                                 |  [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]                                           |                  7
    readCoreV1Namespace                            |  [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]                                           |                  7
                                                   |  [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]                                           |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]                                            |                  7
    createCoreV1Namespace                          |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]                                            |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]                                            |                  7
    deleteCoreV1Namespace                          |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]                                            |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]                                            |                  7
    listCoreV1Node                                 |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]                                            |                  7
    readCoreV1Namespace                            |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]                                            |                  7
                                                   |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]                                            |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]                                                               |                  7
    createCoreV1Namespace                          |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]                                                               |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]                                                               |                  7
    deleteCoreV1Namespace                          |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]                                                               |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]                                                               |                  7
    listCoreV1Node                                 |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]                                                               |                  7
    readCoreV1Namespace                            |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]                                                               |                  7
                                                   |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]                                                               |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]                                                             |                  7
    createCoreV1Namespace                          |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]                                                             |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]                                                             |                  7
    deleteCoreV1Namespace                          |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]                                                             |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]                                                             |                  7
    listCoreV1Node                                 |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]                                                             |                  7
    readCoreV1Namespace                            |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]                                                             |                  7
                                                   |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]                                                             |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]                                                          |                  7
    createCoreV1Namespace                          |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]                                                          |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]                                                          |                  7
    deleteCoreV1Namespace                          |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]                                                          |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]                                                          |                  7
    listCoreV1Node                                 |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]                                                          |                  7
    readCoreV1Namespace                            |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]                                                          |                  7
                                                   |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]                                                          |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]                                                                                |                  7
    createCoreV1Namespace                          |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]                                                                                |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]                                                                                |                  7
    deleteCoreV1Namespace                          |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]                                                                                |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]                                                                                |                  7
    listCoreV1Node                                 |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]                                                                                |                  7
    readCoreV1Namespace                            |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]                                                                                |                  7
                                                   |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]                                                                                |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]                                                                                   |                  7
    createCoreV1Namespace                          |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]                                                                                   |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]                                                                                   |                  7
    deleteCoreV1Namespace                          |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]                                                                                   |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]                                                                                   |                  7
    listCoreV1Node                                 |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]                                                                                   |                  7
    readCoreV1Namespace                            |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]                                                                                   |                  7
                                                   |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]                                                                                   |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]                                                                            |                  7
    createCoreV1Namespace                          |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]                                                                            |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]                                                                            |                  7
    deleteCoreV1Namespace                          |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]                                                                            |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]                                                                            |                  7
    listCoreV1Node                                 |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]                                                                            |                  7
    readCoreV1Namespace                            |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]                                                                            |                  7
                                                   |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]                                                                            |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]                                                  |                  7
    createCoreV1Namespace                          |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]                                                  |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]                                                  |                  7
    deleteCoreV1Namespace                          |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]                                                  |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]                                                  |                  7
    listCoreV1Node                                 |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]                                                  |                  7
    readCoreV1Namespace                            |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]                                                  |                  7
                                                   |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]                                                  |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]                                                           |                  7
    createCoreV1Namespace                          |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]                                                           |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]                                                           |                  7
    deleteCoreV1Namespace                          |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]                                                           |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]                                                           |                  7
    listCoreV1Node                                 |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]                                                           |                  7
    readCoreV1Namespace                            |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]                                                           |                  7
                                                   |  [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]                                                           |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-api-machinery] Discovery Custom resource should have storage version hash                                                                                                                                  |                  7
    createCoreV1Namespace                          |  [sig-api-machinery] Discovery Custom resource should have storage version hash                                                                                                                                  |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-api-machinery] Discovery Custom resource should have storage version hash                                                                                                                                  |                  7
    deleteCoreV1Namespace                          |  [sig-api-machinery] Discovery Custom resource should have storage version hash                                                                                                                                  |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-api-machinery] Discovery Custom resource should have storage version hash                                                                                                                                  |                  7
    listCoreV1Node                                 |  [sig-api-machinery] Discovery Custom resource should have storage version hash                                                                                                                                  |                  7
    readCoreV1Namespace                            |  [sig-api-machinery] Discovery Custom resource should have storage version hash                                                                                                                                  |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-api-machinery] Garbage collector should support cascading deletion of custom resources                                                                                                                     |                  7
    createCoreV1Namespace                          |  [sig-api-machinery] Garbage collector should support cascading deletion of custom resources                                                                                                                     |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-api-machinery] Garbage collector should support cascading deletion of custom resources                                                                                                                     |                  7
    deleteCoreV1Namespace                          |  [sig-api-machinery] Garbage collector should support cascading deletion of custom resources                                                                                                                     |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-api-machinery] Garbage collector should support cascading deletion of custom resources                                                                                                                     |                  7
    listCoreV1Node                                 |  [sig-api-machinery] Garbage collector should support cascading deletion of custom resources                                                                                                                     |                  7
    readCoreV1Namespace                            |  [sig-api-machinery] Garbage collector should support cascading deletion of custom resources                                                                                                                     |                  7
                                                   |  [sig-api-machinery] Garbage collector should support cascading deletion of custom resources                                                                                                                     |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-api-machinery] Garbage collector should support orphan deletion of custom resources                                                                                                                        |                  7
    createCoreV1Namespace                          |  [sig-api-machinery] Garbage collector should support orphan deletion of custom resources                                                                                                                        |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-api-machinery] Garbage collector should support orphan deletion of custom resources                                                                                                                        |                  7
    deleteCoreV1Namespace                          |  [sig-api-machinery] Garbage collector should support orphan deletion of custom resources                                                                                                                        |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-api-machinery] Garbage collector should support orphan deletion of custom resources                                                                                                                        |                  7
    listCoreV1Node                                 |  [sig-api-machinery] Garbage collector should support orphan deletion of custom resources                                                                                                                        |                  7
    readCoreV1Namespace                            |  [sig-api-machinery] Garbage collector should support orphan deletion of custom resources                                                                                                                        |                  7
                                                   |  [sig-api-machinery] Garbage collector should support orphan deletion of custom resources                                                                                                                        |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-api-machinery] Servers with support for Table transformation should return generic metadata details across all namespaces for nodes                                                                        |                  7
    createCoreV1Namespace                          |  [sig-api-machinery] Servers with support for Table transformation should return generic metadata details across all namespaces for nodes                                                                        |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-api-machinery] Servers with support for Table transformation should return generic metadata details across all namespaces for nodes                                                                        |                  7
    deleteCoreV1Namespace                          |  [sig-api-machinery] Servers with support for Table transformation should return generic metadata details across all namespaces for nodes                                                                        |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-api-machinery] Servers with support for Table transformation should return generic metadata details across all namespaces for nodes                                                                        |                  7
    listCoreV1Node                                 |  [sig-api-machinery] Servers with support for Table transformation should return generic metadata details across all namespaces for nodes                                                                        |                  7
    readCoreV1Namespace                            |  [sig-api-machinery] Servers with support for Table transformation should return generic metadata details across all namespaces for nodes                                                                        |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]                                                                                                    |                  7
    createCoreV1Namespace                          |  [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]                                                                                                    |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]                                                                                                    |                  7
    deleteCoreV1Namespace                          |  [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]                                                                                                    |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]                                                                                                    |                  7
    listCoreV1Node                                 |  [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]                                                                                                    |                  7
    readCoreV1Namespace                            |  [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]                                                                                                    |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-cli] Kubectl client Kubectl apply apply set/view last-applied                                                                                                                                              |                  7
    createCoreV1Namespace                          |  [sig-cli] Kubectl client Kubectl apply apply set/view last-applied                                                                                                                                              |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-cli] Kubectl client Kubectl apply apply set/view last-applied                                                                                                                                              |                  7
    deleteCoreV1Namespace                          |  [sig-cli] Kubectl client Kubectl apply apply set/view last-applied                                                                                                                                              |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-cli] Kubectl client Kubectl apply apply set/view last-applied                                                                                                                                              |                  7
    listCoreV1Node                                 |  [sig-cli] Kubectl client Kubectl apply apply set/view last-applied                                                                                                                                              |                  7
    readCoreV1Namespace                            |  [sig-cli] Kubectl client Kubectl apply apply set/view last-applied                                                                                                                                              |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-cli] Kubectl client Kubectl apply should reuse port when apply to an existing SVC                                                                                                                          |                  7
    createCoreV1Namespace                          |  [sig-cli] Kubectl client Kubectl apply should reuse port when apply to an existing SVC                                                                                                                          |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-cli] Kubectl client Kubectl apply should reuse port when apply to an existing SVC                                                                                                                          |                  7
    deleteCoreV1Namespace                          |  [sig-cli] Kubectl client Kubectl apply should reuse port when apply to an existing SVC                                                                                                                          |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-cli] Kubectl client Kubectl apply should reuse port when apply to an existing SVC                                                                                                                          |                  7
    listCoreV1Node                                 |  [sig-cli] Kubectl client Kubectl apply should reuse port when apply to an existing SVC                                                                                                                          |                  7
    readCoreV1Namespace                            |  [sig-cli] Kubectl client Kubectl apply should reuse port when apply to an existing SVC                                                                                                                          |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-cli] Kubectl client Kubectl client-side validation should create/apply a CR with unknown fields for CRD with no validation schema                                                                          |                  7
    createCoreV1Namespace                          |  [sig-cli] Kubectl client Kubectl client-side validation should create/apply a CR with unknown fields for CRD with no validation schema                                                                          |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-cli] Kubectl client Kubectl client-side validation should create/apply a CR with unknown fields for CRD with no validation schema                                                                          |                  7
    deleteCoreV1Namespace                          |  [sig-cli] Kubectl client Kubectl client-side validation should create/apply a CR with unknown fields for CRD with no validation schema                                                                          |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-cli] Kubectl client Kubectl client-side validation should create/apply a CR with unknown fields for CRD with no validation schema                                                                          |                  7
    listCoreV1Node                                 |  [sig-cli] Kubectl client Kubectl client-side validation should create/apply a CR with unknown fields for CRD with no validation schema                                                                          |                  7
    readCoreV1Namespace                            |  [sig-cli] Kubectl client Kubectl client-side validation should create/apply a CR with unknown fields for CRD with no validation schema                                                                          |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-cli] Kubectl client Kubectl client-side validation should create/apply a valid CR for CRD with validation schema                                                                                           |                  7
    createCoreV1Namespace                          |  [sig-cli] Kubectl client Kubectl client-side validation should create/apply a valid CR for CRD with validation schema                                                                                           |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-cli] Kubectl client Kubectl client-side validation should create/apply a valid CR for CRD with validation schema                                                                                           |                  7
    deleteCoreV1Namespace                          |  [sig-cli] Kubectl client Kubectl client-side validation should create/apply a valid CR for CRD with validation schema                                                                                           |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-cli] Kubectl client Kubectl client-side validation should create/apply a valid CR for CRD with validation schema                                                                                           |                  7
    listCoreV1Node                                 |  [sig-cli] Kubectl client Kubectl client-side validation should create/apply a valid CR for CRD with validation schema                                                                                           |                  7
    readCoreV1Namespace                            |  [sig-cli] Kubectl client Kubectl client-side validation should create/apply a valid CR for CRD with validation schema                                                                                           |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-cli] Kubectl client Kubectl client-side validation should create/apply a valid CR with arbitrary-extra properties for CRD with partially-specified validation schema                                       |                  7
    createCoreV1Namespace                          |  [sig-cli] Kubectl client Kubectl client-side validation should create/apply a valid CR with arbitrary-extra properties for CRD with partially-specified validation schema                                       |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-cli] Kubectl client Kubectl client-side validation should create/apply a valid CR with arbitrary-extra properties for CRD with partially-specified validation schema                                       |                  7
    deleteCoreV1Namespace                          |  [sig-cli] Kubectl client Kubectl client-side validation should create/apply a valid CR with arbitrary-extra properties for CRD with partially-specified validation schema                                       |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-cli] Kubectl client Kubectl client-side validation should create/apply a valid CR with arbitrary-extra properties for CRD with partially-specified validation schema                                       |                  7
    listCoreV1Node                                 |  [sig-cli] Kubectl client Kubectl client-side validation should create/apply a valid CR with arbitrary-extra properties for CRD with partially-specified validation schema                                       |                  7
    readCoreV1Namespace                            |  [sig-cli] Kubectl client Kubectl client-side validation should create/apply a valid CR with arbitrary-extra properties for CRD with partially-specified validation schema                                       |                  7
                                                   |  [sig-cli] Kubectl client Kubectl client-side validation should create/apply a valid CR with arbitrary-extra properties for CRD with partially-specified validation schema                                       |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-cli] Kubectl client Kubectl cluster-info dump should check if cluster-info dump succeeds                                                                                                                   |                  7
    createCoreV1Namespace                          |  [sig-cli] Kubectl client Kubectl cluster-info dump should check if cluster-info dump succeeds                                                                                                                   |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-cli] Kubectl client Kubectl cluster-info dump should check if cluster-info dump succeeds                                                                                                                   |                  7
    deleteCoreV1Namespace                          |  [sig-cli] Kubectl client Kubectl cluster-info dump should check if cluster-info dump succeeds                                                                                                                   |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-cli] Kubectl client Kubectl cluster-info dump should check if cluster-info dump succeeds                                                                                                                   |                  7
    listCoreV1Node                                 |  [sig-cli] Kubectl client Kubectl cluster-info dump should check if cluster-info dump succeeds                                                                                                                   |                  7
    readCoreV1Namespace                            |  [sig-cli] Kubectl client Kubectl cluster-info dump should check if cluster-info dump succeeds                                                                                                                   |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes master services is included in cluster-info  [Conformance]                                                                             |                  7
    createCoreV1Namespace                          |  [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes master services is included in cluster-info  [Conformance]                                                                             |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes master services is included in cluster-info  [Conformance]                                                                             |                  7
    deleteCoreV1Namespace                          |  [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes master services is included in cluster-info  [Conformance]                                                                             |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes master services is included in cluster-info  [Conformance]                                                                             |                  7
    listCoreV1Node                                 |  [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes master services is included in cluster-info  [Conformance]                                                                             |                  7
    readCoreV1Namespace                            |  [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes master services is included in cluster-info  [Conformance]                                                                             |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-cli] Kubectl client Kubectl create quota should reject quota with invalid scopes                                                                                                                           |                  7
    createCoreV1Namespace                          |  [sig-cli] Kubectl client Kubectl create quota should reject quota with invalid scopes                                                                                                                           |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-cli] Kubectl client Kubectl create quota should reject quota with invalid scopes                                                                                                                           |                  7
    deleteCoreV1Namespace                          |  [sig-cli] Kubectl client Kubectl create quota should reject quota with invalid scopes                                                                                                                           |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-cli] Kubectl client Kubectl create quota should reject quota with invalid scopes                                                                                                                           |                  7
    listCoreV1Node                                 |  [sig-cli] Kubectl client Kubectl create quota should reject quota with invalid scopes                                                                                                                           |                  7
    readCoreV1Namespace                            |  [sig-cli] Kubectl client Kubectl create quota should reject quota with invalid scopes                                                                                                                           |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-cli] Kubectl client Kubectl get componentstatuses should get componentstatuses                                                                                                                             |                  7
    createCoreV1Namespace                          |  [sig-cli] Kubectl client Kubectl get componentstatuses should get componentstatuses                                                                                                                             |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-cli] Kubectl client Kubectl get componentstatuses should get componentstatuses                                                                                                                             |                  7
    deleteCoreV1Namespace                          |  [sig-cli] Kubectl client Kubectl get componentstatuses should get componentstatuses                                                                                                                             |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-cli] Kubectl client Kubectl get componentstatuses should get componentstatuses                                                                                                                             |                  7
    listCoreV1Node                                 |  [sig-cli] Kubectl client Kubectl get componentstatuses should get componentstatuses                                                                                                                             |                  7
    readCoreV1Namespace                            |  [sig-cli] Kubectl client Kubectl get componentstatuses should get componentstatuses                                                                                                                             |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]                                                                                                                     |                  7
    createCoreV1Namespace                          |  [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]                                                                                                                     |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]                                                                                                                     |                  7
    deleteCoreV1Namespace                          |  [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]                                                                                                                     |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]                                                                                                                     |                  7
    listCoreV1Node                                 |  [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]                                                                                                                     |                  7
    readCoreV1Namespace                            |  [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]                                                                                                                     |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-cli] Kubectl client Proxy server should support                                                                                                                                                            |                  7
    createCoreV1Namespace                          |  [sig-cli] Kubectl client Proxy server should support                                                                                                                                                            |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-cli] Kubectl client Proxy server should support                                                                                                                                                            |                  7
    deleteCoreV1Namespace                          |  [sig-cli] Kubectl client Proxy server should support                                                                                                                                                            |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-cli] Kubectl client Proxy server should support                                                                                                                                                            |                  7
    listCoreV1Node                                 |  [sig-cli] Kubectl client Proxy server should support                                                                                                                                                            |                  7
    readCoreV1Namespace                            |  [sig-cli] Kubectl client Proxy server should support                                                                                                                                                            |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-cli] Kubectl client Proxy server should support proxy with                                                                                                                                                 |                  7
    createCoreV1Namespace                          |  [sig-cli] Kubectl client Proxy server should support proxy with                                                                                                                                                 |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-cli] Kubectl client Proxy server should support proxy with                                                                                                                                                 |                  7
    deleteCoreV1Namespace                          |  [sig-cli] Kubectl client Proxy server should support proxy with                                                                                                                                                 |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-cli] Kubectl client Proxy server should support proxy with                                                                                                                                                 |                  7
    listCoreV1Node                                 |  [sig-cli] Kubectl client Proxy server should support proxy with                                                                                                                                                 |                  7
    readCoreV1Namespace                            |  [sig-cli] Kubectl client Proxy server should support proxy with                                                                                                                                                 |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-instrumentation] MetricsGrabber should grab all metrics from API server.                                                                                                                                   |                  7
    createCoreV1Namespace                          |  [sig-instrumentation] MetricsGrabber should grab all metrics from API server.                                                                                                                                   |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-instrumentation] MetricsGrabber should grab all metrics from API server.                                                                                                                                   |                  7
    deleteCoreV1Namespace                          |  [sig-instrumentation] MetricsGrabber should grab all metrics from API server.                                                                                                                                   |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-instrumentation] MetricsGrabber should grab all metrics from API server.                                                                                                                                   |                  7
    listCoreV1Node                                 |  [sig-instrumentation] MetricsGrabber should grab all metrics from API server.                                                                                                                                   |                  7
    readCoreV1Namespace                            |  [sig-instrumentation] MetricsGrabber should grab all metrics from API server.                                                                                                                                   |                  7
                                                   |  [sig-instrumentation] MetricsGrabber should grab all metrics from API server.                                                                                                                                   |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-network] [sig-windows] Networking Granular Checks: Pods should function for intra-pod communication: http                                                                                                  |                  7
    createCoreV1Namespace                          |  [sig-network] [sig-windows] Networking Granular Checks: Pods should function for intra-pod communication: http                                                                                                  |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-network] [sig-windows] Networking Granular Checks: Pods should function for intra-pod communication: http                                                                                                  |                  7
    deleteCoreV1Namespace                          |  [sig-network] [sig-windows] Networking Granular Checks: Pods should function for intra-pod communication: http                                                                                                  |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-network] [sig-windows] Networking Granular Checks: Pods should function for intra-pod communication: http                                                                                                  |                  7
    listCoreV1Node                                 |  [sig-network] [sig-windows] Networking Granular Checks: Pods should function for intra-pod communication: http                                                                                                  |                  7
    readCoreV1Namespace                            |  [sig-network] [sig-windows] Networking Granular Checks: Pods should function for intra-pod communication: http                                                                                                  |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-network] [sig-windows] Networking Granular Checks: Pods should function for intra-pod communication: udp                                                                                                   |                  7
    createCoreV1Namespace                          |  [sig-network] [sig-windows] Networking Granular Checks: Pods should function for intra-pod communication: udp                                                                                                   |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-network] [sig-windows] Networking Granular Checks: Pods should function for intra-pod communication: udp                                                                                                   |                  7
    deleteCoreV1Namespace                          |  [sig-network] [sig-windows] Networking Granular Checks: Pods should function for intra-pod communication: udp                                                                                                   |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-network] [sig-windows] Networking Granular Checks: Pods should function for intra-pod communication: udp                                                                                                   |                  7
    listCoreV1Node                                 |  [sig-network] [sig-windows] Networking Granular Checks: Pods should function for intra-pod communication: udp                                                                                                   |                  7
    readCoreV1Namespace                            |  [sig-network] [sig-windows] Networking Granular Checks: Pods should function for intra-pod communication: udp                                                                                                   |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-network] [sig-windows] Networking Granular Checks: Pods should function for node-pod communication: http                                                                                                   |                  7
    createCoreV1Namespace                          |  [sig-network] [sig-windows] Networking Granular Checks: Pods should function for node-pod communication: http                                                                                                   |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-network] [sig-windows] Networking Granular Checks: Pods should function for node-pod communication: http                                                                                                   |                  7
    deleteCoreV1Namespace                          |  [sig-network] [sig-windows] Networking Granular Checks: Pods should function for node-pod communication: http                                                                                                   |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-network] [sig-windows] Networking Granular Checks: Pods should function for node-pod communication: http                                                                                                   |                  7
    listCoreV1Node                                 |  [sig-network] [sig-windows] Networking Granular Checks: Pods should function for node-pod communication: http                                                                                                   |                  7
    readCoreV1Namespace                            |  [sig-network] [sig-windows] Networking Granular Checks: Pods should function for node-pod communication: http                                                                                                   |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-network] [sig-windows] Networking Granular Checks: Pods should function for node-pod communication: udp                                                                                                    |                  7
    createCoreV1Namespace                          |  [sig-network] [sig-windows] Networking Granular Checks: Pods should function for node-pod communication: udp                                                                                                    |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-network] [sig-windows] Networking Granular Checks: Pods should function for node-pod communication: udp                                                                                                    |                  7
    deleteCoreV1Namespace                          |  [sig-network] [sig-windows] Networking Granular Checks: Pods should function for node-pod communication: udp                                                                                                    |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-network] [sig-windows] Networking Granular Checks: Pods should function for node-pod communication: udp                                                                                                    |                  7
    listCoreV1Node                                 |  [sig-network] [sig-windows] Networking Granular Checks: Pods should function for node-pod communication: udp                                                                                                    |                  7
    readCoreV1Namespace                            |  [sig-network] [sig-windows] Networking Granular Checks: Pods should function for node-pod communication: udp                                                                                                    |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-scheduling] Multi-AZ Clusters should spread the pods of a replication controller across zones                                                                                                              |                  7
    createCoreV1Namespace                          |  [sig-scheduling] Multi-AZ Clusters should spread the pods of a replication controller across zones                                                                                                              |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-scheduling] Multi-AZ Clusters should spread the pods of a replication controller across zones                                                                                                              |                  7
    deleteCoreV1Namespace                          |  [sig-scheduling] Multi-AZ Clusters should spread the pods of a replication controller across zones                                                                                                              |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-scheduling] Multi-AZ Clusters should spread the pods of a replication controller across zones                                                                                                              |                  7
    listCoreV1Node                                 |  [sig-scheduling] Multi-AZ Clusters should spread the pods of a replication controller across zones                                                                                                              |                  7
    readCoreV1Namespace                            |  [sig-scheduling] Multi-AZ Clusters should spread the pods of a replication controller across zones                                                                                                              |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-scheduling] Multi-AZ Clusters should spread the pods of a service across zones                                                                                                                             |                  7
    createCoreV1Namespace                          |  [sig-scheduling] Multi-AZ Clusters should spread the pods of a service across zones                                                                                                                             |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-scheduling] Multi-AZ Clusters should spread the pods of a service across zones                                                                                                                             |                  7
    deleteCoreV1Namespace                          |  [sig-scheduling] Multi-AZ Clusters should spread the pods of a service across zones                                                                                                                             |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-scheduling] Multi-AZ Clusters should spread the pods of a service across zones                                                                                                                             |                  7
    listCoreV1Node                                 |  [sig-scheduling] Multi-AZ Clusters should spread the pods of a service across zones                                                                                                                             |                  7
    readCoreV1Namespace                            |  [sig-scheduling] Multi-AZ Clusters should spread the pods of a service across zones                                                                                                                             |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-scheduling] Multi-AZ Cluster Volumes [sig-storage] should only be allowed to provision PDs in zones where nodes exist                                                                                      |                  7
    createCoreV1Namespace                          |  [sig-scheduling] Multi-AZ Cluster Volumes [sig-storage] should only be allowed to provision PDs in zones where nodes exist                                                                                      |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-scheduling] Multi-AZ Cluster Volumes [sig-storage] should only be allowed to provision PDs in zones where nodes exist                                                                                      |                  7
    deleteCoreV1Namespace                          |  [sig-scheduling] Multi-AZ Cluster Volumes [sig-storage] should only be allowed to provision PDs in zones where nodes exist                                                                                      |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-scheduling] Multi-AZ Cluster Volumes [sig-storage] should only be allowed to provision PDs in zones where nodes exist                                                                                      |                  7
    listCoreV1Node                                 |  [sig-scheduling] Multi-AZ Cluster Volumes [sig-storage] should only be allowed to provision PDs in zones where nodes exist                                                                                      |                  7
    readCoreV1Namespace                            |  [sig-scheduling] Multi-AZ Cluster Volumes [sig-storage] should only be allowed to provision PDs in zones where nodes exist                                                                                      |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-scheduling] Multi-AZ Cluster Volumes [sig-storage] should schedule pods in the same zones as statically provisioned PVs                                                                                    |                  7
    createCoreV1Namespace                          |  [sig-scheduling] Multi-AZ Cluster Volumes [sig-storage] should schedule pods in the same zones as statically provisioned PVs                                                                                    |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-scheduling] Multi-AZ Cluster Volumes [sig-storage] should schedule pods in the same zones as statically provisioned PVs                                                                                    |                  7
    deleteCoreV1Namespace                          |  [sig-scheduling] Multi-AZ Cluster Volumes [sig-storage] should schedule pods in the same zones as statically provisioned PVs                                                                                    |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-scheduling] Multi-AZ Cluster Volumes [sig-storage] should schedule pods in the same zones as statically provisioned PVs                                                                                    |                  7
    listCoreV1Node                                 |  [sig-scheduling] Multi-AZ Cluster Volumes [sig-storage] should schedule pods in the same zones as statically provisioned PVs                                                                                    |                  7
    readCoreV1Namespace                            |  [sig-scheduling] Multi-AZ Cluster Volumes [sig-storage] should schedule pods in the same zones as statically provisioned PVs                                                                                    |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options                                                                |                  7
    createCoreV1Namespace                          |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options                                                                |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options                                                                |                  7
    deleteCoreV1Namespace                          |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options                                                                |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options                                                                |                  7
    listCoreV1Node                                 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options                                                                |                  7
    readCoreV1Namespace                            |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options                                                                |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume                                                                        |                  7
    createCoreV1Namespace                          |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume                                                                        |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume                                                                        |                  7
    deleteCoreV1Namespace                          |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume                                                                        |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume                                                                        |                  7
    listCoreV1Node                                 |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume                                                                        |                  7
    readCoreV1Namespace                            |  [sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume                                                                        |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                                                         |                  7
    createCoreV1Namespace                          |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                                                         |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                                                         |                  7
    deleteCoreV1Namespace                          |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                                                         |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                                                         |                  7
    listCoreV1Node                                 |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                                                         |                  7
    readCoreV1Namespace                            |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                                                         |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (block volmode)] volumes should store data                                                                                         |                  7
    createCoreV1Namespace                          |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (block volmode)] volumes should store data                                                                                         |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (block volmode)] volumes should store data                                                                                         |                  7
    deleteCoreV1Namespace                          |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (block volmode)] volumes should store data                                                                                         |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (block volmode)] volumes should store data                                                                                         |                  7
    listCoreV1Node                                 |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (block volmode)] volumes should store data                                                                                         |                  7
    readCoreV1Namespace                            |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (block volmode)] volumes should store data                                                                                         |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options                                                             |                  7
    createCoreV1Namespace                          |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options                                                             |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options                                                             |                  7
    deleteCoreV1Namespace                          |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options                                                             |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options                                                             |                  7
    listCoreV1Node                                 |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options                                                             |                  7
    readCoreV1Namespace                            |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options                                                             |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source                                                           |                  7
    createCoreV1Namespace                          |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source                                                           |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source                                                           |                  7
    deleteCoreV1Namespace                          |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source                                                           |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source                                                           |                  7
    listCoreV1Node                                 |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source                                                           |                  7
    readCoreV1Namespace                            |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source                                                           |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume                                                                     |                  7
    createCoreV1Namespace                          |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume                                                                     |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume                                                                     |                  7
    deleteCoreV1Namespace                          |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume                                                                     |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume                                                                     |                  7
    listCoreV1Node                                 |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume                                                                     |                  7
    readCoreV1Namespace                            |  [sig-storage] CSI Volumes [Driver: csi-hostpath-v0] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume                                                                     |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] Dynamic Provisioning Invalid AWS KMS key should report an error and create no PV                                                                                                                  |                  7
    createCoreV1Namespace                          |  [sig-storage] Dynamic Provisioning Invalid AWS KMS key should report an error and create no PV                                                                                                                  |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] Dynamic Provisioning Invalid AWS KMS key should report an error and create no PV                                                                                                                  |                  7
    deleteCoreV1Namespace                          |  [sig-storage] Dynamic Provisioning Invalid AWS KMS key should report an error and create no PV                                                                                                                  |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] Dynamic Provisioning Invalid AWS KMS key should report an error and create no PV                                                                                                                  |                  7
    listCoreV1Node                                 |  [sig-storage] Dynamic Provisioning Invalid AWS KMS key should report an error and create no PV                                                                                                                  |                  7
    readCoreV1Namespace                            |  [sig-storage] Dynamic Provisioning Invalid AWS KMS key should report an error and create no PV                                                                                                                  |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source                                                                 |                  7
    createCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source                                                                 |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source                                                                 |                  7
    deleteCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source                                                                 |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source                                                                 |                  7
    listCoreV1Node                                 |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source                                                                 |                  7
    readCoreV1Namespace                            |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source                                                                 |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                                                     |                  7
    createCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                                                     |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                                                     |                  7
    deleteCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                                                     |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                                                     |                  7
    listCoreV1Node                                 |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                                                     |                  7
    readCoreV1Namespace                            |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                                                     |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                                                     |                  7
    createCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                                                     |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                                                     |                  7
    deleteCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                                                     |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                                                     |                  7
    listCoreV1Node                                 |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                                                     |                  7
    readCoreV1Namespace                            |  [sig-storage] In-tree Volumes [Driver: gluster] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                                                     |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume                                                              |                  7
    createCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume                                                              |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume                                                              |                  7
    deleteCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume                                                              |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume                                                              |                  7
    listCoreV1Node                                 |  [sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume                                                              |                  7
    readCoreV1Namespace                            |  [sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume                                                              |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume                                                                     |                  7
    createCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume                                                                     |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume                                                                     |                  7
    deleteCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume                                                                     |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume                                                                     |                  7
    listCoreV1Node                                 |  [sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume                                                                     |                  7
    readCoreV1Namespace                            |  [sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume                                                                     |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                             |                  7
    createCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                             |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                             |                  7
    deleteCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                             |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                             |                  7
    listCoreV1Node                                 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                             |                  7
    readCoreV1Namespace                            |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                             |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                             |                  7
    createCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                             |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                             |                  7
    deleteCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                             |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                             |                  7
    listCoreV1Node                                 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                             |                  7
    readCoreV1Namespace                            |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                             |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                     |                  7
    createCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                     |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                     |                  7
    deleteCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                     |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                     |                  7
    listCoreV1Node                                 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                     |                  7
    readCoreV1Namespace                            |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                     |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                     |                  7
    createCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                     |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                     |                  7
    deleteCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                     |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                     |                  7
    listCoreV1Node                                 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                     |                  7
    readCoreV1Namespace                            |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                     |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                |                  7
    createCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                |                  7
    deleteCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                |                  7
    listCoreV1Node                                 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                |                  7
    readCoreV1Namespace                            |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                |                  7
    createCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                |                  7
    deleteCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                |                  7
    listCoreV1Node                                 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                |                  7
    readCoreV1Namespace                            |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                            |                  7
    createCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                            |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                            |                  7
    deleteCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                            |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                            |                  7
    listCoreV1Node                                 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                            |                  7
    readCoreV1Namespace                            |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                            |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                            |                  7
    createCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                            |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                            |                  7
    deleteCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                            |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                            |                  7
    listCoreV1Node                                 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                            |                  7
    readCoreV1Namespace                            |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                            |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                                 |                  7
    createCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                                 |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                                 |                  7
    deleteCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                                 |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                                 |                  7
    listCoreV1Node                                 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                                 |                  7
    readCoreV1Namespace                            |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                                 |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                                 |                  7
    createCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                                 |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                                 |                  7
    deleteCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                                 |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                                 |                  7
    listCoreV1Node                                 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                                 |                  7
    readCoreV1Namespace                            |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                                 |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                               |                  7
    createCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                               |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                               |                  7
    deleteCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                               |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                               |                  7
    listCoreV1Node                                 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                               |                  7
    readCoreV1Namespace                            |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                               |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                               |                  7
    createCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                               |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                               |                  7
    deleteCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                               |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                               |                  7
    listCoreV1Node                                 |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                               |                  7
    readCoreV1Namespace                            |  [sig-storage] In-tree Volumes [Driver: local][LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                               |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                                                                 |                  7
    createCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                                                                 |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                                                                 |                  7
    deleteCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                                                                 |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                                                                 |                  7
    listCoreV1Node                                 |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                                                                 |                  7
    readCoreV1Namespace                            |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                                                                 |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (block volmode)] volumes should store data                                                                                                 |                  7
    createCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (block volmode)] volumes should store data                                                                                                 |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (block volmode)] volumes should store data                                                                                                 |                  7
    deleteCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (block volmode)] volumes should store data                                                                                                 |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (block volmode)] volumes should store data                                                                                                 |                  7
    listCoreV1Node                                 |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (block volmode)] volumes should store data                                                                                                 |                  7
    readCoreV1Namespace                            |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (block volmode)] volumes should store data                                                                                                 |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source                                                                   |                  7
    createCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source                                                                   |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source                                                                   |                  7
    deleteCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source                                                                   |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source                                                                   |                  7
    listCoreV1Node                                 |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source                                                                   |                  7
    readCoreV1Namespace                            |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source                                                                   |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                                                         |                  7
    createCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                                                         |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                                                         |                  7
    deleteCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                                                         |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                                                         |                  7
    listCoreV1Node                                 |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                                                         |                  7
    readCoreV1Namespace                            |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod                                                         |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                                                         |                  7
    createCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                                                         |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                                                         |                  7
    deleteCoreV1Namespace                          |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                                                         |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                                                         |                  7
    listCoreV1Node                                 |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                                                         |                  7
    readCoreV1Namespace                            |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data                                                                                         |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] PersistentVolumes:vsphere should test that deleting a PVC before the pod does not cause pod deletion to fail on vsphere volume detach                                                             |                  7
    createCoreV1Namespace                          |  [sig-storage] PersistentVolumes:vsphere should test that deleting a PVC before the pod does not cause pod deletion to fail on vsphere volume detach                                                             |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] PersistentVolumes:vsphere should test that deleting a PVC before the pod does not cause pod deletion to fail on vsphere volume detach                                                             |                  7
    deleteCoreV1Namespace                          |  [sig-storage] PersistentVolumes:vsphere should test that deleting a PVC before the pod does not cause pod deletion to fail on vsphere volume detach                                                             |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] PersistentVolumes:vsphere should test that deleting a PVC before the pod does not cause pod deletion to fail on vsphere volume detach                                                             |                  7
    listCoreV1Node                                 |  [sig-storage] PersistentVolumes:vsphere should test that deleting a PVC before the pod does not cause pod deletion to fail on vsphere volume detach                                                             |                  7
    readCoreV1Namespace                            |  [sig-storage] PersistentVolumes:vsphere should test that deleting a PVC before the pod does not cause pod deletion to fail on vsphere volume detach                                                             |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] PersistentVolumes:vsphere should test that deleting the Namespace of a PVC and Pod causes the successful detach of vsphere volume                                                                 |                  7
    createCoreV1Namespace                          |  [sig-storage] PersistentVolumes:vsphere should test that deleting the Namespace of a PVC and Pod causes the successful detach of vsphere volume                                                                 |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] PersistentVolumes:vsphere should test that deleting the Namespace of a PVC and Pod causes the successful detach of vsphere volume                                                                 |                  7
    deleteCoreV1Namespace                          |  [sig-storage] PersistentVolumes:vsphere should test that deleting the Namespace of a PVC and Pod causes the successful detach of vsphere volume                                                                 |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] PersistentVolumes:vsphere should test that deleting the Namespace of a PVC and Pod causes the successful detach of vsphere volume                                                                 |                  7
    listCoreV1Node                                 |  [sig-storage] PersistentVolumes:vsphere should test that deleting the Namespace of a PVC and Pod causes the successful detach of vsphere volume                                                                 |                  7
    readCoreV1Namespace                            |  [sig-storage] PersistentVolumes:vsphere should test that deleting the Namespace of a PVC and Pod causes the successful detach of vsphere volume                                                                 |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] PersistentVolumes:vsphere should test that deleting the PV before the pod does not cause pod deletion to fail on vspehre volume detach                                                            |                  7
    createCoreV1Namespace                          |  [sig-storage] PersistentVolumes:vsphere should test that deleting the PV before the pod does not cause pod deletion to fail on vspehre volume detach                                                            |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] PersistentVolumes:vsphere should test that deleting the PV before the pod does not cause pod deletion to fail on vspehre volume detach                                                            |                  7
    deleteCoreV1Namespace                          |  [sig-storage] PersistentVolumes:vsphere should test that deleting the PV before the pod does not cause pod deletion to fail on vspehre volume detach                                                            |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] PersistentVolumes:vsphere should test that deleting the PV before the pod does not cause pod deletion to fail on vspehre volume detach                                                            |                  7
    listCoreV1Node                                 |  [sig-storage] PersistentVolumes:vsphere should test that deleting the PV before the pod does not cause pod deletion to fail on vspehre volume detach                                                            |                  7
    readCoreV1Namespace                            |  [sig-storage] PersistentVolumes:vsphere should test that deleting the PV before the pod does not cause pod deletion to fail on vspehre volume detach                                                            |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] Pod Disks should be able to delete a non-existent PD without error                                                                                                                                |                  7
    createCoreV1Namespace                          |  [sig-storage] Pod Disks should be able to delete a non-existent PD without error                                                                                                                                |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] Pod Disks should be able to delete a non-existent PD without error                                                                                                                                |                  7
    deleteCoreV1Namespace                          |  [sig-storage] Pod Disks should be able to delete a non-existent PD without error                                                                                                                                |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] Pod Disks should be able to delete a non-existent PD without error                                                                                                                                |                  7
    listCoreV1Node                                 |  [sig-storage] Pod Disks should be able to delete a non-existent PD without error                                                                                                                                |                  7
    readCoreV1Namespace                            |  [sig-storage] Pod Disks should be able to delete a non-existent PD without error                                                                                                                                |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] Volume limits should verify that all nodes have volume limits                                                                                                                                     |                  7
    createCoreV1Namespace                          |  [sig-storage] Volume limits should verify that all nodes have volume limits                                                                                                                                     |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] Volume limits should verify that all nodes have volume limits                                                                                                                                     |                  7
    deleteCoreV1Namespace                          |  [sig-storage] Volume limits should verify that all nodes have volume limits                                                                                                                                     |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] Volume limits should verify that all nodes have volume limits                                                                                                                                     |                  7
    listCoreV1Node                                 |  [sig-storage] Volume limits should verify that all nodes have volume limits                                                                                                                                     |                  7
    readCoreV1Namespace                            |  [sig-storage] Volume limits should verify that all nodes have volume limits                                                                                                                                     |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] Volume Placement should create and delete pod with multiple volumes from different datastore                                                                                                      |                  7
    createCoreV1Namespace                          |  [sig-storage] Volume Placement should create and delete pod with multiple volumes from different datastore                                                                                                      |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] Volume Placement should create and delete pod with multiple volumes from different datastore                                                                                                      |                  7
    deleteCoreV1Namespace                          |  [sig-storage] Volume Placement should create and delete pod with multiple volumes from different datastore                                                                                                      |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] Volume Placement should create and delete pod with multiple volumes from different datastore                                                                                                      |                  7
    listCoreV1Node                                 |  [sig-storage] Volume Placement should create and delete pod with multiple volumes from different datastore                                                                                                      |                  7
    readCoreV1Namespace                            |  [sig-storage] Volume Placement should create and delete pod with multiple volumes from different datastore                                                                                                      |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] Volume Placement should create and delete pod with multiple volumes from same datastore                                                                                                           |                  7
    createCoreV1Namespace                          |  [sig-storage] Volume Placement should create and delete pod with multiple volumes from same datastore                                                                                                           |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] Volume Placement should create and delete pod with multiple volumes from same datastore                                                                                                           |                  7
    deleteCoreV1Namespace                          |  [sig-storage] Volume Placement should create and delete pod with multiple volumes from same datastore                                                                                                           |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] Volume Placement should create and delete pod with multiple volumes from same datastore                                                                                                           |                  7
    listCoreV1Node                                 |  [sig-storage] Volume Placement should create and delete pod with multiple volumes from same datastore                                                                                                           |                  7
    readCoreV1Namespace                            |  [sig-storage] Volume Placement should create and delete pod with multiple volumes from same datastore                                                                                                           |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] Volume Placement should create and delete pod with the same volume source attach/detach to different worker nodes                                                                                 |                  7
    createCoreV1Namespace                          |  [sig-storage] Volume Placement should create and delete pod with the same volume source attach/detach to different worker nodes                                                                                 |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] Volume Placement should create and delete pod with the same volume source attach/detach to different worker nodes                                                                                 |                  7
    deleteCoreV1Namespace                          |  [sig-storage] Volume Placement should create and delete pod with the same volume source attach/detach to different worker nodes                                                                                 |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] Volume Placement should create and delete pod with the same volume source attach/detach to different worker nodes                                                                                 |                  7
    listCoreV1Node                                 |  [sig-storage] Volume Placement should create and delete pod with the same volume source attach/detach to different worker nodes                                                                                 |                  7
    readCoreV1Namespace                            |  [sig-storage] Volume Placement should create and delete pod with the same volume source attach/detach to different worker nodes                                                                                 |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] Volume Placement should create and delete pod with the same volume source on the same worker node                                                                                                 |                  7
    createCoreV1Namespace                          |  [sig-storage] Volume Placement should create and delete pod with the same volume source on the same worker node                                                                                                 |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] Volume Placement should create and delete pod with the same volume source on the same worker node                                                                                                 |                  7
    deleteCoreV1Namespace                          |  [sig-storage] Volume Placement should create and delete pod with the same volume source on the same worker node                                                                                                 |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] Volume Placement should create and delete pod with the same volume source on the same worker node                                                                                                 |                  7
    listCoreV1Node                                 |  [sig-storage] Volume Placement should create and delete pod with the same volume source on the same worker node                                                                                                 |                  7
    readCoreV1Namespace                            |  [sig-storage] Volume Placement should create and delete pod with the same volume source on the same worker node                                                                                                 |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] Volume Placement test back to back pod creation and deletion with different volume sources on the same worker node                                                                                |                  7
    createCoreV1Namespace                          |  [sig-storage] Volume Placement test back to back pod creation and deletion with different volume sources on the same worker node                                                                                |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] Volume Placement test back to back pod creation and deletion with different volume sources on the same worker node                                                                                |                  7
    deleteCoreV1Namespace                          |  [sig-storage] Volume Placement test back to back pod creation and deletion with different volume sources on the same worker node                                                                                |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] Volume Placement test back to back pod creation and deletion with different volume sources on the same worker node                                                                                |                  7
    listCoreV1Node                                 |  [sig-storage] Volume Placement test back to back pod creation and deletion with different volume sources on the same worker node                                                                                |                  7
    readCoreV1Namespace                            |  [sig-storage] Volume Placement test back to back pod creation and deletion with different volume sources on the same worker node                                                                                |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] vsphere statefulset vsphere statefulset testing                                                                                                                                                   |                  7
    createCoreV1Namespace                          |  [sig-storage] vsphere statefulset vsphere statefulset testing                                                                                                                                                   |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] vsphere statefulset vsphere statefulset testing                                                                                                                                                   |                  7
    deleteCoreV1Namespace                          |  [sig-storage] vsphere statefulset vsphere statefulset testing                                                                                                                                                   |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] vsphere statefulset vsphere statefulset testing                                                                                                                                                   |                  7
    listCoreV1Node                                 |  [sig-storage] vsphere statefulset vsphere statefulset testing                                                                                                                                                   |                  7
    readCoreV1Namespace                            |  [sig-storage] vsphere statefulset vsphere statefulset testing                                                                                                                                                   |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] Zone Support Verify a pod fails to get scheduled when conflicting volume topology (allowedTopologies) and pod scheduling constraints(nodeSelector) are specified                                  |                  7
    createCoreV1Namespace                          |  [sig-storage] Zone Support Verify a pod fails to get scheduled when conflicting volume topology (allowedTopologies) and pod scheduling constraints(nodeSelector) are specified                                  |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] Zone Support Verify a pod fails to get scheduled when conflicting volume topology (allowedTopologies) and pod scheduling constraints(nodeSelector) are specified                                  |                  7
    deleteCoreV1Namespace                          |  [sig-storage] Zone Support Verify a pod fails to get scheduled when conflicting volume topology (allowedTopologies) and pod scheduling constraints(nodeSelector) are specified                                  |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] Zone Support Verify a pod fails to get scheduled when conflicting volume topology (allowedTopologies) and pod scheduling constraints(nodeSelector) are specified                                  |                  7
    listCoreV1Node                                 |  [sig-storage] Zone Support Verify a pod fails to get scheduled when conflicting volume topology (allowedTopologies) and pod scheduling constraints(nodeSelector) are specified                                  |                  7
    readCoreV1Namespace                            |  [sig-storage] Zone Support Verify a pod fails to get scheduled when conflicting volume topology (allowedTopologies) and pod scheduling constraints(nodeSelector) are specified                                  |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on allowed zones specified in storage class                                                                  |                  7
    createCoreV1Namespace                          |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on allowed zones specified in storage class                                                                  |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on allowed zones specified in storage class                                                                  |                  7
    deleteCoreV1Namespace                          |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on allowed zones specified in storage class                                                                  |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on allowed zones specified in storage class                                                                  |                  7
    listCoreV1Node                                 |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on allowed zones specified in storage class                                                                  |                  7
    readCoreV1Namespace                            |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on allowed zones specified in storage class                                                                  |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on a VSAN capability, datastore and compatible zone specified in storage class                               |                  7
    createCoreV1Namespace                          |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on a VSAN capability, datastore and compatible zone specified in storage class                               |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on a VSAN capability, datastore and compatible zone specified in storage class                               |                  7
    deleteCoreV1Namespace                          |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on a VSAN capability, datastore and compatible zone specified in storage class                               |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on a VSAN capability, datastore and compatible zone specified in storage class                               |                  7
    listCoreV1Node                                 |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on a VSAN capability, datastore and compatible zone specified in storage class                               |                  7
    readCoreV1Namespace                            |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on a VSAN capability, datastore and compatible zone specified in storage class                               |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on multiple zones specified in storage class                                                                 |                  7
    createCoreV1Namespace                          |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on multiple zones specified in storage class                                                                 |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on multiple zones specified in storage class                                                                 |                  7
    deleteCoreV1Namespace                          |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on multiple zones specified in storage class                                                                 |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on multiple zones specified in storage class                                                                 |                  7
    listCoreV1Node                                 |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on multiple zones specified in storage class                                                                 |                  7
    readCoreV1Namespace                            |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on multiple zones specified in storage class                                                                 |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on multiple zones specified in the storage class. (No shared datastores exist among both zones)              |                  7
    createCoreV1Namespace                          |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on multiple zones specified in the storage class. (No shared datastores exist among both zones)              |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on multiple zones specified in the storage class. (No shared datastores exist among both zones)              |                  7
    deleteCoreV1Namespace                          |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on multiple zones specified in the storage class. (No shared datastores exist among both zones)              |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on multiple zones specified in the storage class. (No shared datastores exist among both zones)              |                  7
    listCoreV1Node                                 |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on multiple zones specified in the storage class. (No shared datastores exist among both zones)              |                  7
    readCoreV1Namespace                            |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on multiple zones specified in the storage class. (No shared datastores exist among both zones)              |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on the allowed zones and datastore specified in storage class                                                |                  7
    createCoreV1Namespace                          |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on the allowed zones and datastore specified in storage class                                                |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on the allowed zones and datastore specified in storage class                                                |                  7
    deleteCoreV1Namespace                          |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on the allowed zones and datastore specified in storage class                                                |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on the allowed zones and datastore specified in storage class                                                |                  7
    listCoreV1Node                                 |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on the allowed zones and datastore specified in storage class                                                |                  7
    readCoreV1Namespace                            |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on the allowed zones and datastore specified in storage class                                                |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on the allowed zones and storage policy specified in storage class                                           |                  7
    createCoreV1Namespace                          |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on the allowed zones and storage policy specified in storage class                                           |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on the allowed zones and storage policy specified in storage class                                           |                  7
    deleteCoreV1Namespace                          |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on the allowed zones and storage policy specified in storage class                                           |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on the allowed zones and storage policy specified in storage class                                           |                  7
    listCoreV1Node                                 |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on the allowed zones and storage policy specified in storage class                                           |                  7
    readCoreV1Namespace                            |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on the allowed zones and storage policy specified in storage class                                           |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on the allowed zones, datastore and storage policy specified in storage class                                |                  7
    createCoreV1Namespace                          |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on the allowed zones, datastore and storage policy specified in storage class                                |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on the allowed zones, datastore and storage policy specified in storage class                                |                  7
    deleteCoreV1Namespace                          |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on the allowed zones, datastore and storage policy specified in storage class                                |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on the allowed zones, datastore and storage policy specified in storage class                                |                  7
    listCoreV1Node                                 |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on the allowed zones, datastore and storage policy specified in storage class                                |                  7
    readCoreV1Namespace                            |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV, based on the allowed zones, datastore and storage policy specified in storage class                                |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV with storage policy specified in storage class in waitForFirstConsumer binding mode                                 |                  7
    createCoreV1Namespace                          |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV with storage policy specified in storage class in waitForFirstConsumer binding mode                                 |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV with storage policy specified in storage class in waitForFirstConsumer binding mode                                 |                  7
    deleteCoreV1Namespace                          |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV with storage policy specified in storage class in waitForFirstConsumer binding mode                                 |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV with storage policy specified in storage class in waitForFirstConsumer binding mode                                 |                  7
    listCoreV1Node                                 |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV with storage policy specified in storage class in waitForFirstConsumer binding mode                                 |                  7
    readCoreV1Namespace                            |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV with storage policy specified in storage class in waitForFirstConsumer binding mode                                 |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV with storage policy specified in storage class in waitForFirstConsumer binding mode with allowedTopologies          |                  7
    createCoreV1Namespace                          |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV with storage policy specified in storage class in waitForFirstConsumer binding mode with allowedTopologies          |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV with storage policy specified in storage class in waitForFirstConsumer binding mode with allowedTopologies          |                  7
    deleteCoreV1Namespace                          |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV with storage policy specified in storage class in waitForFirstConsumer binding mode with allowedTopologies          |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV with storage policy specified in storage class in waitForFirstConsumer binding mode with allowedTopologies          |                  7
    listCoreV1Node                                 |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV with storage policy specified in storage class in waitForFirstConsumer binding mode with allowedTopologies          |                  7
    readCoreV1Namespace                            |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV with storage policy specified in storage class in waitForFirstConsumer binding mode with allowedTopologies          |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV with storage policy specified in storage class in waitForFirstConsumer binding mode with multiple allowedTopologies |                  7
    createCoreV1Namespace                          |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV with storage policy specified in storage class in waitForFirstConsumer binding mode with multiple allowedTopologies |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV with storage policy specified in storage class in waitForFirstConsumer binding mode with multiple allowedTopologies |                  7
    deleteCoreV1Namespace                          |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV with storage policy specified in storage class in waitForFirstConsumer binding mode with multiple allowedTopologies |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV with storage policy specified in storage class in waitForFirstConsumer binding mode with multiple allowedTopologies |                  7
    listCoreV1Node                                 |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV with storage policy specified in storage class in waitForFirstConsumer binding mode with multiple allowedTopologies |                  7
    readCoreV1Namespace                            |  [sig-storage] Zone Support Verify a pod is created and attached to a dynamically created PV with storage policy specified in storage class in waitForFirstConsumer binding mode with multiple allowedTopologies |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] Zone Support Verify a pod is created on a non-Workspace zone and attached to a dynamically created PV, based on the allowed zones and storage policy specified in storage class                   |                  7
    createCoreV1Namespace                          |  [sig-storage] Zone Support Verify a pod is created on a non-Workspace zone and attached to a dynamically created PV, based on the allowed zones and storage policy specified in storage class                   |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] Zone Support Verify a pod is created on a non-Workspace zone and attached to a dynamically created PV, based on the allowed zones and storage policy specified in storage class                   |                  7
    deleteCoreV1Namespace                          |  [sig-storage] Zone Support Verify a pod is created on a non-Workspace zone and attached to a dynamically created PV, based on the allowed zones and storage policy specified in storage class                   |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] Zone Support Verify a pod is created on a non-Workspace zone and attached to a dynamically created PV, based on the allowed zones and storage policy specified in storage class                   |                  7
    listCoreV1Node                                 |  [sig-storage] Zone Support Verify a pod is created on a non-Workspace zone and attached to a dynamically created PV, based on the allowed zones and storage policy specified in storage class                   |                  7
    readCoreV1Namespace                            |  [sig-storage] Zone Support Verify a pod is created on a non-Workspace zone and attached to a dynamically created PV, based on the allowed zones and storage policy specified in storage class                   |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] Zone Support Verify dynamically created pv with allowed zones specified in storage class, shows the right zone information on its labels                                                          |                  7
    createCoreV1Namespace                          |  [sig-storage] Zone Support Verify dynamically created pv with allowed zones specified in storage class, shows the right zone information on its labels                                                          |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] Zone Support Verify dynamically created pv with allowed zones specified in storage class, shows the right zone information on its labels                                                          |                  7
    deleteCoreV1Namespace                          |  [sig-storage] Zone Support Verify dynamically created pv with allowed zones specified in storage class, shows the right zone information on its labels                                                          |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] Zone Support Verify dynamically created pv with allowed zones specified in storage class, shows the right zone information on its labels                                                          |                  7
    listCoreV1Node                                 |  [sig-storage] Zone Support Verify dynamically created pv with allowed zones specified in storage class, shows the right zone information on its labels                                                          |                  7
    readCoreV1Namespace                            |  [sig-storage] Zone Support Verify dynamically created pv with allowed zones specified in storage class, shows the right zone information on its labels                                                          |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] Zone Support Verify dynamically created pv with multiple zones specified in the storage class, shows both the zones on its labels                                                                 |                  7
    createCoreV1Namespace                          |  [sig-storage] Zone Support Verify dynamically created pv with multiple zones specified in the storage class, shows both the zones on its labels                                                                 |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] Zone Support Verify dynamically created pv with multiple zones specified in the storage class, shows both the zones on its labels                                                                 |                  7
    deleteCoreV1Namespace                          |  [sig-storage] Zone Support Verify dynamically created pv with multiple zones specified in the storage class, shows both the zones on its labels                                                                 |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] Zone Support Verify dynamically created pv with multiple zones specified in the storage class, shows both the zones on its labels                                                                 |                  7
    listCoreV1Node                                 |  [sig-storage] Zone Support Verify dynamically created pv with multiple zones specified in the storage class, shows both the zones on its labels                                                                 |                  7
    readCoreV1Namespace                            |  [sig-storage] Zone Support Verify dynamically created pv with multiple zones specified in the storage class, shows both the zones on its labels                                                                 |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] Zone Support Verify PVC creation fails if no zones are specified in the storage class (No shared datastores exist among all the nodes)                                                            |                  7
    createCoreV1Namespace                          |  [sig-storage] Zone Support Verify PVC creation fails if no zones are specified in the storage class (No shared datastores exist among all the nodes)                                                            |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] Zone Support Verify PVC creation fails if no zones are specified in the storage class (No shared datastores exist among all the nodes)                                                            |                  7
    deleteCoreV1Namespace                          |  [sig-storage] Zone Support Verify PVC creation fails if no zones are specified in the storage class (No shared datastores exist among all the nodes)                                                            |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] Zone Support Verify PVC creation fails if no zones are specified in the storage class (No shared datastores exist among all the nodes)                                                            |                  7
    listCoreV1Node                                 |  [sig-storage] Zone Support Verify PVC creation fails if no zones are specified in the storage class (No shared datastores exist among all the nodes)                                                            |                  7
    readCoreV1Namespace                            |  [sig-storage] Zone Support Verify PVC creation fails if no zones are specified in the storage class (No shared datastores exist among all the nodes)                                                            |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] Zone Support Verify PVC creation fails if only datastore is specified in the storage class (No shared datastores exist among all the nodes)                                                       |                  7
    createCoreV1Namespace                          |  [sig-storage] Zone Support Verify PVC creation fails if only datastore is specified in the storage class (No shared datastores exist among all the nodes)                                                       |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] Zone Support Verify PVC creation fails if only datastore is specified in the storage class (No shared datastores exist among all the nodes)                                                       |                  7
    deleteCoreV1Namespace                          |  [sig-storage] Zone Support Verify PVC creation fails if only datastore is specified in the storage class (No shared datastores exist among all the nodes)                                                       |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] Zone Support Verify PVC creation fails if only datastore is specified in the storage class (No shared datastores exist among all the nodes)                                                       |                  7
    listCoreV1Node                                 |  [sig-storage] Zone Support Verify PVC creation fails if only datastore is specified in the storage class (No shared datastores exist among all the nodes)                                                       |                  7
    readCoreV1Namespace                            |  [sig-storage] Zone Support Verify PVC creation fails if only datastore is specified in the storage class (No shared datastores exist among all the nodes)                                                       |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] Zone Support Verify PVC creation fails if only storage policy is specified in the storage class (No shared datastores exist among all the nodes)                                                  |                  7
    createCoreV1Namespace                          |  [sig-storage] Zone Support Verify PVC creation fails if only storage policy is specified in the storage class (No shared datastores exist among all the nodes)                                                  |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] Zone Support Verify PVC creation fails if only storage policy is specified in the storage class (No shared datastores exist among all the nodes)                                                  |                  7
    deleteCoreV1Namespace                          |  [sig-storage] Zone Support Verify PVC creation fails if only storage policy is specified in the storage class (No shared datastores exist among all the nodes)                                                  |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] Zone Support Verify PVC creation fails if only storage policy is specified in the storage class (No shared datastores exist among all the nodes)                                                  |                  7
    listCoreV1Node                                 |  [sig-storage] Zone Support Verify PVC creation fails if only storage policy is specified in the storage class (No shared datastores exist among all the nodes)                                                  |                  7
    readCoreV1Namespace                            |  [sig-storage] Zone Support Verify PVC creation fails if only storage policy is specified in the storage class (No shared datastores exist among all the nodes)                                                  |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] Zone Support Verify PVC creation fails if the availability zone specified in the storage class have no shared datastores under it.                                                                |                  7
    createCoreV1Namespace                          |  [sig-storage] Zone Support Verify PVC creation fails if the availability zone specified in the storage class have no shared datastores under it.                                                                |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] Zone Support Verify PVC creation fails if the availability zone specified in the storage class have no shared datastores under it.                                                                |                  7
    deleteCoreV1Namespace                          |  [sig-storage] Zone Support Verify PVC creation fails if the availability zone specified in the storage class have no shared datastores under it.                                                                |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] Zone Support Verify PVC creation fails if the availability zone specified in the storage class have no shared datastores under it.                                                                |                  7
    listCoreV1Node                                 |  [sig-storage] Zone Support Verify PVC creation fails if the availability zone specified in the storage class have no shared datastores under it.                                                                |                  7
    readCoreV1Namespace                            |  [sig-storage] Zone Support Verify PVC creation fails if the availability zone specified in the storage class have no shared datastores under it.                                                                |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] Zone Support Verify PVC creation with an invalid VSAN capability along with a compatible zone combination specified in storage class fails                                                        |                  7
    createCoreV1Namespace                          |  [sig-storage] Zone Support Verify PVC creation with an invalid VSAN capability along with a compatible zone combination specified in storage class fails                                                        |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] Zone Support Verify PVC creation with an invalid VSAN capability along with a compatible zone combination specified in storage class fails                                                        |                  7
    deleteCoreV1Namespace                          |  [sig-storage] Zone Support Verify PVC creation with an invalid VSAN capability along with a compatible zone combination specified in storage class fails                                                        |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] Zone Support Verify PVC creation with an invalid VSAN capability along with a compatible zone combination specified in storage class fails                                                        |                  7
    listCoreV1Node                                 |  [sig-storage] Zone Support Verify PVC creation with an invalid VSAN capability along with a compatible zone combination specified in storage class fails                                                        |                  7
    readCoreV1Namespace                            |  [sig-storage] Zone Support Verify PVC creation with an invalid VSAN capability along with a compatible zone combination specified in storage class fails                                                        |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] Zone Support Verify PVC creation with compatible policy and datastore without any zones specified in the storage class fails (No shared datastores exist among all the nodes)                     |                  7
    createCoreV1Namespace                          |  [sig-storage] Zone Support Verify PVC creation with compatible policy and datastore without any zones specified in the storage class fails (No shared datastores exist among all the nodes)                     |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] Zone Support Verify PVC creation with compatible policy and datastore without any zones specified in the storage class fails (No shared datastores exist among all the nodes)                     |                  7
    deleteCoreV1Namespace                          |  [sig-storage] Zone Support Verify PVC creation with compatible policy and datastore without any zones specified in the storage class fails (No shared datastores exist among all the nodes)                     |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] Zone Support Verify PVC creation with compatible policy and datastore without any zones specified in the storage class fails (No shared datastores exist among all the nodes)                     |                  7
    listCoreV1Node                                 |  [sig-storage] Zone Support Verify PVC creation with compatible policy and datastore without any zones specified in the storage class fails (No shared datastores exist among all the nodes)                     |                  7
    readCoreV1Namespace                            |  [sig-storage] Zone Support Verify PVC creation with compatible policy and datastore without any zones specified in the storage class fails (No shared datastores exist among all the nodes)                     |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] Zone Support Verify PVC creation with incompatible datastore and zone combination specified in storage class fails                                                                                |                  7
    createCoreV1Namespace                          |  [sig-storage] Zone Support Verify PVC creation with incompatible datastore and zone combination specified in storage class fails                                                                                |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] Zone Support Verify PVC creation with incompatible datastore and zone combination specified in storage class fails                                                                                |                  7
    deleteCoreV1Namespace                          |  [sig-storage] Zone Support Verify PVC creation with incompatible datastore and zone combination specified in storage class fails                                                                                |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] Zone Support Verify PVC creation with incompatible datastore and zone combination specified in storage class fails                                                                                |                  7
    listCoreV1Node                                 |  [sig-storage] Zone Support Verify PVC creation with incompatible datastore and zone combination specified in storage class fails                                                                                |                  7
    readCoreV1Namespace                            |  [sig-storage] Zone Support Verify PVC creation with incompatible datastore and zone combination specified in storage class fails                                                                                |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] Zone Support Verify PVC creation with incompatible storage policy along with compatible zone and datastore combination specified in storage class fails                                           |                  7
    createCoreV1Namespace                          |  [sig-storage] Zone Support Verify PVC creation with incompatible storage policy along with compatible zone and datastore combination specified in storage class fails                                           |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] Zone Support Verify PVC creation with incompatible storage policy along with compatible zone and datastore combination specified in storage class fails                                           |                  7
    deleteCoreV1Namespace                          |  [sig-storage] Zone Support Verify PVC creation with incompatible storage policy along with compatible zone and datastore combination specified in storage class fails                                           |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] Zone Support Verify PVC creation with incompatible storage policy along with compatible zone and datastore combination specified in storage class fails                                           |                  7
    listCoreV1Node                                 |  [sig-storage] Zone Support Verify PVC creation with incompatible storage policy along with compatible zone and datastore combination specified in storage class fails                                           |                  7
    readCoreV1Namespace                            |  [sig-storage] Zone Support Verify PVC creation with incompatible storage policy along with compatible zone and datastore combination specified in storage class fails                                           |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] Zone Support Verify PVC creation with incompatible storagePolicy and zone combination specified in storage class fails                                                                            |                  7
    createCoreV1Namespace                          |  [sig-storage] Zone Support Verify PVC creation with incompatible storagePolicy and zone combination specified in storage class fails                                                                            |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] Zone Support Verify PVC creation with incompatible storagePolicy and zone combination specified in storage class fails                                                                            |                  7
    deleteCoreV1Namespace                          |  [sig-storage] Zone Support Verify PVC creation with incompatible storagePolicy and zone combination specified in storage class fails                                                                            |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] Zone Support Verify PVC creation with incompatible storagePolicy and zone combination specified in storage class fails                                                                            |                  7
    listCoreV1Node                                 |  [sig-storage] Zone Support Verify PVC creation with incompatible storagePolicy and zone combination specified in storage class fails                                                                            |                  7
    readCoreV1Namespace                            |  [sig-storage] Zone Support Verify PVC creation with incompatible storagePolicy and zone combination specified in storage class fails                                                                            |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] Zone Support Verify PVC creation with incompatible zone along with compatible storagePolicy and datastore combination specified in storage class fails                                            |                  7
    createCoreV1Namespace                          |  [sig-storage] Zone Support Verify PVC creation with incompatible zone along with compatible storagePolicy and datastore combination specified in storage class fails                                            |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] Zone Support Verify PVC creation with incompatible zone along with compatible storagePolicy and datastore combination specified in storage class fails                                            |                  7
    deleteCoreV1Namespace                          |  [sig-storage] Zone Support Verify PVC creation with incompatible zone along with compatible storagePolicy and datastore combination specified in storage class fails                                            |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] Zone Support Verify PVC creation with incompatible zone along with compatible storagePolicy and datastore combination specified in storage class fails                                            |                  7
    listCoreV1Node                                 |  [sig-storage] Zone Support Verify PVC creation with incompatible zone along with compatible storagePolicy and datastore combination specified in storage class fails                                            |                  7
    readCoreV1Namespace                            |  [sig-storage] Zone Support Verify PVC creation with incompatible zone along with compatible storagePolicy and datastore combination specified in storage class fails                                            |                  7
    createAuthorizationV1SubjectAccessReview       |  [sig-storage] Zone Support Verify PVC creation with invalid zone specified in storage class fails                                                                                                               |                  7
    createCoreV1Namespace                          |  [sig-storage] Zone Support Verify PVC creation with invalid zone specified in storage class fails                                                                                                               |                  7
    createRbacAuthorizationV1NamespacedRoleBinding |  [sig-storage] Zone Support Verify PVC creation with invalid zone specified in storage class fails                                                                                                               |                  7
    deleteCoreV1Namespace                          |  [sig-storage] Zone Support Verify PVC creation with invalid zone specified in storage class fails                                                                                                               |                  7
    listCoreV1NamespacedServiceAccount             |  [sig-storage] Zone Support Verify PVC creation with invalid zone specified in storage class fails                                                                                                               |                  7
    listCoreV1Node                                 |  [sig-storage] Zone Support Verify PVC creation with invalid zone specified in storage class fails                                                                                                               |                  7
    readCoreV1Namespace                            |  [sig-storage] Zone Support Verify PVC creation with invalid zone specified in storage class fails                                                                                                               |                  7
   (776 rows)

   #+end_src

** List distinct endpoints
Now we want to list the endpoints and the tests that hit them, When we have this, we can do an except join on these two tables to see tests that hit a small amount of endpoints, and these endpoints are hit by a small amount of tests.
   #+NAME: List Low Tested Endpoints, pt 1
   #+begin_src sql-mode
     WITH stable_endpoints AS (
     SELECT DISTINCT 
          COUNT(distinct ae.useragent) FILTER(where ae.operation_id = ae.operation_id) as distinct_tests,
            ae.operation_id
            FROM
            audit_event ae
            JOIN endpoint_coverage ec on (ae.operation_id = ec.operation_id)
            WHERE
            useragent LIKE 'e2e.test%'
            AND ae.job != 'live'
            AND ec.level = 'stable'
      GROUP BY ae.operation_id
      ORDER BY operation_id
     )       
     SELECT
       operation_id
       FROM
           stable_endpoints
           WHERE distinct_tests < 5
         ;

   #+end_src

   #+RESULTS: List Low Tested Endpoints, pt 1
   #+begin_src sql-mode
                                operation_id                              
   -----------------------------------------------------------------------
    createApiextensionsV1CustomResourceDefinition
    createApiregistrationV1APIService
    createAuthenticationV1TokenReview
    createAuthorizationV1SelfSubjectAccessReview
    createCoordinationV1NamespacedLease
    createCoreV1NamespacedLimitRange
    createCoreV1NamespacedPodTemplate
    createSchedulingV1PriorityClass
    deleteAdmissionregistrationV1CollectionMutatingWebhookConfiguration
    deleteAdmissionregistrationV1CollectionValidatingWebhookConfiguration
    deleteApiextensionsV1CollectionCustomResourceDefinition
    deleteApiextensionsV1CustomResourceDefinition
    deleteApiregistrationV1APIService
    deleteAppsV1NamespacedReplicaSet
    deleteBatchV1NamespacedJob
    deleteCoordinationV1CollectionNamespacedLease
    deleteCoordinationV1NamespacedLease
    deleteCoreV1NamespacedLimitRange
    deleteCoreV1NamespacedResourceQuota
    deleteSchedulingV1PriorityClass
    getAdmissionregistrationAPIGroup
    getAdmissionregistrationV1APIResources
    getApiextensionsAPIGroup
    getApiextensionsV1APIResources
    getApiregistrationV1APIResources
    getAppsV1APIResources
    getAuthenticationV1APIResources
    getAuthorizationV1APIResources
    getAutoscalingV1APIResources
    getBatchV1APIResources
    getCoordinationV1APIResources
    getCoreAPIVersions
    getCoreV1APIResources
    getNetworkingV1APIResources
    getRbacAuthorizationV1APIResources
    getSchedulingV1APIResources
    getStorageV1APIResources
    listAdmissionregistrationV1MutatingWebhookConfiguration
    listAdmissionregistrationV1ValidatingWebhookConfiguration
    listApiextensionsV1CustomResourceDefinition
    listAppsV1NamespacedDaemonSet
    listCoordinationV1NamespacedLease
    listCoreV1Namespace
    listCoreV1NamespacedLimitRange
    listCoreV1NamespacedPodTemplate
    listCoreV1NamespacedSecret
    listCoreV1PodForAllNamespaces
    logFileListHandler
    patchAdmissionregistrationV1MutatingWebhookConfiguration
    patchAdmissionregistrationV1ValidatingWebhookConfiguration
    patchApiextensionsV1CustomResourceDefinition
    patchApiextensionsV1CustomResourceDefinitionStatus
    patchCoordinationV1NamespacedLease
    patchCoreV1NamespacedConfigMap
    patchCoreV1NamespacedPod
    patchCoreV1NamespacedPodStatus
    patchCoreV1Node
    readAdmissionregistrationV1MutatingWebhookConfiguration
    readAdmissionregistrationV1ValidatingWebhookConfiguration
    readApiextensionsV1CustomResourceDefinition
    readApiextensionsV1CustomResourceDefinitionStatus
    readApiregistrationV1APIService
    readAppsV1NamespacedReplicaSet
    readAppsV1NamespacedStatefulSetScale
    readCoordinationV1NamespacedLease
    readCoreV1NamespacedLimitRange
    readCoreV1NamespacedReplicationControllerScale
    readCoreV1NamespacedSecret
    readCoreV1NamespacedServiceAccount
    replaceAdmissionregistrationV1MutatingWebhookConfiguration
    replaceAdmissionregistrationV1ValidatingWebhookConfiguration
    replaceApiextensionsV1CustomResourceDefinition
    replaceApiextensionsV1CustomResourceDefinitionStatus
    replaceAppsV1NamespacedReplicaSet
    replaceAppsV1NamespacedStatefulSetScale
    replaceCoordinationV1NamespacedLease
    replaceCoreV1NamespacedLimitRange
    replaceCoreV1NamespacedReplicationController
    replaceCoreV1NamespacedReplicationControllerScale
    replaceCoreV1NamespacedResourceQuota
    replaceCoreV1NamespacedSecret
    replaceCoreV1NamespacedServiceAccount
    replaceCoreV1Node
    replaceCoreV1NodeStatus
   (84 rows)

   #+end_src

   
   Now we will list the same # of distinctly tested endpoints, but grabbing the test that hits them.  We cannot do it in the above query, because it will create too many duplicate rows.  We also wanna limit the audit events we look at, so we are not seeing any general hit.
   
   #+NAME: List Low Tested Endpoints
   #+begin_src sql-mode
     WITH stable_endpoints AS (
     SELECT
          COUNT(distinct ae.useragent) FILTER(where ae.operation_id = ae.operation_id) as distinct_tests,
            ae.operation_id
            FROM
            audit_event ae
            JOIN endpoint_coverage ec on (ae.operation_id = ec.operation_id)
            WHERE
            useragent LIKE 'e2e.test%'
            AND ae.job != 'live'
            AND ec.level = 'stable'
            GROUP BY ae.operation_id
     )
     SELECT DISTINCT
       stable_endpoints.operation_id,
       split_part(ae.useragent, '--', 2) as test,
       distinct_tests
       FROM
           stable_endpoints
           JOIN
           audit_event ae on (ae.operation_id = stable_endpoints.operation_id)
           -- WHERE stable_endpoints.operation_id = 'createAuthenticationV1TokenReview'
           WHERE distinct_tests < 5
            AND ae.useragent like 'e2e.test%'
            ORDER BY operation_id
            ;
   #+end_src

   #+RESULTS: List Low Tested Endpoints
   #+begin_src sql-mode
                                operation_id                              |                                                                                    test                                                                                    | distinct_tests 
   -----------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------
    createApiextensionsV1CustomResourceDefinition                         |                                                                                                                                                                            |              1
    createApiregistrationV1APIService                                     |                                                                                                                                                                            |              1
    createAuthenticationV1TokenReview                                     |  [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]                                                                                             |              1
    createAuthorizationV1SelfSubjectAccessReview                          |  [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]                       |              1
    createCoordinationV1NamespacedLease                                   |  [k8s.io] Lease lease API should be available [Conformance]                                                                                                                |              1
    createCoreV1NamespacedLimitRange                                      |  [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied.                                                           |              1
    createCoreV1NamespacedPodTemplate                                     |  [sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls                                                                  |              2
    createCoreV1NamespacedPodTemplate                                     |  [sig-api-machinery] Servers with support for Table transformation should return chunks of table results for list calls                                                    |              2
    createSchedulingV1PriorityClass                                       |  [sig-scheduling] PreemptionExecutionPath runs ReplicaSets to verify preemption running path                                                                               |              1
    deleteAdmissionregistrationV1CollectionMutatingWebhookConfiguration   |  [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]                                                        |              1
    deleteAdmissionregistrationV1CollectionValidatingWebhookConfiguration |  [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]                                                      |              1
    deleteApiextensionsV1CollectionCustomResourceDefinition               |                                                                                                                                                                            |              1
    deleteApiextensionsV1CustomResourceDefinition                         |                                                                                                                                                                            |              1
    deleteApiregistrationV1APIService                                     |                                                                                                                                                                            |              1
    deleteAppsV1NamespacedReplicaSet                                      |  [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]                                                      |              1
    deleteBatchV1NamespacedJob                                            |  [sig-apps] CronJob should remove from active list jobs that have been deleted                                                                                             |              4
    deleteBatchV1NamespacedJob                                            |  [sig-apps] Job should delete a job [Conformance]                                                                                                                          |              4
    deleteBatchV1NamespacedJob                                            |  [sig-apps] Job should remove pods when job is deleted                                                                                                                     |              4
    deleteBatchV1NamespacedJob                                            |  [sig-cli] Kubectl client Simple pod should support inline execution and attach                                                                                            |              4
    deleteCoordinationV1CollectionNamespacedLease                         |  [k8s.io] Lease lease API should be available [Conformance]                                                                                                                |              1
    deleteCoordinationV1NamespacedLease                                   |  [k8s.io] Lease lease API should be available [Conformance]                                                                                                                |              1
    deleteCoreV1NamespacedLimitRange                                      |  [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied.                                                           |              1
    deleteCoreV1NamespacedResourceQuota                                   |  [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]                                                                        |              2
    deleteCoreV1NamespacedResourceQuota                                   |  [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a custom resource.                                                                |              2
    deleteSchedulingV1PriorityClass                                       |  [sig-scheduling] PreemptionExecutionPath runs ReplicaSets to verify preemption running path                                                                               |              1
    getAdmissionregistrationAPIGroup                                      |  [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]                                      |              1
    getAdmissionregistrationV1APIResources                                |  [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]                                      |              3
    getAdmissionregistrationV1APIResources                                |  [sig-api-machinery] Aggregator Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]                                            |              3
    getAdmissionregistrationV1APIResources                                |  [sig-network] Services should create endpoints for unready pods                                                                                                           |              3
    getApiextensionsAPIGroup                                              |  [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance] |              1
    getApiextensionsV1APIResources                                        |  [sig-api-machinery] Aggregator Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]                                            |              3
    getApiextensionsV1APIResources                                        |  [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance] |              3
    getApiextensionsV1APIResources                                        |  [sig-network] Services should create endpoints for unready pods                                                                                                           |              3
    getApiregistrationV1APIResources                                      |  [sig-api-machinery] Aggregator Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]                                            |              2
    getApiregistrationV1APIResources                                      |  [sig-network] Services should create endpoints for unready pods                                                                                                           |              2
    getAppsV1APIResources                                                 |  [sig-api-machinery] Aggregator Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]                                            |              2
    getAppsV1APIResources                                                 |  [sig-network] Services should create endpoints for unready pods                                                                                                           |              2
    getAuthenticationV1APIResources                                       |  [sig-api-machinery] Aggregator Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]                                            |              2
    getAuthenticationV1APIResources                                       |  [sig-network] Services should create endpoints for unready pods                                                                                                           |              2
    getAuthorizationV1APIResources                                        |  [sig-api-machinery] Aggregator Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]                                            |              2
    getAuthorizationV1APIResources                                        |  [sig-network] Services should create endpoints for unready pods                                                                                                           |              2
    getAutoscalingV1APIResources                                          |  [sig-api-machinery] Aggregator Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]                                            |              2
    getAutoscalingV1APIResources                                          |  [sig-network] Services should create endpoints for unready pods                                                                                                           |              2
    getBatchV1APIResources                                                |  [sig-api-machinery] Aggregator Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]                                            |              2
    getBatchV1APIResources                                                |  [sig-network] Services should create endpoints for unready pods                                                                                                           |              2
    getCoordinationV1APIResources                                         |  [sig-api-machinery] Aggregator Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]                                            |              2
    getCoordinationV1APIResources                                         |  [sig-network] Services should create endpoints for unready pods                                                                                                           |              2
    getCoreAPIVersions                                                    |  [sig-api-machinery] Aggregator Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]                                            |              3
    getCoreAPIVersions                                                    |  [sig-network] Networking should provide unchanging, static URL paths for kubernetes api services                                                                          |              3
    getCoreAPIVersions                                                    |  [sig-network] Services should create endpoints for unready pods                                                                                                           |              3
    getCoreV1APIResources                                                 |  [sig-api-machinery] Aggregator Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]                                            |              2
    getCoreV1APIResources                                                 |  [sig-network] Services should create endpoints for unready pods                                                                                                           |              2
    getNetworkingV1APIResources                                           |  [sig-api-machinery] Aggregator Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]                                            |              2
    getNetworkingV1APIResources                                           |  [sig-network] Services should create endpoints for unready pods                                                                                                           |              2
    getRbacAuthorizationV1APIResources                                    |  [sig-api-machinery] Aggregator Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]                                            |              2
    getRbacAuthorizationV1APIResources                                    |  [sig-network] Services should create endpoints for unready pods                                                                                                           |              2
    getSchedulingV1APIResources                                           |  [sig-api-machinery] Aggregator Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]                                            |              2
    getSchedulingV1APIResources                                           |  [sig-network] Services should create endpoints for unready pods                                                                                                           |              2
    getStorageV1APIResources                                              |  [sig-api-machinery] Aggregator Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]                                            |              2
    getStorageV1APIResources                                              |  [sig-network] Services should create endpoints for unready pods                                                                                                           |              2
    listAdmissionregistrationV1MutatingWebhookConfiguration               |  [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]                                                        |              1
    listAdmissionregistrationV1ValidatingWebhookConfiguration             |  [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]                                                      |              1
    listApiextensionsV1CustomResourceDefinition                           |                                                                                                                                                                            |              1
    listAppsV1NamespacedDaemonSet                                         |                                                                                                                                                                            |              1
    listCoordinationV1NamespacedLease                                     |  [k8s.io] Lease lease API should be available [Conformance]                                                                                                                |              1
    listCoreV1Namespace                                                   |  [sig-storage] PersistentVolumes GCEPD should test that deleting the Namespace of a PVC and Pod causes the successful detach of Persistent Disk                            |              1
    listCoreV1NamespacedLimitRange                                        |  [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied.                                                           |              1
    listCoreV1NamespacedPodTemplate                                       |  [sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls                                                                  |              2
    listCoreV1NamespacedPodTemplate                                       |  [sig-api-machinery] Servers with support for Table transformation should return chunks of table results for list calls                                                    |              2
    listCoreV1NamespacedSecret                                            |  [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]                                                           |              1
    listCoreV1PodForAllNamespaces                                         |  [k8s.io] [sig-node] NodeProblemDetector [DisabledForLargeClusters] should run without error                                                                               |              1
    logFileListHandler                                                    |  [sig-network] Networking should provide unchanging, static URL paths for kubernetes api services                                                                          |              1
    patchAdmissionregistrationV1MutatingWebhookConfiguration              |  [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]                                             |              1
    patchAdmissionregistrationV1ValidatingWebhookConfiguration            |  [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]                                           |              1
    patchApiextensionsV1CustomResourceDefinition                          |                                                                                                                                                                            |              1
    patchApiextensionsV1CustomResourceDefinitionStatus                    |                                                                                                                                                                            |              1
    patchCoordinationV1NamespacedLease                                    |  [k8s.io] Lease lease API should be available [Conformance]                                                                                                                |              1
    patchCoreV1NamespacedConfigMap                                        |  [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]                                            |              1
    patchCoreV1NamespacedPod                                              |  [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]                                                                            |              2
    patchCoreV1NamespacedPod                                              |  [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]         |              2
    patchCoreV1NamespacedPodStatus                                        |  [k8s.io] Pods should support pod readiness gates [NodeFeature:PodReadinessGate]                                                                                           |              1
    patchCoreV1Node                                                       |  [k8s.io] [sig-node] kubelet [k8s.io] [sig-node] Clean up pods on node kubelet should be able to delete 10 pods per node in 1m0s.                                          |              2
    patchCoreV1Node                                                       |  [sig-storage] Mounted volume expand Should verify mounted devices can be resized                                                                                          |              2
    readAdmissionregistrationV1MutatingWebhookConfiguration               |  [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]                                             |              1
    readAdmissionregistrationV1ValidatingWebhookConfiguration             |  [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]                                           |              1
    readApiextensionsV1CustomResourceDefinition                           |                                                                                                                                                                            |              1
    readApiextensionsV1CustomResourceDefinitionStatus                     |                                                                                                                                                                            |              1
    readApiregistrationV1APIService                                       |                                                                                                                                                                            |              1
    readAppsV1NamespacedReplicaSet                                        |  [sig-apps] Deployment deployment should support proportional scaling [Conformance]                                                                                        |              4
    readAppsV1NamespacedReplicaSet                                        |  [sig-apps] Deployment deployment should support rollover [Conformance]                                                                                                    |              4
    readAppsV1NamespacedReplicaSet                                        |  [sig-apps] ReplicaSet should surface a failure condition on a common issue like exceeded quota                                                                            |              4
    readAppsV1NamespacedReplicaSet                                        |  [sig-scheduling] PreemptionExecutionPath runs ReplicaSets to verify preemption running path                                                                               |              4
    readAppsV1NamespacedStatefulSetScale                                  |  [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]                                  |              1
    readCoordinationV1NamespacedLease                                     |  [k8s.io] Lease lease API should be available [Conformance]                                                                                                                |              3
    readCoordinationV1NamespacedLease                                     |  [k8s.io] NodeLease when the NodeLease feature is enabled the kubelet should create and update a lease in the kube-node-lease namespace                                    |              3
    readCoordinationV1NamespacedLease                                     |  [k8s.io] NodeLease when the NodeLease feature is enabled the kubelet should report node status infrequently                                                               |              3
    readCoreV1NamespacedLimitRange                                        |  [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied.                                                           |              1
    readCoreV1NamespacedReplicationControllerScale                        |  [sig-network] Services should create endpoints for unready pods                                                                                                           |              1
    readCoreV1NamespacedSecret                                            |  [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]                                                                                  |              2
    readCoreV1NamespacedSecret                                            |  [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]                                                                                             |              2
    readCoreV1NamespacedServiceAccount                                    |  [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]                                                                                  |              3
    readCoreV1NamespacedServiceAccount                                    |  [sig-auth] ServiceAccounts should ensure a single API token exists                                                                                                        |              3
    readCoreV1NamespacedServiceAccount                                    |  [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]                                                                                             |              3
    replaceAdmissionregistrationV1MutatingWebhookConfiguration            |  [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]                                             |              1
    replaceAdmissionregistrationV1ValidatingWebhookConfiguration          |  [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]                                           |              1
    replaceApiextensionsV1CustomResourceDefinition                        |                                                                                                                                                                            |              1
    replaceApiextensionsV1CustomResourceDefinitionStatus                  |                                                                                                                                                                            |              1
    replaceAppsV1NamespacedReplicaSet                                     |  [sig-apps] ReplicaSet should surface a failure condition on a common issue like exceeded quota                                                                            |              1
    replaceAppsV1NamespacedStatefulSetScale                               |  [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]                                  |              1
    replaceCoordinationV1NamespacedLease                                  |  [k8s.io] Lease lease API should be available [Conformance]                                                                                                                |              1
    replaceCoreV1NamespacedLimitRange                                     |  [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied.                                                           |              1
    replaceCoreV1NamespacedReplicationController                          |  [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]                                                   |              2
    replaceCoreV1NamespacedReplicationController                          |  [sig-network] Services should create endpoints for unready pods                                                                                                           |              2
    replaceCoreV1NamespacedReplicationControllerScale                     |  [sig-network] Services should create endpoints for unready pods                                                                                                           |              1
    replaceCoreV1NamespacedResourceQuota                                  |  [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]                                                                        |              2
    replaceCoreV1NamespacedResourceQuota                                  |  [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a custom resource.                                                                |              2
    replaceCoreV1NamespacedSecret                                         |  [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]                                                             |              2
    replaceCoreV1NamespacedSecret                                         |  [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]                                                                      |              2
    replaceCoreV1NamespacedServiceAccount                                 |  [sig-auth] ServiceAccounts should ensure a single API token exists                                                                                                        |              1
    replaceCoreV1Node                                                     |  [k8s.io] [sig-node] kubelet [k8s.io] [sig-node] Clean up pods on node kubelet should be able to delete 10 pods per node in 1m0s.                                          |              1
    replaceCoreV1NodeStatus                                               |  [sig-scheduling] PreemptionExecutionPath runs ReplicaSets to verify preemption running path                                                                               |              1
   (121 rows)

   #+end_src
   
   Success!

** Combinee and Except
   
   So now we want to combine these two tables.  We ahve a list of tests that hit a small amount of endpoints, and the endpoints they hit.  We also have a list of endpoints that are hit by a small amount of tests, and the tests they hit.
   So I _think_ we can just select tests from the top and do an intersect clause for the endpoints at the bottom.  This would return the rows that are in the top and bottom.
   
   #+NAME: focused tests and endpoints
   #+begin_src sql-mode
     WITH tests as (
       SELECT DISTINCT
         COUNT(distinct operation_id) FILTER(where useragent = audit_event.useragent) as distinct_endpoints,
         split_part(useragent, '--', 2) as test,
         useragent
         FROM
             audit_event
        WHERE
              useragent LIKE 'e2e.test%'
          AND job != 'live'
        GROUP BY useragent
     ), stable_endpoints AS (
     SELECT
          COUNT(distinct ae.useragent) FILTER(where ae.operation_id = ae.operation_id) as distinct_tests,
            ae.operation_id
            FROM
            audit_event ae
            JOIN endpoint_coverage ec on (ae.operation_id = ec.operation_id)
            WHERE
            useragent LIKE 'e2e.test%'
            AND ae.job != 'live'
            AND ec.level = 'stable'
            GROUP BY ae.operation_id
     )
    
     (SELECT DISTINCT
       audit_event.operation_id,
       test
       FROM tests
         JOIN
         audit_event on (audit_event.useragent = tests.useragent)
      WHERE distinct_endpoints < 10)
       INTERSECT
     (SELECT DISTINCT
       stable_endpoints.operation_id,
       split_part(ae.useragent, '--', 2) as test
       FROM
           stable_endpoints
           JOIN
           audit_event ae on (ae.operation_id = stable_endpoints.operation_id)
           -- WHERE stable_endpoints.operation_id = 'createAuthenticationV1TokenReview'
           WHERE distinct_tests < 5
            AND ae.useragent like 'e2e.test%')
            ;
   #+end_src

   #+RESULTS: focused tests and endpoints
   #+begin_src sql-mode
                    operation_id                 |                                                                         test                                                                         
   ----------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------
    readCoordinationV1NamespacedLease            |  [k8s.io] NodeLease when the NodeLease feature is enabled the kubelet should create and update a lease in the kube-node-lease namespace
    createCoreV1NamespacedPodTemplate            |  [sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls
    createCoreV1NamespacedPodTemplate            |  [sig-api-machinery] Servers with support for Table transformation should return chunks of table results for list calls
    createAuthorizationV1SelfSubjectAccessReview |  [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]
    listCoreV1PodForAllNamespaces                |  [k8s.io] [sig-node] NodeProblemDetector [DisabledForLargeClusters] should run without error
    readCoordinationV1NamespacedLease            |  [k8s.io] NodeLease when the NodeLease feature is enabled the kubelet should report node status infrequently
    listCoreV1NamespacedPodTemplate              |  [sig-api-machinery] Servers with support for Table transformation should return chunks of table results for list calls
    listCoreV1NamespacedPodTemplate              |  [sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls
   (8 rows)

   #+end_src
   
   This might be great.  Let's look through these 8 results.  For each one, we want to make sure the test is hitting less than 10 endpionts overall, and that the endpoint is being hit by less than 5 tests.
   The numbers are slightly arbitrary.  14 endpoints is the average for a test, and so we are looking at tests whose distinct endpoint is below that.
   The average for endpoints is gonna be a bit ridiculous, since some are hit by all 830 tests.  So we picked a small number that still returns over 100 results.
   
   We can take a look at a couple sample  endpoint in one block and their test in another.
*** readCoordinationV1NamespacedLease and its Test
    #+begin_src sql-mode
      SELECT DISTINCT
          operation_id,
          split_part(useragent, '--', 2) as test
          FROM
              audit_event 
              WHERE operation_id = 'readCoordinationV1NamespacedLease'
               AND useragent like 'e2e.test%'
               ;
    #+end_src

    #+RESULTS:
    #+begin_src sql-mode
               operation_id            |                                                                  test                                                                   
    -----------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------
     readCoordinationV1NamespacedLease |  [k8s.io] Lease lease API should be available [Conformance]
     readCoordinationV1NamespacedLease |  [k8s.io] NodeLease when the NodeLease feature is enabled the kubelet should create and update a lease in the kube-node-lease namespace
     readCoordinationV1NamespacedLease |  [k8s.io] NodeLease when the NodeLease feature is enabled the kubelet should report node status infrequently
    (3 rows)

    #+end_src
   
    #+begin_src sql-mode
      SELECT DISTINCT
        audit_event.operation_id,
        split_part(useragent, '--', 2) as test
      FROM
          audit_event 
       WHERE useragent like '%[k8s.io] NodeLease when the NodeLease feature is enabled the kubelet should create and update a lease in the kube-node-lease namespace'
             ;


    #+end_src

    #+RESULTS:
    #+begin_src sql-mode
                      operation_id                  |                                                                  test                                                                   
    ------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------
     createAuthorizationV1SubjectAccessReview       |  [k8s.io] NodeLease when the NodeLease feature is enabled the kubelet should create and update a lease in the kube-node-lease namespace
     createCoreV1Namespace                          |  [k8s.io] NodeLease when the NodeLease feature is enabled the kubelet should create and update a lease in the kube-node-lease namespace
     createRbacAuthorizationV1NamespacedRoleBinding |  [k8s.io] NodeLease when the NodeLease feature is enabled the kubelet should create and update a lease in the kube-node-lease namespace
     deleteCoreV1Namespace                          |  [k8s.io] NodeLease when the NodeLease feature is enabled the kubelet should create and update a lease in the kube-node-lease namespace
     listCoreV1NamespacedServiceAccount             |  [k8s.io] NodeLease when the NodeLease feature is enabled the kubelet should create and update a lease in the kube-node-lease namespace
     listCoreV1Node                                 |  [k8s.io] NodeLease when the NodeLease feature is enabled the kubelet should create and update a lease in the kube-node-lease namespace
     readCoordinationV1NamespacedLease              |  [k8s.io] NodeLease when the NodeLease feature is enabled the kubelet should create and update a lease in the kube-node-lease namespace
     readCoreV1Namespace                            |  [k8s.io] NodeLease when the NodeLease feature is enabled the kubelet should create and update a lease in the kube-node-lease namespace
    (8 rows)

    #+end_src
   
    This is making sense.  We have a test that hits a small amount of endpoints, and an endpoint that is hit by a small amount of tests.  There are likely some basic discovery endpoints, but then the core of the test is around what nodeLease can do.
   
   

*** createCoreV1NamespacedPodTemplate and its Test
    #+begin_src sql-mode
      SELECT DISTINCT
          operation_id,
          split_part(useragent, '--', 2) as test
          FROM
              audit_event 
              WHERE operation_id = 'createCoreV1NamespacedPodTemplate'
               AND useragent like 'e2e.test%'
               ;
    #+end_src

    #+RESULTS:
    #+begin_src sql-mode
               operation_id            |                                                          test                                                           
    -----------------------------------+-------------------------------------------------------------------------------------------------------------------------
     createCoreV1NamespacedPodTemplate |  [sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls
     createCoreV1NamespacedPodTemplate |  [sig-api-machinery] Servers with support for Table transformation should return chunks of table results for list calls
    (2 rows)

    #+end_src

   
    #+begin_src sql-mode
      SELECT DISTINCT
        audit_event.operation_id,
        split_part(useragent, '--', 2) as test
      FROM
          audit_event 
       WHERE useragent like '%[sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls'
       OR useragent like '%[sig-api-machinery] Servers with support for Table transformation should return chunks of table results for list calls'
        ORDER BY test
             ;


    #+end_src

    #+RESULTS:
    #+begin_src sql-mode
                      operation_id                  |                                                          test                                                           
    ------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------
     createAuthorizationV1SubjectAccessReview       |  [sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls
     createCoreV1Namespace                          |  [sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls
     createCoreV1NamespacedPodTemplate              |  [sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls
     createRbacAuthorizationV1NamespacedRoleBinding |  [sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls
     deleteCoreV1Namespace                          |  [sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls
     listCoreV1NamespacedPodTemplate                |  [sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls
     listCoreV1NamespacedServiceAccount             |  [sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls
     listCoreV1Node                                 |  [sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls
     readCoreV1Namespace                            |  [sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls
     createAuthorizationV1SubjectAccessReview       |  [sig-api-machinery] Servers with support for Table transformation should return chunks of table results for list calls
     createCoreV1Namespace                          |  [sig-api-machinery] Servers with support for Table transformation should return chunks of table results for list calls
     createCoreV1NamespacedPodTemplate              |  [sig-api-machinery] Servers with support for Table transformation should return chunks of table results for list calls
     createRbacAuthorizationV1NamespacedRoleBinding |  [sig-api-machinery] Servers with support for Table transformation should return chunks of table results for list calls
     deleteCoreV1Namespace                          |  [sig-api-machinery] Servers with support for Table transformation should return chunks of table results for list calls
     listCoreV1NamespacedPodTemplate                |  [sig-api-machinery] Servers with support for Table transformation should return chunks of table results for list calls
     listCoreV1NamespacedServiceAccount             |  [sig-api-machinery] Servers with support for Table transformation should return chunks of table results for list calls
     listCoreV1Node                                 |  [sig-api-machinery] Servers with support for Table transformation should return chunks of table results for list calls
     readCoreV1Namespace                            |  [sig-api-machinery] Servers with support for Table transformation should return chunks of table results for list calls
    (18 rows)

    #+end_src

   
 endpoint hit by two endpoints, these endoints only hit   9 tests each.
   


 overall it's looking good.


** Combinee and Except With only non-conformance tests.
   
   So now we want to combine these two tables.  We ahve a list of tests that hit a small amount of endpoints, and the endpoints they hit.  We also have a list of endpoints that are hit by a small amount of tests, and the tests they hit.
   So I _think_ we can just select tests from the top and do an intersect clause for the endpoints at the bottom.  This would return the rows that are in the top and bottom.
   
   
   #+NAME: focused non-conformance tests and endpoints
   #+begin_src sql-mode
     WITH tests as (
       SELECT DISTINCT
         COUNT(distinct operation_id) FILTER(where useragent = audit_event.useragent) as distinct_endpoints,
         split_part(useragent, '--', 2) as test,
         useragent
         FROM
             audit_event
        WHERE
              useragent LIKE 'e2e.test%'
          AND job != 'live'
        GROUP BY useragent
     ), stable_endpoints AS (
     SELECT
          COUNT(distinct ae.useragent) FILTER(where ae.operation_id = ae.operation_id) as distinct_tests,
            ae.operation_id
            FROM
            audit_event ae
            JOIN endpoint_coverage ec on (ae.operation_id = ec.operation_id)
            WHERE
            useragent LIKE 'e2e.test%'
            AND ae.job != 'live'
            AND ec.level = 'stable'
            AND ec.conf_hits = 0 
            GROUP BY ae.operation_id
     )

     (SELECT DISTINCT
       audit_event.operation_id,
       test
       FROM tests
         JOIN
         audit_event on (audit_event.useragent = tests.useragent)
       WHERE distinct_endpoints < 14
       AND test not like '%[Conformance]%'
     )
       INTERSECT
     (SELECT DISTINCT
       stable_endpoints.operation_id,
       split_part(ae.useragent, '--', 2) as test
       FROM
           stable_endpoints
           JOIN
           audit_event ae on (ae.operation_id = stable_endpoints.operation_id)
           -- WHERE stable_endpoints.operation_id = 'createAuthenticationV1TokenReview'
           WHERE distinct_tests < 10
            AND ae.useragent like 'e2e.test%')
          ORDER BY test
            ;
   #+end_src

   #+RESULTS: focused non-conformance tests and endpoints
   #+begin_src sql-mode
                  operation_id                |                                                                              test                                                                              
   -------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------
    readCoordinationV1NamespacedLease         |  [k8s.io] NodeLease when the NodeLease feature is enabled the kubelet should create and update a lease in the kube-node-lease namespace
    readCoordinationV1NamespacedLease         |  [k8s.io] NodeLease when the NodeLease feature is enabled the kubelet should report node status infrequently
    patchCoreV1NamespacedPodStatus            |  [k8s.io] Pods should support pod readiness gates [NodeFeature:PodReadinessGate]
    listCoreV1PodForAllNamespaces             |  [k8s.io] [sig-node] NodeProblemDetector [DisabledForLargeClusters] should run without error
    listBatchV1NamespacedJob                  |  [sig-api-machinery] Garbage collector should delete jobs and pods created by cronjob
    replaceCoreV1NamespacedResourceQuota      |  [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a custom resource.
    deleteCoreV1NamespacedResourceQuota       |  [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a custom resource.
    listCoreV1NamespacedPodTemplate           |  [sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls
    createCoreV1NamespacedPodTemplate         |  [sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls
    listCoreV1NamespacedPodTemplate           |  [sig-api-machinery] Servers with support for Table transformation should return chunks of table results for list calls
    createCoreV1NamespacedPodTemplate         |  [sig-api-machinery] Servers with support for Table transformation should return chunks of table results for list calls
    listBatchV1NamespacedJob                  |  [sig-apps] CronJob should delete successful/failed finished jobs with limit of one job
    listBatchV1NamespacedJob                  |  [sig-apps] CronJob should not emit unexpected warnings
    listBatchV1NamespacedJob                  |  [sig-apps] CronJob should replace jobs when ReplaceConcurrent
    listBatchV1NamespacedJob                  |  [sig-apps] CronJob should schedule multiple jobs concurrently
    createCoreV1NamespacedPodEviction         |  [sig-apps] DisruptionController evictions: enough pods, absolute => should allow an eviction
    createCoreV1NamespacedPodEviction         |  [sig-apps] DisruptionController evictions: enough pods, replicaSet, percentage => should allow an eviction
    createCoreV1NamespacedPodEviction         |  [sig-apps] DisruptionController evictions: maxUnavailable allow single eviction, percentage => should allow an eviction
    createCoreV1NamespacedPodEviction         |  [sig-apps] DisruptionController evictions: maxUnavailable deny evictions, integer => should not allow an eviction
    createCoreV1NamespacedPodEviction         |  [sig-apps] DisruptionController evictions: no PDB => should allow an eviction
    createCoreV1NamespacedPodEviction         |  [sig-apps] DisruptionController evictions: too few pods, absolute => should not allow an eviction
    createCoreV1NamespacedPodEviction         |  [sig-apps] DisruptionController evictions: too few pods, replicaSet, percentage => should not allow an eviction
    createCoreV1NamespacedPodEviction         |  [sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it
    createBatchV1NamespacedJob                |  [sig-apps] Job should fail to exceed backoffLimit
    createBatchV1NamespacedJob                |  [sig-apps] Job should fail when exceeds active deadline
    deleteBatchV1NamespacedJob                |  [sig-apps] Job should remove pods when job is deleted
    createBatchV1NamespacedJob                |  [sig-apps] Job should remove pods when job is deleted
    createBatchV1NamespacedJob                |  [sig-apps] Job should run a job to completion when tasks sometimes fail and are not locally restarted
    createBatchV1NamespacedJob                |  [sig-apps] Job should run a job to completion when tasks succeed
    readAppsV1NamespacedReplicaSet            |  [sig-apps] ReplicaSet should surface a failure condition on a common issue like exceeded quota
    replaceAppsV1NamespacedReplicaSet         |  [sig-apps] ReplicaSet should surface a failure condition on a common issue like exceeded quota
    createBatchV1NamespacedJob                |  [sig-auth] Metadata Concealment should run a check-metadata-concealment job to completion
    replaceCoreV1NamespacedServiceAccount     |  [sig-auth] ServiceAccounts should ensure a single API token exists
    readCoreV1NamespacedServiceAccount        |  [sig-auth] ServiceAccounts should ensure a single API token exists
    readCoreV1NamespacedConfigMap             |  [sig-autoscaling] DNS horizontal autoscaling [DisabledForLargeClusters] kube-dns-autoscaler should scale kube-dns pods in both nonfaulty and faulty scenarios
    listCoreV1NamespacedReplicationController |  [sig-cli] Kubectl client Kubectl apply should apply a new configuration to an existing RC
    deleteBatchV1NamespacedJob                |  [sig-cli] Kubectl client Simple pod should support inline execution and attach
    readCoreV1NamespacedEndpoints             |  [sig-network] Firewall rule should have correct firewall rules for e2e cluster
    logFileListHandler                        |  [sig-network] Networking should provide unchanging, static URL paths for kubernetes api services
    getAPIVersions                            |  [sig-network] Networking should provide unchanging, static URL paths for kubernetes api services
    getCoreAPIVersions                        |  [sig-network] Networking should provide unchanging, static URL paths for kubernetes api services
    readCoreV1NamespacedEndpoints             |  [sig-network] Services should allow pods to hairpin back to themselves through services
    readCoreV1NamespacedConfigMap             |  [sig-node] ConfigMap should update ConfigMap successfully
   (43 rows)

   #+end_src

   #+RESULTS: focused tests and endpoints
   #+begin_src sql-mode
                    operation_id                 |                                                                         test                                                                         
   ----------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------
    readCoordinationV1NamespacedLease            |  [k8s.io] NodeLease when the NodeLease feature is enabled the kubelet should create and update a lease in the kube-node-lease namespace
    createCoreV1NamespacedPodTemplate            |  [sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls
    createCoreV1NamespacedPodTemplate            |  [sig-api-machinery] Servers with support for Table transformation should return chunks of table results for list calls
    createAuthorizationV1SelfSubjectAccessReview |  [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]
    listCoreV1PodForAllNamespaces                |  [k8s.io] [sig-node] NodeProblemDetector [DisabledForLargeClusters] should run without error
    readCoordinationV1NamespacedLease            |  [k8s.io] NodeLease when the NodeLease feature is enabled the kubelet should report node status infrequently
    listCoreV1NamespacedPodTemplate              |  [sig-api-machinery] Servers with support for Table transformation should return chunks of table results for list calls
    listCoreV1NamespacedPodTemplate              |  [sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls
   (8 rows)

   #+end_src
   
* Conclusions | Next Steps
* Footnotes
