# -*- ii: enabled; -*-
#+TITLE: Kind Cluster Setup
* TODO [0/7] Cluster Setup                                      :neverexport:
  :PROPERTIES:
  :LOGGING:  nil
  :END:
** TODO Connect to remote machine if wanted
*** ensure ssh-agent is running locally
You can read more about this, but basically ensure you have it working before you connect.
   #+begin_src tmate :session foo:hello :eval never-export
     # ssh-add -c ~/.ssh/path-to-my-key
     # will prompt for use and the following command should list your keys
     ssh-add -l
   #+end_src
*** forwards to the development env
You will likely leave this up and running just so you can use git push/pull and use a kubectl for the rest of your work.
   #+begin_src tmate :session foo:hello :eval never-export
     ssh -A $USER.ii.coop
   #+end_src
*** ensure ssh-agent socket is remotely working
   #+begin_src tmate :session foo:hello :eval never-export
     ssh-add -l
   #+end_src
** TODO Create a K8s cluster Running Kubemacs
   
[[file:~/cncf/apisnoop/deployment/k8s/kind-cluster-config.yaml::#%20kind-cluster-config.yaml][kind-cluster-config.yaml (enabling Dynamic Audit Logging)]]

   #+BEGIN_SRC tmate :eval never-export :session foo:cluster :tangle ../setup.sh
     export NS=ii
     export KUBEMACS_IMAGE=gcr.io/apisnoop/kubemacs:0.9.24
     # ensure current kind-cluster-config.yaml
     wget -c https://raw.githubusercontent.com/cncf/apisnoop/master/deployment/k8s/kind-cluster-config.yaml
     kind create cluster --name kind \
          --image kindest/node:v1.17.0@sha256:9512edae126da271b66b990b6fff768fbb7cd786c7d39e86bdf55906352fdf62 \
          --config kind-cluster-config.yaml
     # Populate the kind work node CRIs with the larger images before deployment
     docker pull $KUBEMACS_IMAGE # cache into docker socket
     kind load docker-image --nodes kind-worker $KUBEMACS_IMAGE # docker->kind
     # create a namespace / set default NS
     kubectl create ns $NS
     kubectl config set-context $(kubectl config current-context) --namespace=$NS
     # these two commands just ensure our image is cached and available quickly
     kubectl apply -k https://github.com/cncf/apisnoop/deployment/k8s/local
     kubectl wait --for=condition=Available deployment/kubemacs
     KUBEMACS_POD=$(kubectl get pod --selector=app=kubemacs -o name  | sed s:pod/::)
     kubectl exec -t -i $KUBEMACS_POD -- attach
   #+END_SRC

Alternatively the above generates a script that can be run on any kind host:

   #+begin_src tmate :eval never-export :session foo:cluster
     ssh -A $USER.ii.coop
     wget -c https://raw.githubusercontent.com/cncf/apisnoop/master/setup.sh
     chmod +x setup.sh
     # edit with your email address
     ./setup.sh
   #+end_src

** TODO Connect your local computer to remote computer
*** configure local .bashrc with merged KUBECONFIG
   #+begin_src tmate :session ii:local :eval never-export
      export KUBECONFIG=$KUBECONFIG:~/.kube/config:~/.kube/kind-config
   #+end_src
*** copy remote kind KUBECONFIG
   #+begin_src tmate :session ii:local :eval never-export
     scp $USER.ii.coop:.kube/config ~/.kube/kind-config
     kubectl config set clusters.kind-kind.server "https://$USER.ii.coop:6443"
   #+end_src
** TODO In a local OSC52 Compatible Terminal
   This needs to be run in an OSC52 compatible terminal like iTerm2, putty or
     xterm (libvte/gnome-terminals do not work)
   #+begin_src shell :eval nevel
     PODNAME=$(kubectl -n kubemacs get pod --selector=app=kubemacs -o name  | sed s:pod/::)
     kubectl exec -n kubemacs -t -i $PODNAME -- attach
   #+end_src

   #+RESULTS:
   #+begin_example
   #+end_example
* In Cluster

You should see an emacs session inside a tmate.
Upon connection, your local copy-paste buffer will contain a sharable ssh/web url for others to join.

Open up ~/apisnoop/org/tickets/mock-template.org and deploy tilt from within a 'right eye'

You can then visit these urls (replace hh with your username):

https://hh.ii.coop/coverage
https://hh.ii.coop/hasura/console
https://hh.ii.coop:10350 # tilt
