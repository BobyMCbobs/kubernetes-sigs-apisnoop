#+TITLE: APIsnoop
#+AUTHOR: ii team
#+DATE: 15 August 2019
#+INCLUDE: "config.org"
#+TODO: TODO(t) NEXT(n) IN-PROGRESS(i) BLOCKED(b) | TADA(d)
#+ARCHIVE: archive/meta.archive.org::
#+PROPERTY: header-args:sql-mode+ :results silent


* Purpose
* Welcome, ii dev!
If you're reading this org file, from within spacemacs, and expecting to do your work from within an org-file...then welcome, fellow ii dev (or honorary ii dev)!

To ensure you're set up properly, you want to run down this checklist:
** TADA [0%] Ready to Work!
    :PROPERTIES:
    :RESET_CHECK_BOXES: t
    :LOGGING: nil
    :END:
- [ ] Ensure you are reading this, and working, from within a tmate session on sharing.io.
  how do to do this is outside scope of this org, but ensure you've ssh'ed into sharing.io, and started a tmate session.

- [ ] Start up dev environment with the ii env variables
  : open a new tmate pane (ctrl+b c) or run `, ,` within the block to run the following:
  #+NAME: start docker containers
  #+BEGIN_SRC tmate :noweb eval :session apisnoop:docker
    # These  sequences are to allow you to use this as an iteration loop
    
    
    
    cd ~/ii/apisnoop/apps # docker-compose.yaml is here
    # Retangle / export code from org/documentation usually into ./apps/*
    # the eval: local vars set this emacs instance server-name to apisnoop
    rm hasura/migrations/* # just in case we move files around
    emacsclient -s apisnoop -e "(org-babel-tangle-file \"../org/meta.org\")"
    emacsclient -s apisnoop -e "(org-babel-tangle-file \"../org/tables_and_views.org\")"
    # We have a sharing.io check to ensure everyone get's there own PORTS
    . .loadenv
    # Bring down anything you may already have up
    docker-compose down -t 0 --remove-orphans
    docker-compose rm -f
    # Build your containers
    docker-compose build
    # Bring up your containers
    docker-compose up --remove-orphans
  #+END_SRC

- [ ] perform migrations (if not using .cli-migrations hasura image)

  #+NAME: start docker containers
  #+BEGIN_SRC tmate :noweb eval :session apisnoop:migrations
    cd ~/ii/apisnoop/apps/hasura
    hasura migrate apply
    hasura migrate status
  #+END_SRC

- [ ] Connect to your postgres db from within this file
  You'll want execute this code block by moving your cursor within and typing =,,=
  
  #+NAME: Connect org to postgres
  #+BEGIN_SRC emacs-lisp :results silent
    (sql-connect "apisnoop" (concat "*SQL: postgres:data*"))
  #+END_SRC

- [ ] Test your connection works
  You can run this sql block, and it see a message in your minbuffer like:
  : You are connected to database "apisnoop" as user "apisnoop" on host "localhost" at port "10041".

  #+NAME: Test Connection
  #+BEGIN_SRC sql-mode :results silent
  \conninfo
  #+END_SRC

- [ ] Load cached audit events
  It is highly likely that a teammate has already run through a db setup, and loaded, named, and indexed their audit events. You can use their cached sql for your own db, speeding up the setup time considerably. 

  To do this, you want to:
  #+NAME: start docker containers
  #+BEGIN_SRC tmate :session apisnoop:load_events
    cd ~/ii/apisnoop/apps
    . .loadenv
    psql < /tmp/ci-kubernetes-e2e-gci-gce.1165794879855398916.sql
  #+END_SRC
 
  This will load audit events from bucket =ci-kubernetes-e2e-gci-gce= and job =1165794879855398916=
  If you want to use another bucket/job, check out the longer setup checklist later on.

  The process should take around 30 seconds.  It may throw errors about tables or indexes already existing, but otherwise finish successfully.  

- [ ] Test that audit events loaded.
  
  Now that we are connected to our db, we can run sql queries, like checking if the loading of cached audit events work.
  The following query should return a count of =305025=. You may need to run this twice to ensure your reconnected.
  #+NAME: Number of distinct audit events
  #+BEGIN_SRC sql-mode
  select count(distinct audit_id) from audit_event;
  #+END_SRC

  #+RESULTS: Number of distinct audit events
  #+begin_src sql-mode
   count  
  --------
   316950
  (1 row)

  #+end_src
  
  If this didn't work, check out the longer setup below.
- [ ] Update views based on audit_events

#+NAME: update audit events
#+BEGIN_SRC sql-mode
  REFRESH MATERIALIZED VIEW podspec_field_coverage_material;
#+END_SRC

#+RESULTS: update audit events
#+begin_src sql-mode
REFRESH MATERIALIZED VIEW
#+end_src
  
- [ ] Start up a psql interpreter with the ii env variables
  It's useful to have psql up to run queries directly in the interpreter.
  : open a new tmate pane (ctrl+b c), or navigate to one used to load cached audit event

  #+NAME: start docker containers
  #+BEGIN_SRC tmate :noweb eval :session apisnoop:psql
    cd ~/ii/apisnoop/apps # docker-compose.yaml is here
    . .loadenv
    psql
  #+END_SRC

- [ ] Test your  hasura endpoint is up
  If all is working right, you should be able to visit =$YOURUSERNAME-hasura.sharing.io=
  You will see many views and all should have data.
  
- [ ] Get a drink of water and mark this todo as DONE
  You're all set up and ready to go, but hydration is important!  Get a drink of water, stretch, and recharge before you crush it today!  
  Also, =gh gh gh= to go back to the top then =,TTd= to mark this task as DONE!

* Tables and Views
  All the critical tables and views for apisnoop are documented and tangled from [[file:tables_and_views.org][tables_and_views.org]].
  Explorations into new views, or ad-hoc queries to help answer a problem, are done in our ~explorations~ folder.
* Apps
** .env
#+BEGIN_SRC shell :tangle ../apps/.env_sample
  PGADMIN_PORT=9001
  HASURA_PORT=9000
  # UID based PGPORT used to expose per user postgresql ports on same box
  PGPORT=54321
  PGHOST=localhost
  PGUSER=apisnoop
  PGPASS=s3cr3tsauc3
  PGDATABASE=apisnoop
  CONN="host=127.0.0.1 port=54321 user=apisnoop dbname=apisnoop password=s3cr3tsauc3 sslmode=disable client_encoding=UTF8"
#+END_SRC
** .loadenv
#+NAME: .loadenv
#+BEGIN_SRC shell :tangle ../apps/.loadenv
  # If we are on sharing.io, use UID based *_PORTs
  if [ $(hostname) = "sharing.io" ]
  then
      # Overwriting .env based on \*-${USER}.sharing.io
      echo Using sharing.io setup 1>&2
  (
      # UID based *_PORT used to expose per user postgresql,hasura, and pgadmin ports on same box
      if [ "$KOMPOSE" = "true" ]
      then
              echo Using kompose https://$USER-hasura.apisnoop.io 1>&2
              echo PGPORT=5432
              echo HASURA_PORT=8080
              echo endpoint: https://$USER-hasura.apisnoop.io > $PWD/hasura/config.yaml
      else
              echo Using docker-compose https://$USER-hasura.sharing.io 1>&2
              echo PGPORT=$(id -u)1
              echo HASURA_PORT=$(id -u)0
              echo endpoint: https://$USER-hasura.sharing.io > $PWD/hasura/config.yaml
      fi

      # for running in docker-compose, different localhost:port per user id same
      # for running in docker-compose, different localhost:port per user id same
      # echo PG_CONTAINER_PORT=$PGPORT
      # for running in kompose
      echo PGADMIN_PORT=$(id -u)2
      echo PGHOST=localhost
      echo PGDATABASE=apisnoop
      echo PGUSER=apisnoop
      echo PGPASS=s3cr3tsauc3
      echo PGPASSFILE=$PWD/pgpass
      echo COMPOSE_PROJECT_NAME=apisnoop_$USER
      TAG=$(TZ='Pacific/Auckland'; export TZ ; date +%F-%H-%M)
      echo TAG=$TAG
      # echo HASURA_IMAGE=raiinbow/hasura:$TAG
      # echo POSTGRES_IMAGE=raiinbow/postgres:$TAG
      # echo $PGHOST:$PGPORT:$PGDATABASE:$PGUSER:$PGPASS > $PWD/pgpass
      echo GOOGLE_APPLICATION_CREDENTIALS=$HOME/.gcreds.json
      echo GKS_ZONE="australia-southeast1-a"
      echo GCS_CLUSTER="single-node-cluster"
      echo APISNOOP_NAMESPACE="apisnoop-$USER"
      echo TRAEFIK_NAMESPACE="kube-system"
      echo TRAEFIK_DEPLOYMENT="ii-traefik"
      echo SQLITE_DB=$PWD/sqlite/raiinbow.db
  ) > .env
      export $(grep -v '^#' .env | xargs -d '\n')
      gcloud container clusters get-credentials ${GCS_CLUSTER} --zone ${GKS_ZONE} 2> /dev/null || echo cluster gcreds error
      kubectl config set-context $(kubectl config current-context) --namespace=${APISNOOP_NAMESPACE} 2>&1 > /dev/null
  else
      cp .env_sample .env
      echo SQLITE_DB=$PWD/raiinbow.db >> .env
      cp hasura/config_sample.yaml hasura/config.yaml
      export $(grep -v '^#' .env | xargs -d '\n')
  fi

  PGPASSFILE=$(pwd)/pgpass
  echo $PGHOST:$PGPORT:$PGDATABASE:$PGUSER:$PGPASS > $PGPASSFILE
  chmod 600 $PGPASSFILE
  export CONN="host=127.0.0.1 port=$PGPORT user=$PGUSER dbname=$PGDATABASE password=$PGPASS sslmode=disable client_encoding=UTF8"
#+END_SRC

** Hasura
*** Tracking Tables
    :PROPERTIES:
    :header-args:yaml+: :tangle ../apps/hasura/migrations/999_tracking.up.yaml
    :END:
**** api_swagger
 #+NAME: track api_swagger
 #+BEGIN_SRC yaml
 - type: track_table
   args:
     schema: public
     name: api_swagger
 #+END_SRC
**** api_operation
 #+NAME: track api_operation
 #+BEGIN_SRC yaml
 - type: track_table
   args:
     schema: public
     name: api_operation
 #+END_SRC

**** api_operation_parameter

  #+NAME: track api_operation_parameter
  #+BEGIN_SRC yaml
  - type: track_table
    args:
      schema: public
      name: api_operation_parameter
  #+END_SRC
**** api_operation_response
  #+NAME: track api_operation_response
  #+BEGIN_SRC yaml
  - type: track_table
    args:
      schema: public
      name: api_operation_response
  #+END_SRC

**** api_schema
  #+NAME: track api_schema
  #+BEGIN_SRC yaml
  - type: track_table
    args:
      schema: public
      name: api_schema
  #+END_SRC

**** api_schema_field
 #+NAME: track api_schema_field
 #+BEGIN_SRC yaml
 - type: track_table
   args:
     schema: public
     name: api_schema_field
 #+END_SRC

**** over
  #+NAME: track over
  #+BEGIN_SRC yaml :tangle no
  - type: track_table
    args:
      schema: public
      name: over
  #+END_SRC
**** raw_audit_event
 #+NAME: track raw_audit_event
 #+BEGIN_SRC yaml
 - type: track_table
   args:
     schema: public
     name: raw_audit_event
 #+END_SRC
**** audit_event
  #+NAME: track audit_event
  #+BEGIN_SRC yaml
  - type: track_table
    args:
      schema: public
      name: audit_event
  #+END_SRC

**** kind_field_path
  #+NAME: track kind_field_path
  #+BEGIN_SRC yaml
  - type: track_table
    args:
      schema: public
      name: kind_field_path
  #+END_SRC

**** kind_field_path_recursion
  #+NAME: track kind_field_path_recursion
  #+BEGIN_SRC yaml
  - type: track_table
    args:
      schema: public
      name: kind_field_path_recursion
  #+END_SRC

**** podspec_field_coverage
  #+NAME: track podspec_field_coverage
  #+BEGIN_SRC yaml
  - type: track_table
    args:
      schema: public
      name: podspec_field_coverage
  #+END_SRC

**** podspec_field_summary
  #+NAME: track podspec_field_summary
  #+BEGIN_SRC yaml
  - type: track_table
    args:
      schema: public
      name: podspec_field_summary
  #+END_SRC

**** podspec_field_report
  #+NAME: track podspec_field_report
  #+BEGIN_SRC yaml
  - type: track_table
    args:
      schema: public
      name: podspec_field_report
  #+END_SRC

*** config.yml

#+NAME: hasura config sample
#+BEGIN_SRC text :tangle ../apps/hasura/config_sample.yaml :noweb yes
endpoint: http://localhost:9000
#+END_SRC
*** Dockerfile
#+NAME: apisnoop hasura dockerfile
#+BEGIN_SRC dockerfile :tangle ../apps/hasura/Dockerfile
  FROM hasura/graphql-engine:v1.0.0-beta.6.cli-migrations
  # FROM hasura/graphql-engine:v1.0.0-beta.6
  MAINTAINER Hippie Hacker <hh@ii.coop>
  COPY ./migrations /hasura-migrations
#+END_SRC
** Postgres
*** init-apisnoop-db.sh

 #+NAME: init apisnoop db
 #+BEGIN_SRC sql-mode :tangle ../apps/postgres/initdb/apisnoop_db.sql
   -- ERROR:  database "apisnoop" already exists
   -- create database apisnoop;
   -- create user myuser with encrypted password 'mypass';
   grant all privileges on database apisnoop to apisnoop;
   create role dba with superuser noinherit;
   grant dba to apisnoop;
   \connect apisnoop
   -- we generate uuids
   CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
   -- we write python functions
   CREATE EXTENSION IF NOT EXISTS plpython3u;
   -- we write shell functions
   CREATE EXTENSION IF NOT EXISTS plsh;
   -- regex indexes required trgm
   CREATE EXTENSION IF NOT EXISTS pg_trgm;
   -- paths need an index too
   CREATE EXTENSION IF NOT EXISTS ltree;
   -- hasura needs hash functions
   CREATE EXTENSION IF NOT EXISTS pgcrypto;
   -- hasura db catalog and views
   CREATE SCHEMA IF NOT EXISTS hdb_catalog;
   CREATE SCHEMA IF NOT EXISTS hdb_views;
   -- make the user an owner of system schemas
   ALTER SCHEMA hdb_catalog OWNER TO apisnoop;
   ALTER SCHEMA hdb_views OWNER TO apisnoop;
   GRANT SELECT ON ALL TABLES IN SCHEMA information_schema TO apisnoop;
   GRANT SELECT ON ALL TABLES IN SCHEMA pg_catalog TO apisnoop;
   GRANT USAGE ON SCHEMA public TO apisnoop;
   GRANT ALL ON ALL TABLES IN SCHEMA public TO apisnoop;
   GRANT ALL ON ALL SEQUENCES IN SCHEMA public TO apisnoop;
   GRANT pg_execute_server_program TO apisnoop;
 #+END_SRC
*** Dockerfile
#+BEGIN_SRC dockerfile :tangle ../apps/postgres/Dockerfile
  FROM postgres:12.0
  MAINTAINER Hippie Hacker <hh@ii.coop>
  RUN apt-get update \
    && apt-get install -y --no-install-recommends \
    postgresql-plpython3-12 \
    postgresql-12-plsh \
    python3-bs4\
    python3-requests \
    wget \
    make \
    gcc \
    libc6-dev \
    curl \
    jq \
    git \
    software-properties-common \
    apt-transport-https
  #  && rm -rf /var/lib/apt/lists/*

  RUN curl -L https://dl.google.com/go/go1.12.4.linux-amd64.tar.gz \
    | tar -C /usr/local -xzf - \
    && echo 'export PATH=$PATH:/usr/local/go/bin' \
    > /etc/profile.d/usr-local-go-path.sh \
    && echo 'export PATH=$PATH:$HOME/go/bin' \
    > /etc/profile.d/homedir-go-path.sh
  RUN . /etc/profile.d/usr-local-go-path.sh \
    && . /etc/profile.d/homedir-go-path.sh \
    && go get github.com/golangci/gofmt/gofmt \
    && go get -u golang.org/x/lint/golint \
    && go get golang.org/x/tools/cmd/goimports \
    && go get github.com/jgautheron/goconst/cmd/goconst \
    && go get github.com/jgautheron/usedexports \
    && go get -u github.com/kisielk/errcheck \
    && go get github.com/ii/apisnoopregexp \
    && cd ~/go/src/github.com/ii/apisnoopregexp \
    && make install \
    && cp ~/go/bin/rmatch /usr/local/bin
  COPY ./initdb /docker-entrypoint-initdb.d
  HEALTHCHECK --interval=10s --timeout=5s --start-period=5s --retries=5 \
    CMD pg_isready -U apisnoop || exit 1
 # RUN sed -i -e"s/^#logging_collector = off.*$/logging_collector = on/" /var/lib/postgresql/data/postgresql.conf

#+END_SRC

** pgadmin
*** servers.json
# python setup.py --dump-servers /tmp/server.json --user apisnoop@cncf.io
#+NAME: pgadmin default servers config
#+BEGIN_SRC json :tangle ../apps/pgadmin/servers.json
  {
      "Servers": {
          "1": {
              "Name": "apisnoop",
              "Group": "Servers",
              "Host": "postgres",
              "Port": 5432,
              "MaintenanceDB": "postgres",
              "Username": "apisnoop",
              "SSLMode": "prefer",
              "SSLCert": "<STORAGE_DIR>/.postgresql/postgresql.crt",
              "SSLKey": "<STORAGE_DIR>/.postgresql/postgresql.key",
              "SSLCompression": 0,
              "Timeout": 0,
              "UseSSHTunnel": 0,
              "TunnelPort": "22",
              "TunnelAuthentication": 0
          }
      }
  }
#+END_SRC

** docker-compose.yml

#+NAME: hasura docker-compose
#+BEGIN_SRC yaml :tangle ../apps/docker-compose.yml
  # hasura/docker-compose.yaml
  # Kompose Note: We don’t support anything 3.4 and above at the moment
  version: "3"
  services:
    postgres:
      # image: postgres:11.5 # debian-slim / alternative: postgres:11.5-alpine
      # we need our image to include plpython3u
      image: "raiinbow/postgres:${TAG}"
      build: "./postgres"
        # dockerfile: postgres/Dockerfile
        # context: .
      container_name: "${USER}-postgres"
      restart: always
      shm_size: '64GB' # we currently use big boxes
      #cap_add: # capabilities
      #  - ALL
      environment:
        # These are postgres server setup options
        - POSTGRES_DB=${PGDATABASE}
        - POSTGRES_USER=${PGUSER}
        - POSTGRES_PASSWORD=${PGPASS}
        # - PGDATA=/dev/shm/pgdata
        # - POSTGRES_PASSWORD_FILE="/run/secrets/postgres-passwd" # k8s secret style
        # - POSTGRES_INITDB_ARGS=""
        # - POSTGRES_INITDB_WALDIR=""
        # - PGDATA="/var/lib/postgresql/data/"
        # These are psql client defaults
        - PGDATABASE=${PGDATABASE}
        - PGUSER=${PGUSER}
      #volumes:
        # runs *sql and executable *sh and sources non-executable *sh
        # - ./postgres/initdb:/docker-entrypoint-initdb.d:Z
        # mainly mounted for debugging
        #- ./hasura/migrations:/migrations:Z
      healthcheck:
        test: ["CMD-SHELL", "pg_isready -U $PGUSER"]
        interval: 10s
        timeout: 5s
        retries: 5
      ports: # exposed to docker host
        - "${PGPORT}:5432"
      # Expose ports without publishing them to the host machine
      # - they’ll only be accessible to linked services.
      expose: # exposed to other containers
        - "${PGPORT}"
      networks: # separate from web due to traefik routing on sharing.io
        - db
      labels:
        ingress.class: "traefik"
        kompose.controller.type: "deployment" # or daemonset or replicationcontroller
        # kompose.service.type: "loadbalancer" # nodeport / clusterip / loadbalancer / headless
        # kompose.service.expose: true
        # Maybe see if kompose can work with let's encrypt
        #- "kompose.service.expose.tls-secret="
        # kompose.volume.size: 1Gi
        # traefik.enable: "true"
        # traefik.basic.port: 8080
        # traefik.basic.protocol: "http"
        # traefik.basic.frontend.rule: "Host:${USER}-hasura.sharing.io"
    hasura:
      #image: hasura/graphql-engine:v1.0.0-beta.5
      #image: hasura/graphql-engine:v1.0.0-beta.5.cli-migrations
      image: "raiinbow/hasura:${TAG}"
      build: "./hasura"
      # build:
      #   dockerfile: hasura/Dockerfile
      #   context: .
      #   image: "raiinbow/hasura:${USER}"
      container_name: "${USER}-hasura"
      restart: always
      networks:
        - web
        - db
      environment:
        - HASURA_GRAPHQL_DATABASE_URL=postgres://${PGUSER}:${PGPASS}@postgres:5432/${PGDATABASE}
        - HASURA_GRAPHQL_ENABLE_CONSOLE=true
      # volumes:
      #   - ./hasura/migrations:/hasura-migrations:Z
      depends_on:
        - postgres
      ports: # exposed to docker host
        - "${HASURA_PORT}:8080"
      expose:
        - "8080"
      labels:
        kompose.controller.type: "deployment" # or daemonset or replicationcontroller
        kompose.service.type: "headless" # necessary for traefik
        # kompose.service.type: "clusterip" # nodeport / clusterip / loadbalancer / headless
        # kompose.service.type: "loadbalancer" # nodeport / clusterip / loadbalancer / headless
        # kompose.service.type: "nodeport" # nodeport / clusterip / loadbalancer / headless
        kompose.service.expose: "${USER}-hasura.apisnoop.io" # true / hostname
        ingress.kubernetes.io/protocol: "http"
        kubernetes.io/ingress.class: "traefik"
        # Maybe see if kompose can work with let's encrypt
        #- "kompose.service.expose.tls-secret="
        # kompose.volume.size: 1Gi
        traefik.docker.network: "web"
        traefik.enable: "true"
        traefik.basic.port: 8080
        traefik.basic.protocol: "http"
        traefik.basic.frontend.rule: "Host:${USER}-hasura.sharing.io"
    # pgadmin:
    #   container_name: "${USER}-pgadmin"
    #   image: dpage/pgadmin4:4.12
    #   restart: always
    #   networks:
    #     - db
    #     - web
    #   environment:
    #     - PGADMIN_DEFAULT_EMAIL=apisnoop@cncf.io
    #     - PGADMIN_DEFAULT_PASSWORD=${PGPASS}
    #     # python setup.py --dump-servers /tmp/servers.json --user apisnoop@cncf.io
    #     - PGADMIN_SERVER_JSON_FILE=/apisnoop/servers.json
    #     - PGADMIN_CONFIG_APP_NAME=APISnoopQL
    #     - PGADMIN_CONFIG_APP_COPYRIGHT="Copyright (C) 2019, The Cloud Native Compute Foundation"
    #     - PGADMIN_CONFIG_LOGIN_BANNER="Welcome to APISnoopQL!"
    #     - PGADMIN_CONFIG_ALLOW_SAVE_PASSWORD=True
    #     - PGADMIN_CONFIG_MAX_QUERY_HIST_STORED=1234
    #     - PGADMIN_CONFIG_SESSION_COOKIE_NAME=apisnoop_session
    #     - PGADMIN_CONFIG_UPGRADE_CHECK_ENABLED=False
    #     - PGADMIN_CONFIG_SESSION_EXPIRATION_TIME=7
    #   volumes:
    #    - ./pgadmin:/apisnoop:Z
    #   ports: # exposed to docker host
    #     - "${PGADMIN_PORT}:80"
    #   expose:
    #     - "80"
    #   labels:
    #     - "traefik.docker.network=web"
    #     - "traefik.enable=true"
    #     - "traefik.basic.port=80"
    #     - "traefik.basic.protocol=http"
    #     - "traefik.basic.frontend.rule=Host:${USER}-pgadmin.sharing.io"
  #volumes:
  #  migrations:
  networks:
    web:
      external: true
    db:
#+END_SRC

* Footnotes
** Local Variables

Force this instance of emacs to use the apisnoop server-name.
This allows us to tangle from the emacsclient cli.

# Local Variables:
# eval: (setq server-name "apisnoop")
# eval: (server-force-delete)
# eval: (server-start)
# End:
 
 
 
