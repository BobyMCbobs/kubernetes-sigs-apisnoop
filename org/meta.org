#+TITLE: APIsnoop
#+AUTHOR: ii team
#+DATE: 15 August 2019
#+INCLUDE: "config.org"
#+TODO: TODO(t) NEXT(n) IN-PROGRESS(i) BLOCKED(b) | TADA(d)
#+ARCHIVE: archive/meta.archive.org::
#+PROPERTY: header-args:sql-mode+ :results silent


* Purpose
* Welcome, ii dev!
If you're reading this org file, from within spacemacs, and expecting to do your work from within an org-file...then welcome, fellow ii dev (or honorary ii dev)!

To ensure you're set up properly, you want to run down this checklist:
** TADA [0%] Ready to Work!
    :PROPERTIES:
    :RESET_CHECK_BOXES: t
    :LOGGING: nil
    :END:
- [ ] Ensure you are reading this, and working, from within a tmate session on sharing.io.
  how do to do this is outside scope of this org, but ensure you've ssh'ed into sharing.io, and started a tmate session.

- [ ] Start up dev environment with the ii env variables
  : open a new tmate pane (ctrl+b c) or run `, ,` within the block to run the following:

  #+NAME: start docker containers
  #+BEGIN_SRC tmate :noweb eval :session apisnoop:docker
    # These  sequences are to allow you to use this as an iteration loop
    
    
    
    cd ~/ii/apisnoop/apps # docker-compose.yaml is here
    # Retangle / export code from org/documentation usually into ./apps/*
    # the eval: local vars set this emacs instance server-name to apisnoop
    rm hasura/migrations/* # just in case we move files around
    emacsclient -s apisnoop -e "(org-babel-tangle-file \"../org/meta.org\")"
    # We have a sharing.io check to ensure everyone get's there own PORTS
    . .loadenv
    # Bring down anything you may already have up
    docker-compose down -t 0 --remove-orphans
    docker-compose rm -f
    # Build your containers
    docker-compose build
    # Bring up your containers
    docker-compose up --remove-orphans
  #+END_SRC

- [ ] perform migrations (if not using .cli-migrations hasura image)

  #+NAME: start docker containers
  #+BEGIN_SRC tmate :noweb eval :session apisnoop:migrations
    cd ~/ii/apisnoop/apps/hasura
    hasura migrate apply
    hasura migrate status
  #+END_SRC

- [ ] Connect to your postgres db from within this file
  You'll want execute this code block by moving your cursor within and typing =,,=
  
  #+NAME: Connect org to postgres
  #+BEGIN_SRC emacs-lisp :results silent
    (sql-connect "apisnoop" (concat "*SQL: postgres:data*"))
  #+END_SRC

- [ ] Test your connection works
  You can run this sql block, and it see a message in your minbuffer like:
  : You are connected to database "apisnoop" as user "apisnoop" on host "localhost" at port "10041".

  #+NAME: Test Connection
  #+BEGIN_SRC sql-mode :results silent
  \conninfo
  #+END_SRC

- [ ] Load cached audit events
  It is highly likely that a teammate has already run through a db setup, and loaded, named, and indexed their audit events. You can use their cached sql for your own db, speeding up the setup time considerably. 

  To do this, you want to:
  #+NAME: start docker containers
  #+BEGIN_SRC tmate :session apisnoop:load_events
    cd ~/ii/apisnoop/apps
    . .loadenv
    psql < /tmp/ci-kubernetes-e2e-gci-gce.1165794879855398916.sql
  #+END_SRC
 
  This will load audit events from bucket =ci-kubernetes-e2e-gci-gce= and job =1165794879855398916=
  If you want to use another bucket/job, check out the longer setup checklist later on.

  The process should take around 30 seconds.  It may throw errors about tables or indexes already existing, but otherwise finish successfully.  

- [ ] Test that audit events loaded.
  
  Now that we are connected to our db, we can run sql queries, like checking if the loading of cached audit events work.
  The following query should return a count of =305025=. You may need to run this twice to ensure your reconnected.
  #+NAME: Number of distinct audit events
  #+BEGIN_SRC sql-mode
  select count(distinct audit_id) from audit_event;
  #+END_SRC

  #+RESULTS: Number of distinct audit events
  #+begin_src sql-mode
   count  
  --------
   305025
  (1 row)

  #+end_src
  
  If this didn't work, check out the longer setup below.
  
- [ ] Start up a psql interpreter with the ii env variables
  It's useful to have psql up to run queries directly in the interpreter.
  : open a new tmate pane (ctrl+b c), or navigate to one used to load cached audit event

  #+NAME: start docker containers
  #+BEGIN_SRC tmate :noweb eval :session apisnoop:psql
    cd ~/ii/apisnoop/apps # docker-compose.yaml is here
    . .loadenv
    psql
  #+END_SRC

- [ ] Test your  hasura endpoint is up
  If all is working right, you should be able to visit =$YOURUSERNAME-hasura.sharing.io=
  You will see many views and all should have data.
  
- [ ] If cached sql not available, load audit events.
  We have a long process as [[*901: update_audit_events.up.sql][part 901: update_audit_events.up.sql]].  You can click enter on that link and then execute each code block within this heading in order.  This process will take about a half hour.

- [ ] Get a drink of water and mark this todo as DONE
  You're all set up and ready to go, but hydration is important!  Get a drink of water, stretch, and recharge before you crush it today!  
  Also, =gh gh gh= to go back to the top then =,TTd= to mark this task as DONE!

* Raw Swaggers Table, and Helper Functions
  :PROPERTIES:
  :header-args:sql-mode+: :results silent
  :END:
  These are jsonb indexed loads of swagger.json from github k8s commits or releases.
  Eventually these will also be populated on the fly when running within/against a cluster.
** 100: API Swagger Table
  :PROPERTIES:
  :header-args:sql-mode+: :tangle ../apps/hasura/migrations/100_table_api_swagger.up.sql
  :END:
*** Create Table
#+NAME: api_swagger
#+BEGIN_SRC sql-mode
CREATE TABLE api_swagger (
    id int GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    ingested_at timestamp DEFAULT CURRENT_TIMESTAMP,
    -- version text NOT NULL,
    -- definition_id text NOT NULL,
    data jsonb NOT NULL
);
#+END_SRC
*** Index Table
#+NAME: general index the raw_swagger
#+BEGIN_SRC sql-mode
  CREATE INDEX idx_swagger_jsonb_ops ON api_swagger
    USING GIN (data jsonb_ops);
  CREATE INDEX idx_swagger_jsonb_path_ops ON api_swagger
    USING GIN (data jsonb_path_ops);
#+END_SRC
** 120: Function for load swagger via curl
  :PROPERTIES:
  :header-args:sql-mode+: :tangle ../apps/hasura/migrations/120_function_load_swagger_via_curl.up.sql
  :END:
  
#+NAME: load_swagger_via_curl.py
#+BEGIN_SRC python :eval never :exports code
  # should probably sanitize branch_or_tag
  try:
      from string import Template
      sql = Template("copy api_swagger (data) FROM PROGRAM '$curl' (DELIMITER e'\x02', FORMAT 'csv', QUOTE e'\x01');").substitute(
      curl =  ''.join([
          'curl https://raw.githubusercontent.com/kubernetes/kubernetes/',
          branch_or_tag,
          '/api/openapi-spec/swagger.json | jq -c .'])
      )
      rv = plpy.execute(sql)
      return "it worked"
  except:
      return "something went wrong"
#+END_SRC

#+NAME: load_swagger_via_curl.sql
#+BEGIN_SRC sql-mode :noweb yes
  set role dba;
  CREATE OR REPLACE FUNCTION load_swagger_via_curl(branch_or_tag text)
  RETURNS text AS $$
  <<load_swagger_via_curl.py>>
  $$ LANGUAGE plpython3u ;
  reset role;
#+END_SRC

* Operation Views
  :PROPERTIES:
  :header-args:sql-mode+: :results silent
  :END:
  These are views derived from the 'data->path' section of our api_swagger table.
** 140: api_operation_material view
  :PROPERTIES:
  :header-args:sql-mode+: :tangle ../apps/hasura/migrations/140_view_api_operation_material.up.sql
  :END:
  We can track this, but it won't show up in Hasura as it does not support materialized views yet.  We can still use it to create _other_ views hasura can see though.
*** Define regex_from_path function
#+NAME: regex_from_path.py
#+BEGIN_SRC python :eval never :export none
  import re
  if path is None:
    return None
  K8S_PATH_VARIABLE_PATTERN = re.compile("{(path)}$")
  VARIABLE_PATTERN = re.compile("{([^}]+)}")
  path_regex = K8S_PATH_VARIABLE_PATTERN.sub("(.*)", path).rstrip('/')
  path_regex = VARIABLE_PATTERN.sub("([^/]*)", path_regex).rstrip('/')
  if not path_regex.endswith(")") and not path_regex.endswith("?"):
    path_regex += "([^/]*)"
  if path_regex.endswith("proxy"):
      path_regex += "/?$"
  else:
      path_regex += "$"
  return path_regex
#+END_SRC

#+NAME: regex_from_path.sql
#+BEGIN_SRC sql-mode :noweb yes
  set role dba;
  CREATE OR REPLACE FUNCTION regex_from_path(path text)
  RETURNS text AS $$
  <<regex_from_path.py>>
  $$ LANGUAGE plpython3u ;
  reset role;
#+END_SRC

*** Create
#+NAME: api_operation_material
#+BEGIN_SRC sql-mode 
  CREATE MATERIALIZED VIEW "public"."api_operation_material" AS 
    SELECT
           (d.value ->> 'operationId'::text) AS operation_id,
           CASE
           WHEN paths.key ~~ '%alpha%' THEN 'alpha'
           WHEN paths.key ~~ '%beta%' THEN 'beta'
           ELSE 'stable'
           END AS level,
           split_part((cat_tag.value ->> 0), '_'::text, 1) AS category,
           ((d.value -> 'x-kubernetes-group-version-kind'::text) ->> 'group'::text) AS k8s_group,
           ((d.value -> 'x-kubernetes-group-version-kind'::text) ->> 'kind'::text) AS k8s_kind,
           ((d.value -> 'x-kubernetes-group-version-kind'::text) ->> 'version'::text) AS k8s_version,
           CASE
           WHEN (lower((d.value ->> 'description'::text)) ~~ '%deprecated%'::text) THEN true
           ELSE false
           END AS deprecated,
           (d.value ->> 'description'::text) AS description,
           d.key AS http_method,
           (d.value ->> 'x-kubernetes-action'::text) AS k8s_action,
           CASE
            WHEN (d.value ->> 'x-kubernetes-action'::text) = 'get' THEN ARRAY ['get']
            WHEN (d.value ->> 'x-kubernetes-action'::text) =  'list' THEN ARRAY [ 'list' ]
            WHEN (d.value ->> 'x-kubernetes-action'::text) = 'proxy' THEN ARRAY [ 'proxy' ]
            WHEN (d.value ->> 'x-kubernetes-action'::text) = 'deletecollection' THEN ARRAY [ 'deletecollection' ]
            WHEN (d.value ->> 'x-kubernetes-action'::text) = 'watch' THEN ARRAY [ 'watch' ]
            WHEN (d.value ->> 'x-kubernetes-action'::text) = 'post' THEN ARRAY [ 'post', 'create' ]
            WHEN (d.value ->> 'x-kubernetes-action'::text) =  'put' THEN ARRAY [ 'put', 'update' ]
            WHEN (d.value ->> 'x-kubernetes-action'::text) = 'patch' THEN ARRAY [ 'patch' ]
            WHEN (d.value ->> 'x-kubernetes-action'::text) = 'connect' THEN ARRAY [ 'connect' ]
           ELSE NULL
             END as event_verb,
           paths.key AS path,
           (d.value -> 'consumes'::text)::jsonb AS consumes,
           (d.value -> 'responses'::text)::jsonb AS responses,
           (d.value -> 'parameters'::text)::jsonb AS parameters,
           string_agg(btrim((jsonstring.value)::text, '"'::text), ', '::text) AS tags,
           string_agg(btrim((schemestring.value)::text, '"'::text), ', '::text) AS schemes,
           regex_from_path(paths.key) as regex,
           api_swagger.id AS raw_swagger_id
      FROM api_swagger
      , jsonb_each((api_swagger.data -> 'paths'::text)) paths(key, value)
      , jsonb_each(paths.value) d(key, value)
      , jsonb_array_elements((d.value -> 'tags'::text)) cat_tag(value)
      , jsonb_array_elements((d.value -> 'tags'::text)) jsonstring(value)
      , jsonb_array_elements((d.value -> 'schemes'::text)) schemestring(value)
     GROUP BY api_swagger.id, paths.key, d.key, d.value, cat_tag.value
     ORDER BY paths.key;
#+END_SRC
*** Index
#+NAME: index the api_operation_material
#+BEGIN_SRC sql-mode :tangle ../apps/hasura/migrations/260_view_api_operation_material.up.sql :results silent
    CREATE INDEX api_operation_materialized_event_verb  ON api_operation_material            (event_verb);
    CREATE INDEX api_operation_materialized_k8s_action  ON api_operation_material            (k8s_action);
    CREATE INDEX api_operation_materialized_k8s_group   ON api_operation_material            (k8s_group);
    CREATE INDEX api_operation_materialized_k8s_version ON api_operation_material            (k8s_version);
    CREATE INDEX api_operation_materialized_k8s_kind    ON api_operation_material            (k8s_kind);
    CREATE INDEX api_operation_materialized_tags        ON api_operation_material            (tags);
    CREATE INDEX api_operation_materialized_schemes     ON api_operation_material            (schemes);
    CREATE INDEX api_operation_materialized_regex_gist  ON api_operation_material USING GIST (regex gist_trgm_ops);
    CREATE INDEX api_operation_materialized_regex_gin   ON api_operation_material USING GIN  (regex gin_trgm_ops);
    CREATE INDEX api_operation_materialized_consumes_ops   ON api_operation_material USING GIN  (consumes jsonb_ops);
    CREATE INDEX api_operation_materialized_consumes_path  ON api_operation_material USING GIN  (consumes jsonb_path_ops);
    CREATE INDEX api_operation_materialized_parameters_ops   ON api_operation_material USING GIN  (parameters jsonb_ops);
    CREATE INDEX api_operation_materialized_parameters_path  ON api_operation_material USING GIN  (parameters jsonb_path_ops);
    CREATE INDEX api_operation_materialized_responses_ops   ON api_operation_material USING GIN  (responses jsonb_ops);
    CREATE INDEX api_operation_materialized_responses_path  ON api_operation_material USING GIN  (responses jsonb_path_ops);
#+END_SRC
** 150: api_operation view of material
  :PROPERTIES:
  :header-args:sql-mode+: :tangle ../apps/hasura/migrations/150_view_api_operation.up.sql
  :END:
   This grabs the 'paths' section of our swagger.json, where each path contains operation Id, tags, schemes, etc.
*** Create View
#+NAME: api_operation view
#+BEGIN_SRC sql-mode 
  CREATE OR REPLACE VIEW "public"."api_operation" AS 
    SELECT * from api_operation_material;
#+END_SRC
** 160: api_operation_parameter_material
  :PROPERTIES:
  :header-args:sql-mode+: :tangle ../apps/hasura/migrations/160_view_api_operation_parameter_material.up.sql
  :END:
*** Create
Using our api_operation_material view, look into the parameters field in each one.     
#+NAME: api_operation_parameter_material view
#+BEGIN_SRC sql-mode
  CREATE MATERIALIZED VIEW "public"."api_operation_parameter_material" AS 
     -- SELECT api_operation.operation_id as param_op,
     --        (param.entry ->> 'name'::text) AS param_name,
     --        CASE
     --        WHEN ((param.entry ->> 'required'::text) = 'true') THEN true
     --        ELSE false
     --         END AS param_required,
     --        -- for resource:
     --        -- if param is body in body, take its $ref from its schema
     --        -- otherwise, take its type
     --        replace(
     --          CASE
     --          WHEN ((param.entry ->> 'in'::text) = 'body'::text) 
     --           AND ((param.entry -> 'schema'::text) is not null)
     --            THEN ((param.entry -> 'schema'::text) ->> '$ref'::text)
     --          ELSE (param.entry ->> 'type'::text)
     --          END, '#/definitions/','') AS param_schema,
     --        (param.entry ->> 'description'::text) AS param_description,
     --        (param.entry ->> 'in'::text) AS "in",
     --        CASE
     --        WHEN ((param.entry ->> 'uniqueItems'::text) = 'true') THEN true
     --        ELSE false
     --        END AS unique_items,
     --        api_operation.raw_swagger_id
     --   FROM api_operation
     --        , jsonb_array_elements(api_operation.parameters) WITH ORDINALITY param(entry, index)
     --         WHERE api_operation.parameters IS NOT NULL;
    SELECT api_operation.operation_id AS param_op,
    (param.entry ->> 'name'::text) AS param_name,
           -- for resource:
           -- if param is body in body, take its $ref from its schema
           -- otherwise, take its type
           replace(
             CASE
             WHEN ((param.entry ->> 'in'::text) = 'body'::text) 
              AND ((param.entry -> 'schema'::text) is not null)
               THEN ((param.entry -> 'schema'::text) ->> '$ref'::text)
             ELSE (param.entry ->> 'type'::text)
             END, '#/definitions/','') AS param_schema,
           CASE
           WHEN ((param.entry ->> 'required'::text) = 'true') THEN true
           ELSE false
            END AS required,
           (param.entry ->> 'description'::text) AS param_description,
           CASE
           WHEN ((param.entry ->> 'uniqueItems'::text) = 'true') THEN true
           ELSE false
           END AS unique_items,
           (param.entry ->> 'in'::text) AS "in",
           api_operation.raw_swagger_id,
           param.entry as entry
      FROM api_operation
           , jsonb_array_elements(api_operation.parameters) WITH ORDINALITY param(entry, index)
            WHERE api_operation.parameters IS NOT NULL;
#+END_SRC
*** Index
#+NAME: index the api_operation_material
#+BEGIN_SRC sql-mode
    CREATE UNIQUE INDEX                                  ON api_operation_parameter_material(raw_swagger_id, param_op, param_name);
    CREATE INDEX api_parameters_materialized_schema      ON api_operation_parameter_material            (param_schema);
    -- CREATE INDEX api_parameters_materialized_entry       ON api_operation_parameter_material            (entry);
#+END_SRC

** 170: api_operation_parameter view of material
  :PROPERTIES:
  :header-args:sql-mode+: :tangle ../apps/hasura/migrations/170_view_api_operation_parameter.up.sql
  :END:
Using our api_operation view, look into the parameters field in each one.     
*** Create
 #+NAME: api_operation_parameter view
 #+BEGIN_SRC sql-mode
   CREATE OR REPLACE VIEW "public"."api_operation_parameter" AS 
     SELECT * from api_operation_parameter_material;
 #+END_SRC

** 180: api_operation_response view
  :PROPERTIES:
  :header-args:sql-mode+: :tangle ../apps/hasura/migrations/180_view_api_operation_response.up.sql
  :END:
   Similar to parameters, within each of the paths of the swagger.json, there is a responses field.  We are listing the values within this field.
*** Create
 #+NAME: Responses View
 #+BEGIN_SRC sql-mode 
   CREATE OR REPLACE VIEW "public"."api_operation_response" AS 
     SELECT api_operation.operation_id as resp_op,
            d.key AS resp_code,
            (d.value ->> 'description'::text) AS resp_description,
            replace(
              CASE
              WHEN (((d.value -> 'schema'::text) IS NOT NULL) AND (((d.value -> 'schema'::text) -> 'type'::text) IS NOT NULL))
                THEN ((d.value -> 'schema'::text) ->> 'type'::text)
              WHEN (((d.value -> 'schema'::text) IS NOT NULL) AND (((d.value -> 'schema'::text) -> '$ref'::text) IS NOT NULL))
                THEN ((d.value -> 'schema'::text) ->> '$ref'::text)
              ELSE NULL::text
              END, '#/definitions/','') AS resp_schema,
              api_operation.raw_swagger_id
       FROM (api_operation
             JOIN LATERAL jsonb_each(api_operation.responses) d(key, value) ON (true))
      ORDER BY (uuid_generate_v1());
 #+END_SRC
* Schema Views
  :PROPERTIES:
  :header-args:sql-mode+: :results silent
  :END:
  These are views derived from the 'data->definitions' in our api_swagger table
** 191: api_schema view
  :PROPERTIES:
  :header-args:sql-mode+: :tangle ../apps/hasura/migrations/191_view_api_schema.up.sql
  :END:
*** Create
 #+NAME: api_schema view
 #+BEGIN_SRC sql-mode 
   CREATE OR REPLACE VIEW "public"."api_schema" AS 
    SELECT 
       d.key AS schema_name,
       (((d.value -> 'x-kubernetes-group-version-kind'::text) -> 0) ->> 'kind'::text) AS k8s_kind,
       (d.value ->> 'type'::text) AS resource_type,
       (((d.value -> 'x-kubernetes-group-version-kind'::text) -> 0) ->> 'version'::text) AS k8s_version,
       (((d.value -> 'x-kubernetes-group-version-kind'::text) -> 0) ->> 'group'::text) AS k8s_group,
       ARRAY(SELECT jsonb_array_elements_text(d.value -> 'required')) as required_fields,
       (d.value -> 'properties'::text) AS properties,
       api_swagger.id AS raw_swagger_id,
       d.value
      FROM api_swagger
        , jsonb_each((api_swagger.data -> 'definitions'::text)) d(key, value)
        -- , jsonb_array_elements((d.value -> 'required'::text)) reqstring(value)
      GROUP BY api_swagger.id, d.key, d.value;

 #+END_SRC
** 200: api_schema_field view
  :PROPERTIES:
  :header-args:sql-mode+: :tangle ../apps/hasura/migrations/200_view_api_schema_field.up.sql
  :END:
*** Create
#+NAME: api_schema_field view
#+BEGIN_SRC sql-mode 
  CREATE OR REPLACE VIEW "public"."api_schema_field" AS 
    SELECT api_schema.schema_name as field_schema,
           d.key AS field_name,
           replace(
             CASE
             WHEN d.value->>'type' = 'string' THEN 'string'
             WHEN d.value->>'type' IS NULL THEN d.value->>'$ref'
             WHEN d.value->>'type' = 'array'
              AND d.value->'items'->> 'type' IS NULL
               THEN d.value->'items'->>'$ref'
             WHEN d.value->>'type' = 'array'
              AND d.value->'items'->>'$ref' IS NULL
               THEN d.value->'items'->>'type'
             ELSE 'integer'::text
             END, '#/definitions/','') AS field_kind,
           CASE
           WHEN d.value->>'type' IS NULL THEN 'subtype'
           ELSE d.value->>'type'
             END AS field_type,
           d.value->>'description' AS description,
           CASE
           WHEN d.key = ANY(api_schema.required_fields) THEN true
           ELSE false
             END AS required,
           CASE
           WHEN (   d.value->>'description' ilike '%This field is alpha-level%'
                 or d.value->>'description' ilike '%This is an alpha field%'
                 or d.value->>'description' ilike '%This is an alpha feature%') THEN 'alpha'
           WHEN (   d.value->>'description' ilike '%This field is beta-level%'
                 or d.value->>'description' ilike '%This field is beta%'
                 or d.value->>'description' ilike '%This is a beta feature%'
                 or d.value->>'description' ilike '%This is an beta feature%'
                 or d.value->>'description' ilike '%This is an beta field%') THEN 'beta'
           ELSE 'ga'
             END AS release,
           CASE
           WHEN  d.value->>'description' ilike '%deprecated%' THEN true
            ELSE false
            END AS deprecated,
           CASE
           WHEN ( d.value->>'description' ilike '%requires the % feature gate to be enabled%'
                 or d.value->>'description' ilike '%depends on the % feature gate being enabled%'
                 or d.value->>'description' ilike '%requires the % feature flag to be enabled%'
                 or d.value->>'description' ilike '%honored if the API server enables the % feature gate%'
                 or d.value->>'description' ilike '%honored by servers that enable the % feature%'
                 or d.value->>'description' ilike '%requires enabling % feature gate%'
                 or d.value->>'description' ilike '%honored by clusters that enables the % feature%'
                 or d.value->>'description' ilike '%only if the % feature gate is enabled%'
                 ) THEN true
           ELSE false
             END AS feature_gated,
           d.value->>'format' AS format,
           d.value->>'x-kubernetes-patch-merge-key' AS merge_key,
           d.value->>'x-kubernetes-patch-strategy' AS patch_strategy,
           api_schema.raw_swagger_id,
           d.value
      FROM (api_schema
            JOIN LATERAL jsonb_each(api_schema.properties) d(key, value) ON (true));
#+END_SRC
* OpenAPI Over Views
  :PROPERTIES:
  :header-args:sql-mode+: :results silent
  :END:
  This combines fields from the majority fo the above views to create one uber view.
** 210: over view
  :PROPERTIES:
  :header-args:sql-mode+: :notangle ../apps/hasura/migrations/210_view_over.up.sql
  :END:
*** Create
 #+NAME: over view
 #+BEGIN_SRC sql-mode
   CREATE OR REPLACE VIEW "public"."over" AS
     SELECT
       op.name as param_name,
       op.required as param_required,
       op.description as param_description,
       o.operation_id,
       op.resource,
       r.name as resource_name,
       r.k8s_group,
       r.k8s_version,
       r.k8s_kind,
       rf.resource_field,
       rf.param_type,
       rf.field_kind,
       rf.description,
       rf.format,
       rf.merge_key,
       rf.patch_strategy
       FROM
           api_operation_parameter op
           JOIN api_operation o ON (
             o.raw_swagger_id = op.raw_swagger_id
             AND
             o.operation_id = op.operation_id
           )
           LEFT JOIN api_schema r ON (
             op.resource = r.name
             AND
             op.raw_swagger_id = r.raw_swagger_id
             )
           LEFT JOIN api_schema_field rf ON (
             rf.api_resource_name = r.name
             AND
             rf.raw_swagger_id = r.raw_swagger_id
           )
      ORDER BY op.name;
 #+END_SRC
* Loading Swagger Data
  :PROPERTIES:
  :header-args:sql-mode+: :tangle ../apps/hasura/migrations/199_load_and_populate_swaggers.up.sql
  :END:

** 199: Populate Swaggers Up
  :PROPERTIES:
  :header-args:sql-mode+: :results silent
  :END:
#+NAME: reload swaggers for particluar releases
#+BEGIN_SRC sql-mode
  delete from api_swagger;
  select * from load_swagger_via_curl('master');
  REFRESH MATERIALIZED VIEW api_operation_material;
  -- HINT:  Create a unique index with no WHERE clause on one or more columns of the materialized view^
  REFRESH MATERIALIZED VIEW CONCURRENTLY api_operation_parameter_material;
  -- select * from load_swagger_via_curl('release-1.15');
  -- select * from load_swagger_via_curl('release-1.14');
  -- select * from load_swagger_via_curl('release-1.13');
  -- select * from load_swagger_via_curl('release-1.12');
  -- select * from load_swagger_via_curl('release-1.11');
  -- select * from load_swagger_via_curl('release-1.10');
#+END_SRC
* Raw Audit Events Table, and helper functions
  :PROPERTIES:
  :header-args:sql-mode+: :results silent
  :END:
** 220: raw_audit_event Table
  :PROPERTIES:
  :header-args:sql-mode+: :tangle ../apps/hasura/migrations/220_table_raw_audit_event.up.sql
  :END:
*** Create
#+NAME: raw_audit_event
#+BEGIN_SRC sql-mode
  CREATE UNLOGGED TABLE raw_audit_event (
    -- id int GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    -- ingested_at timestamp DEFAULT CURRENT_TIMESTAMP,
    bucket text,
    job text,
    audit_id text NOT NULL,
    stage text NOT NULL,
    event_verb text NOT NULL,
    request_uri text NOT NULL,
    operation_id text,
    data jsonb NOT NULL
  );
#+END_SRC
*** Index
#+NAME: index the raw_audit_event
#+BEGIN_SRC sql-mode
-- CREATE INDEX idx_audit_event_primary          ON raw_audit_event (bucket, job, audit_id, stage);
-- ALTER TABLE raw_audit_event add primary key using index idx_audit_event_primary;
CREATE INDEX idx_audit_event_jsonb_ops        ON raw_audit_event USING GIN (data jsonb_ops);
CREATE INDEX idx_audit_event_jsonb_path_jobs  ON raw_audit_event USING GIN (data jsonb_path_ops);
#+END_SRC
** 245: load_audit_event Function
  :PROPERTIES:
  :header-args:sql-mode+:  :tangle ../apps/hasura/migrations/245_function_load_audit_event.up.sql
  :END:
*** Python Code
#+NAME: load_audit_events.py
#+BEGIN_SRC python :noweb yes :exports none
  #!/usr/bin/env python3
  from urllib.request import urlopen, urlretrieve
  import os
  import re
  from bs4 import BeautifulSoup
  import subprocess
  import time
  import glob
  from tempfile import mkdtemp
  from string import Template


  def get_html(url):
      html = urlopen(url).read()
      soup = BeautifulSoup(html, 'html.parser')
      return soup


  def download_url_to_path(url, local_path):
      local_dir = os.path.dirname(local_path)
      if not os.path.isdir(local_dir):
          os.makedirs(local_dir)
      if not os.path.isfile(local_path):
          process = subprocess.Popen(['wget', '-q', url, '-O', local_path])
          downloads[local_path] = process

  # this global dict is used to track our wget subprocesses
  # wget was used because the files can get to several halfa gig
  downloads = {}
  def load_audit_events(bucket,job):
      bucket_url = 'https://storage.googleapis.com/kubernetes-jenkins/logs/' + bucket + '/' + job + '/'
      artifacts_url = 'https://gcsweb.k8s.io/gcs/kubernetes-jenkins/logs/' + bucket + '/' +  job + '/' + 'artifacts'
      job_metadata_files = [
          'finished.json',
          'artifacts/metadata.json',
          'artifacts/junit_01.xml',
          'build-log.txt'
      ]
      download_path = mkdtemp( dir='/tmp', prefix='apisnoop-' + bucket + '-' + job ) + '/'
      combined_log_file = download_path + 'audit.log'

      # meta data to download
      for jobfile in job_metadata_files:
          download_url_to_path( bucket_url + jobfile,
                                download_path + jobfile )

      # Use soup to grab url of each of audit.log.* (some end in .gz)
      soup = get_html(artifacts_url)
      master_link = soup.find(href=re.compile("master"))
      master_soup = get_html(
          "https://gcsweb.k8s.io" + master_link['href'])
      log_links = master_soup.find_all(
          href=re.compile("audit.log"))

      # download all logs
      for link in log_links:
          log_url = link['href']
          log_file = download_path + os.path.basename(log_url)
          download_url_to_path( log_url, log_file)

      # Our Downloader uses subprocess of curl for speed
      for download in downloads.keys():
          # Sleep for 5 seconds and check for next download
          while downloads[download].poll() is None:
              time.sleep(5)
              # print("Still downloading: " + download)
          # print("Downloaded: " + download)

      # Loop through the files, (z)cat them into a combined audit.log
      with open(combined_log_file, 'ab') as log:
          for logfile in sorted(
                  glob.glob(download_path + '*kube-apiserver-audit*'), reverse=True):
              if logfile.endswith('z'):
                  subprocess.run(['zcat', logfile], stdout=log, check=True)
              else:
                  subprocess.run(['cat', logfile], stdout=log, check=True)
      # Load the resulting combined audit.log directly into raw_audit_event
      try:
          # for some reason tangling isn't working to reference this SQL block
          sql = Template("""
  CREATE TEMPORARY TABLE raw_audit_event_import (data jsonb not null) ;
  COPY raw_audit_event_import (data)
  FROM '${audit_logfile}' (DELIMITER e'\x02', FORMAT 'csv', QUOTE e'\x01');

  INSERT INTO raw_audit_event(bucket, job,
                               audit_id, stage,
                               event_verb, request_uri,
                               -- operation_id,
                               data)
  SELECT '${bucket}', '${job}',
         (raw.data ->> 'auditID'), (raw.data ->> 'stage'),
         (raw.data ->> 'verb'), (raw.data ->> 'requestURI'),
         -- ops.operation_id,
         raw.data 
    FROM raw_audit_event_import raw;
           -- FIXME: this join is necesary, but expensive
           -- https://github.com/cncf/apisnoopregexp is an alterative approach
           -- LEFT JOIN api_operation_material ops ON
           --  ops.raw_swagger_id = 1
           --    AND raw.data ->> 'verb' = ANY(ops.event_verb)
           --    AND raw.data ->> 'requestURI' ~ ops.regex;
          """).substitute(
              audit_logfile = combined_log_file,
              bucket = bucket,
              job = job
          )
          with open(download_path + 'load.sql', 'w') as sqlfile:
            sqlfile.write(sql)
          rv = plpy.execute(sql)
          #plpy.commit()
          # this calls external binary, not part of transaction 8(
          #rv = plpy.execute("select * from audit_event_op_update();")
          #plpy.commit()
          #rv = plpy.execute("REFRESH MATERIALIZED VIEW CONCURRENTLY podspec_field_coverage_material;")
          #plpy.commit()
          return "it worked"
      except plpy.SPIError:
          return "something went wrong with plpy"
      except:
          return "something unknown went wrong"
  if __name__ == "__main__":
      load_audit_events('ci-kubernetes-e2e-gci-gce','1134962072287711234')
  else:
      load_audit_events(bucket,job)
#+END_SRC

#+RESULTS: load_audit_events.py

*** Create
#+NAME: load_audit_events.sql
#+BEGIN_SRC sql-mode :noweb yes
  set role dba;
  CREATE OR REPLACE FUNCTION load_audit_events(bucket text, job text)
  RETURNS text AS $$
  <<load_audit_events.py>>
  $$ LANGUAGE plpython3u ;
  reset role;
#+END_SRC
** 244: audit_event_op_update operation Function
  :PROPERTIES:
  :header-args:sql-mode+:  :tangle ../apps/hasura/migrations/244_function_audit_event_op_update.up.sql
  :END:
*** Create
#+NAME: audit_events_op_update.sql
#+BEGIN_SRC sql-mode :noweb yes
  set role dba;
  CREATE OR REPLACE FUNCTION audit_event_op_update()
  RETURNS text AS $$
  #!/bin/bash
  (echo 'hello'
   pwd
   id
   env
   unset PGLOCALEDIR
   unset PGSYSCONFDIR
   /usr/local/bin/rmatch || echo FAILS
  ) 2>&1 > /tmp/rmatch.log
  $$ LANGUAGE plsh ;
  reset role;
#+END_SRC

** 900: populate_audit_events.up.sql
  :PROPERTIES:
  :header-args:sql-mode+: :notangle ../apps/hasura/migrations/900_populate_audit_events.up.sql
  :END:

We could load audit_events directly from test-grid via bucket and job.
However they do NOT include the OperationID.
It's computationally expensive... nearly 30 minutes on a 56 Xeon core box with 300+ gigs of ram.

Might be good to instead save our processed audit_events via

#+BEGIN_SRC shell :eval never
pg_dump --host=$PGHOST --port=$PGPORT --username=$PGUSER --dbname=$PGDATABASE --table=raw_audit_event
 > $BUCKET.$JOB.sql 
#+END_SRC

Which we could easily load via:

#+BEGIN_SRC shell :eval
psql < /tmp/ci-kubernetes-e2e-gci-gce.1165794879855398916.sql
#+END_SRC

#+RESULTS:
#+begin_EXAMPLE
#+end_EXAMPLE

*** Call load_audit_events()

#+NAME: reload sample audit event 
#+BEGIN_SRC sql-mode :noweb yes :results append :output both
  select * from load_audit_events('ci-kubernetes-e2e-gci-gce','1165794879855398916');
#+END_SRC

#+RESULTS: reload sample audit event
#+begin_src sql-mode
 load_audit_events 
-------------------
 
(1 row)

#+end_src

** 901: update_audit_events.up.sql
  :PROPERTIES:
  :header-args:sql-mode+: :notangle ../apps/hasura/migrations/901_update_audit_events.up.sql
  :END:
*** Call load_audit_events() interactively
#+NAME: update event operation_id sample audit event
#+BEGIN_SRC tmate :session sql:update_opid1 :exports none
  cd ~/ii/apisnoop/apps
  . .loadenv
  psql
  select * from audit_event_op_update()\;
  REFRESH MATERIALIZED VIEW podspec_field_coverage_material;
#+END_SRC
*** follow htop to see CPU usage
#+NAME: update event operation_id sample audit event
#+BEGIN_SRC tmate :session sql:htop1 :exports none
  htop
#+END_SRC

*** see how far we have to go
#+NAME: every 10 seconsd count the number of events with no operation_id
#+BEGIN_SRC tmate :session sql:op_count1 :exports none
  cd ~/ii/apisnoop/apps
  . .loadenv
  psql
  select count(*) from raw_audit_event where operation_id is null; \watch 10
#+END_SRC

* Audit Events View
  :PROPERTIES:
  :header-args:sql-mode+: :results silent
  :END:
   We'll need to figure out which is the correct audit events here
** 225: Audit Events View
  :PROPERTIES:
  :header-args:sql-mode+: :tangle ../apps/hasura/migrations/225_view_audit_event.up.sql
  :END:
*** Create
    #+NAME: view audit_event
    #+BEGIN_SRC sql-mode
      CREATE OR REPLACE VIEW "public"."audit_event" AS
        SELECT (raw.data ->> 'auditID') as audit_id,
               raw.bucket,
               raw.job,
               raw.data ->> 'level' as event_level,
               raw.data ->> 'stage' as event_stage,
               raw.operation_id,
               -- yops.operation_id,
               -- ops.k8s_action,
               -- ops.http_method,
               -- event_verb_to_http_method(raw.data ->> 'verb') AS operation_verb,
               -- ops.path as op_path,
               raw.data ->> 'verb' as event_verb,
               raw.data ->> 'apiVersion' as api_version,
               raw.data ->> 'requestURI' as request_uri,
               -- Always "Event"
               -- raw.data ->> 'kind' as kind,
               raw.data ->> 'userAgent' as useragent,
               raw.data -> 'user' as event_user,
               raw.data #>> '{objectRef,namespace}' as object_namespace,
               raw.data #>> '{objectRef,resource}' as object_type,
               raw.data #>> '{objectRef,apiGroup}' as object_group,
               raw.data #>> '{objectRef,apiVersion}' as object_ver,
               raw.data -> 'sourceIPs' as source_ips,
               raw.data -> 'annotations' as annotations,
               raw.data -> 'requestObject' as request_object,
               raw.data -> 'responseObject' as response_object,
               raw.data -> 'responseStatus' as response_status,
               raw.data ->> 'stageTimestamp' as stage_timestamp,
               raw.data ->> 'requestReceivedTimestamp' as request_received_timestamp,
               raw.data as data
        FROM raw_audit_event raw;
    #+END_SRC
* Field Coverage
  :PROPERTIES:
  :header-args:sql-mode+: :results silent
  :END:
** 400: kind_field_path recursive view
  :PROPERTIES:
  :header-args:sql-mode+: :tangle ../apps/hasura/migrations/400_view_kind_field_path.up.sql
  :END:
*** kind_field_path_recursion
#+NAME: Recursive kind_field_path view
#+BEGIN_SRC sql-mode
  create or replace recursive view kind_field_path_recursion(
    kind,
    field_path,
    field_kind,
    field_type,
    sub_kind,
    release,
    deprecated,
    gated,
    required
  ) AS
   SELECT DISTINCT
   sf.field_schema AS kind,
   sf.field_name AS field_path, -- this becomes a path
   sf.field_kind AS field_kind,
   sf.field_type AS field_type,
   sf.field_schema AS sub_kind, -- this is the kind at this level
   sf.release AS release,
   sf.deprecated AS deprecated, 
   sf.feature_gated AS feature_gated,
   sf.required AS required
   from api_schema_field sf
   UNION
   SELECT
    kfpr.kind AS kind,
    ( kfpr.field_path || '.' || f.field_name ) AS field_path,
    f.field_kind AS field_kind,
    f.field_type AS field_type,
    CASE
    WHEN f.field_kind = 'string' OR f.field_kind = 'integer' THEN f.field_schema
    ELSE f.field_kind
     END as sub_kind,
    f.release AS release,
    f.deprecated AS deprecated,
    f.feature_gated AS feature_gated,
    f.required AS required
    FROM api_schema_field f
    INNER JOIN kind_field_path_recursion kfpr ON
    f.field_schema = kfpr.field_kind
    AND f.field_kind not like 'io.k8s.apiextensions-apiserver.pkg.apis.apiextensions.%.JSONSchemaProps';
  ;
#+END_SRC

*** kind_field_path_material
#+NAME: kind_field_path material
#+BEGIN_SRC sql-mode
   create materialized view kind_field_path_material AS
   select
     kind,
     field_path AS field_path,
     -- (text2ltree(field_path)) AS field_path, -- results in errors for now
     field_kind AS field_kind,
     field_type,
     sub_kind,
     release,
     deprecated,
     gated,
     required
    from kind_field_path_recursion;
  -- drop materialized view kind_field_path_material cascade;
#+END_SRC
*** kind_field_path_material indexes
#+NAME: kind_field_path_material indexs
#+BEGIN_SRC sql-mode
CREATE INDEX kfpm_kind_idx       ON kind_field_path_material (kind);
CREATE INDEX kfpm_field_path_idx ON kind_field_path_material (field_path);
CREATE INDEX kfpm_field_type_idx ON kind_field_path_material (field_type);
CREATE INDEX kfpm_sub_kind_idx   ON kind_field_path_material (sub_kind);
-- GIST requires ltree
-- CREATE INDEX kfpm_kind_idx       ON kind_field_path_material USING GIST (kind);
-- CREATE INDEX kfpm_field_path_idx ON kind_field_path_material USING GIST (field_path);
-- CREATE INDEX kfpm_field_type_idx ON kind_field_type_material USING GIST (field_type);
-- CREATE INDEX kfpm_sub_kind_idx   ON kind_field_path_material USING GIST (sub_kind);
#+END_SRC

*** kind_field_path view
#+NAME: kind_field_path view
#+BEGIN_SRC sql-mode
  create or replace view kind_field_path AS
  select
    kind,
    field_path,
    field_kind,
    field_type,
    sub_kind,
    release,
    deprecated,
    gated,
    required
   from kind_field_path_material where field_kind not like 'io%';
#+END_SRC

* PodSpec Field Coverage
  :PROPERTIES:
  :header-args:sql-mode+: :results silent
  :END:
** 600: PodSpec Materialized View
  :PROPERTIES:
  :header-args:sql-mode+: :tangle ../apps/hasura/migrations/600_podspec_field_coverage_material.up.sql
  :END:
#+NAME: view podspec_field_coverage_material
#+BEGIN_SRC sql-mode
  CREATE MATERIALIZED VIEW "public"."podspec_field_coverage_material" AS 
  SELECT DISTINCT
    audit_event.operation_id,
    jsonb_object_keys(audit_event.request_object -> 'spec'::text) AS podspec_field,
    count(event_field.event_field) AS hits,
    split_part(audit_event.useragent, '--', 2) as test,
    split_part(audit_event.useragent, '--', 1) as useragent
    FROM audit_event,
         LATERAL
           jsonb_object_keys(audit_event.request_object -> 'spec'::text)
           event_field(event_field)
   WHERE (audit_event.request_object ->> 'kind'::text) = 'Pod'::text
     AND audit_event.operation_id !~~ '%alpha%'::text
     AND audit_event.operation_id !~~ '%beta%'::text
   GROUP BY operation_id, podspec_field, useragent
  UNION
  SELECT DISTINCT
    audit_event.operation_id,
    jsonb_object_keys(audit_event.request_object -> 'template' -> 'spec'::text) AS podspec_field,
    count(event_field.event_field) AS hits,
    split_part(audit_event.useragent, '--', 2) as test,
    split_part(audit_event.useragent, '--', 1) as useragent
    FROM audit_event,
         LATERAL
           jsonb_object_keys(audit_event.request_object -> 'template' -> 'spec'::text)
           event_field(event_field)
   WHERE (audit_event.request_object ->> 'kind'::text) = 'PodTemplate'::text
     AND audit_event.operation_id !~~ '%alpha%'::text
     AND audit_event.operation_id !~~ '%beta%'::text
   GROUP BY operation_id, podspec_field, useragent
  UNION
  SELECT DISTINCT
    audit_event.operation_id,
    jsonb_object_keys(audit_event.request_object -> 'spec' -> 'template' -> 'spec'::text) AS podspec_field,
    count(event_field.event_field) AS hits,
    split_part(audit_event.useragent, '--', 2) as test,
    split_part(audit_event.useragent, '--', 1) as useragent
    FROM audit_event,
         LATERAL
           jsonb_object_keys(audit_event.request_object -> 'spec' -> 'template' -> 'spec'::text)
           event_field(event_field)
   WHERE (audit_event.request_object->>'kind' = 'DaemonSet'
     OR  audit_event.request_object->>'kind' = 'Deployment'
     OR  audit_event.request_object->>'kind' = 'ReplicationController'
     OR  audit_event.request_object->>'kind' = 'StatefulSet'
     OR  audit_event.request_object->>'kind' = 'Job'
     OR  audit_event.request_object->>'kind' = 'ReplicaSet')
     AND audit_event.operation_id !~~ '%alpha%'::text
     AND audit_event.operation_id !~~ '%beta%'::text
   GROUP BY operation_id, podspec_field, useragent;
#+END_SRC
** 601: PodSpec Field Coverage View
  :PROPERTIES:
  :header-args:sql-mode+: :tangle ../apps/hasura/migrations/601_view_podspec_field_coverage.up.sql
  :END:
#+NAME: view podspec_field_coverage
#+BEGIN_SRC sql-mode
create view podspec_field_coverage as select * from podspec_field_coverage_material;
#+END_SRC
** 602: PodSpec Field Summary View
  :PROPERTIES:
  :header-args:sql-mode+: :tangle ../apps/hasura/migrations/602_view_podspec_field_summary.up.sql
  :END:
#+NAME: view podspec_field_summary
#+BEGIN_SRC sql-mode
  create view podspec_field_summary as
  select distinct field_name as podspec_field,
                  0 as other_hits,
                  0 as e2e_hits,
                  0 as conf_hits
    from api_schema_field
   where field_schema like '%PodSpec%'
   UNION
  select
    podspec_field,
    sum(hits) as other_hits,
    0 as e2e_hits,
    0 as conf_hits
    from podspec_field_coverage
   where useragent not like 'e2e.test%'
   group by podspec_field
   UNION
  select
    podspec_field,
    0 as other_hits,
    sum(hits) as e2e_hits,
    0 as conf_hits
    from podspec_field_coverage
   where useragent like 'e2e.test%'
     and test not like '%Conformance%'
   group by podspec_field
   UNION
  select
    podspec_field,
    0 as other_hits,
    0 as e2e_hits,
    sum(hits) as conf_hits
    from podspec_field_coverage
   where useragent like 'e2e.test%'
     and test like '%Conformance%'
   group by podspec_field;
#+END_SRC
** 604: PodSpec Field Review View
  :PROPERTIES:
  :header-args:sql-mode+: :tangle ../apps/hasura/migrations/604_view_podspec_field_report.up.sql
  :END:
#+NAME: podspec_field_hits
#+BEGIN_SRC sql-mode
  create or replace view podspec_field_report as
  select distinct podspec_field,
        sum(other_hits) as other_hits,
        sum(e2e_hits) as e2e_hits,
        sum(conf_hits) as conf_hits,
        kfp.release,
        kfp.deprecated,
        kfp.gated,
        kfp.required
  from podspec_field_summary pfs, kind_field_path kfp
  where kfp.field_type not like 'io%'
    and kfp.kind like '%PodSpec'
    and kfp.sub_kind like '%PodSpec'
    and pfs.podspec_field = regexp_replace(kfp.field_path, '.*\.','') 
  group by podspec_field, kfp.release, kfp.deprecated, kfp.gated, kfp.required
  order by conf_hits, e2e_hits, other_hits;
#+END_SRC

* Apps
** .env
#+BEGIN_SRC shell :tangle ../apps/.env_sample
  PGADMIN_PORT=9001
  HASURA_PORT=9000
  # UID based PGPORT used to expose per user postgresql ports on same box
  PGPORT=54321
  PGHOST=localhost
  PGUSER=apisnoop
  PGPASS=s3cr3tsauc3
  PGDATABASE=apisnoop
  CONN="host=127.0.0.1 port=54321 user=apisnoop dbname=apisnoop password=s3cr3tsauc3 sslmode=disable client_encoding=UTF8"
#+END_SRC
** .loadenv
#+NAME: .loadenv
#+BEGIN_SRC shell :tangle ../apps/.loadenv
  # If we are on sharing.io, use UID based *_PORTs
  if [ $(hostname) = "sharing.io" ]
  then
      # Overwriting .env based on \*-${USER}.sharing.io
      echo Using sharing.io setup 1>&2
  (
      # UID based *_PORT used to expose per user postgresql,hasura, and pgadmin ports on same box
      if [ "$KOMPOSE" = "true" ]
      then
              echo Using kompose https://$USER-hasura.apisnoop.io 1>&2
              echo PGPORT=5432
              echo HASURA_PORT=8080
              echo endpoint: https://$USER-hasura.apisnoop.io > $PWD/hasura/config.yaml
      else
              echo Using docker-compose https://$USER-hasura.sharing.io 1>&2
              echo PGPORT=$(id -u)1
              echo HASURA_PORT=$(id -u)0
              echo endpoint: https://$USER-hasura.sharing.io > $PWD/hasura/config.yaml
      fi

      # for running in docker-compose, different localhost:port per user id same
      # for running in docker-compose, different localhost:port per user id same
      # echo PG_CONTAINER_PORT=$PGPORT
      # for running in kompose
      echo PGADMIN_PORT=$(id -u)2
      echo PGHOST=localhost
      echo PGDATABASE=apisnoop
      echo PGUSER=apisnoop
      echo PGPASS=s3cr3tsauc3
      echo PGPASSFILE=$PWD/pgpass
      echo COMPOSE_PROJECT_NAME=apisnoop_$USER
      TAG=$(TZ='Pacific/Auckland'; export TZ ; date +%F-%H-%M)
      echo TAG=$TAG
      # echo HASURA_IMAGE=raiinbow/hasura:$TAG
      # echo POSTGRES_IMAGE=raiinbow/postgres:$TAG
      # echo $PGHOST:$PGPORT:$PGDATABASE:$PGUSER:$PGPASS > $PWD/pgpass
      echo GOOGLE_APPLICATION_CREDENTIALS=$HOME/.gcreds.json
      echo GKS_ZONE="australia-southeast1-a"
      echo GCS_CLUSTER="single-node-cluster"
      echo APISNOOP_NAMESPACE="apisnoop-$USER"
      echo TRAEFIK_NAMESPACE="kube-system"
      echo TRAEFIK_DEPLOYMENT="ii-traefik"
  ) > .env
      export $(grep -v '^#' .env | xargs -d '\n')
      gcloud container clusters get-credentials ${GCS_CLUSTER} --zone ${GKS_ZONE} 2> /dev/null || echo cluster gcreds error
      kubectl config set-context $(kubectl config current-context) --namespace=${APISNOOP_NAMESPACE} 2>&1 > /dev/null
  else
      cp .env_sample .env
      cp hasura/config_sample.yaml hasura/config.yaml
      export $(grep -v '^#' .env | xargs -d '\n')
  fi

  PGPASSFILE=$(pwd)/pgpass
  echo $PGHOST:$PGPORT:$PGDATABASE:$PGUSER:$PGPASS > $PGPASSFILE
  chmod 600 $PGPASSFILE
  export CONN="host=127.0.0.1 port=$PGPORT user=$PGUSER dbname=$PGDATABASE password=$PGPASS sslmode=disable client_encoding=UTF8"
#+END_SRC

** Hasura
*** Tracking Tables
    :PROPERTIES:
    :header-args:yaml+: :tangle ../apps/hasura/migrations/999_tracking.up.yaml
    :END:
**** api_swagger
 #+NAME: track api_swagger
 #+BEGIN_SRC yaml
 - type: track_table
   args:
     schema: public
     name: api_swagger
 #+END_SRC
**** api_operation
 #+NAME: track api_operation
 #+BEGIN_SRC yaml
 - type: track_table
   args:
     schema: public
     name: api_operation
 #+END_SRC

**** api_operation_parameter

  #+NAME: track api_operation_parameter
  #+BEGIN_SRC yaml
  - type: track_table
    args:
      schema: public
      name: api_operation_parameter
  #+END_SRC
**** api_operation_response
  #+NAME: track api_operation_response
  #+BEGIN_SRC yaml
  - type: track_table
    args:
      schema: public
      name: api_operation_response
  #+END_SRC

**** api_schema
  #+NAME: track api_schema
  #+BEGIN_SRC yaml
  - type: track_table
    args:
      schema: public
      name: api_schema
  #+END_SRC

**** api_schema_field
 #+NAME: track api_schema_field
 #+BEGIN_SRC yaml
 - type: track_table
   args:
     schema: public
     name: api_schema_field
 #+END_SRC

**** over
  #+NAME: track over
  #+BEGIN_SRC yaml :tangle no
  - type: track_table
    args:
      schema: public
      name: over
  #+END_SRC
**** raw_audit_event
 #+NAME: track raw_audit_event
 #+BEGIN_SRC yaml
 - type: track_table
   args:
     schema: public
     name: raw_audit_event
 #+END_SRC
**** audit_event
  #+NAME: track audit_event
  #+BEGIN_SRC yaml
  - type: track_table
    args:
      schema: public
      name: audit_event
  #+END_SRC

**** kind_field_path
  #+NAME: track kind_field_path
  #+BEGIN_SRC yaml
  - type: track_table
    args:
      schema: public
      name: kind_field_path
  #+END_SRC

**** kind_field_path_recursion
  #+NAME: track kind_field_path_recursion
  #+BEGIN_SRC yaml
  - type: track_table
    args:
      schema: public
      name: kind_field_path_recursion
  #+END_SRC

**** podspec_field_coverage
  #+NAME: track podspec_field_coverage
  #+BEGIN_SRC yaml
  - type: track_table
    args:
      schema: public
      name: podspec_field_coverage
  #+END_SRC

**** podspec_field_summary
  #+NAME: track podspec_field_summary
  #+BEGIN_SRC yaml
  - type: track_table
    args:
      schema: public
      name: podspec_field_summary
  #+END_SRC

**** podspec_field_report
  #+NAME: track podspec_field_report
  #+BEGIN_SRC yaml
  - type: track_table
    args:
      schema: public
      name: podspec_field_report
  #+END_SRC

*** config.yml

#+NAME: hasura config sample
#+BEGIN_SRC text :tangle ../apps/hasura/config_sample.yaml :noweb yes
endpoint: http://localhost:9000
#+END_SRC
*** Dockerfile
#+NAME: apisnoop hasura dockerfile
#+BEGIN_SRC dockerfile :tangle ../apps/hasura/Dockerfile
  FROM hasura/graphql-engine:v1.0.0-beta.6.cli-migrations
  # FROM hasura/graphql-engine:v1.0.0-beta.6
  MAINTAINER Hippie Hacker <hh@ii.coop>
  COPY ./migrations /hasura-migrations
#+END_SRC
** Postgres
*** init-apisnoop-db.sh

 #+NAME: init apisnoop db
 #+BEGIN_SRC sql-mode :tangle ../apps/postgres/initdb/apisnoop_db.sql
   -- ERROR:  database "apisnoop" already exists
   -- create database apisnoop;
   -- create user myuser with encrypted password 'mypass';
   grant all privileges on database apisnoop to apisnoop;
   create role dba with superuser noinherit;
   grant dba to apisnoop;
   \connect apisnoop
   -- we generate uuids
   CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
   -- we write python functions
   CREATE EXTENSION IF NOT EXISTS plpython3u;
   -- we write shell functions
   CREATE EXTENSION IF NOT EXISTS plsh;
   -- regex indexes required trgm
   CREATE EXTENSION IF NOT EXISTS pg_trgm;
   -- paths need an index too
   CREATE EXTENSION IF NOT EXISTS ltree;
   -- hasura needs hash functions
   CREATE EXTENSION IF NOT EXISTS pgcrypto;
   -- hasura db catalog and views
   CREATE SCHEMA IF NOT EXISTS hdb_catalog;
   CREATE SCHEMA IF NOT EXISTS hdb_views;
   -- make the user an owner of system schemas
   ALTER SCHEMA hdb_catalog OWNER TO apisnoop;
   ALTER SCHEMA hdb_views OWNER TO apisnoop;
   GRANT SELECT ON ALL TABLES IN SCHEMA information_schema TO apisnoop;
   GRANT SELECT ON ALL TABLES IN SCHEMA pg_catalog TO apisnoop;
   GRANT USAGE ON SCHEMA public TO apisnoop;
   GRANT ALL ON ALL TABLES IN SCHEMA public TO apisnoop;
   GRANT ALL ON ALL SEQUENCES IN SCHEMA public TO apisnoop;
   GRANT pg_execute_server_program TO apisnoop;
 #+END_SRC
*** Dockerfile
#+BEGIN_SRC dockerfile :tangle ../apps/postgres/Dockerfile
  FROM postgres:11.5
  MAINTAINER Hippie Hacker <hh@ii.coop>
  RUN apt-get update \
    && apt-get install -y --no-install-recommends \
    postgresql-plpython3-11 \
    postgresql-11-plsh \
    python3-bs4\
    python3-requests \
    wget \
    make \
    gcc \
    libc6-dev \
    curl \
    jq \
    git \
    software-properties-common \
    apt-transport-https
  #  && rm -rf /var/lib/apt/lists/*

  RUN curl -L https://dl.google.com/go/go1.12.4.linux-amd64.tar.gz \
    | tar -C /usr/local -xzf - \
    && echo 'export PATH=$PATH:/usr/local/go/bin' \
    > /etc/profile.d/usr-local-go-path.sh \
    && echo 'export PATH=$PATH:$HOME/go/bin' \
    > /etc/profile.d/homedir-go-path.sh
  RUN . /etc/profile.d/usr-local-go-path.sh \
    && . /etc/profile.d/homedir-go-path.sh \
    && go get github.com/golangci/gofmt/gofmt \
    && go get -u golang.org/x/lint/golint \
    && go get golang.org/x/tools/cmd/goimports \
    && go get github.com/jgautheron/goconst/cmd/goconst \
    && go get github.com/jgautheron/usedexports \
    && go get -u github.com/kisielk/errcheck \
    && go get github.com/ii/apisnoopregexp \
    && cd ~/go/src/github.com/ii/apisnoopregexp \
    && make install \
    && cp ~/go/bin/rmatch /usr/local/bin
  COPY ./initdb /docker-entrypoint-initdb.d
  HEALTHCHECK --interval=10s --timeout=5s --start-period=5s --retries=5 \
    CMD pg_isready -U apisnoop || exit 1
 # RUN sed -i -e"s/^#logging_collector = off.*$/logging_collector = on/" /var/lib/postgresql/data/postgresql.conf

#+END_SRC

** pgadmin
*** servers.json
# python setup.py --dump-servers /tmp/server.json --user apisnoop@cncf.io
#+NAME: pgadmin default servers config
#+BEGIN_SRC json :tangle ../apps/pgadmin/servers.json
  {
      "Servers": {
          "1": {
              "Name": "apisnoop",
              "Group": "Servers",
              "Host": "postgres",
              "Port": 5432,
              "MaintenanceDB": "postgres",
              "Username": "apisnoop",
              "SSLMode": "prefer",
              "SSLCert": "<STORAGE_DIR>/.postgresql/postgresql.crt",
              "SSLKey": "<STORAGE_DIR>/.postgresql/postgresql.key",
              "SSLCompression": 0,
              "Timeout": 0,
              "UseSSHTunnel": 0,
              "TunnelPort": "22",
              "TunnelAuthentication": 0
          }
      }
  }
#+END_SRC

** docker-compose.yml

#+NAME: hasura docker-compose
#+BEGIN_SRC yaml :tangle ../apps/docker-compose.yml
  # hasura/docker-compose.yaml
  # Kompose Note: We don’t support anything 3.4 and above at the moment
  version: "3"
  services:
    postgres:
      # image: postgres:11.5 # debian-slim / alternative: postgres:11.5-alpine
      # we need our image to include plpython3u
      image: "raiinbow/postgres:${TAG}"
      build: "./postgres"
        # dockerfile: postgres/Dockerfile
        # context: .
      container_name: "${USER}-postgres"
      restart: always
      shm_size: '64GB' # we currently use big boxes
      #cap_add: # capabilities
      #  - ALL
      environment:
        # These are postgres server setup options
        - POSTGRES_DB=${PGDATABASE}
        - POSTGRES_USER=${PGUSER}
        - POSTGRES_PASSWORD=${PGPASS}
        # - PGDATA=/dev/shm/pgdata
        # - POSTGRES_PASSWORD_FILE="/run/secrets/postgres-passwd" # k8s secret style
        # - POSTGRES_INITDB_ARGS=""
        # - POSTGRES_INITDB_WALDIR=""
        # - PGDATA="/var/lib/postgresql/data/"
        # These are psql client defaults
        - PGDATABASE=${PGDATABASE}
        - PGUSER=${PGUSER}
      #volumes:
        # runs *sql and executable *sh and sources non-executable *sh
        # - ./postgres/initdb:/docker-entrypoint-initdb.d:Z
        # mainly mounted for debugging
        #- ./hasura/migrations:/migrations:Z
      healthcheck:
        test: ["CMD-SHELL", "pg_isready -U $PGUSER"]
        interval: 10s
        timeout: 5s
        retries: 5
      ports: # exposed to docker host
        - "${PGPORT}:5432"
      # Expose ports without publishing them to the host machine
      # - they’ll only be accessible to linked services.
      expose: # exposed to other containers
        - "${PGPORT}"
      networks: # separate from web due to traefik routing on sharing.io
        - db
      labels:
        ingress.class: "traefik"
        kompose.controller.type: "deployment" # or daemonset or replicationcontroller
        # kompose.service.type: "loadbalancer" # nodeport / clusterip / loadbalancer / headless
        # kompose.service.expose: true
        # Maybe see if kompose can work with let's encrypt
        #- "kompose.service.expose.tls-secret="
        # kompose.volume.size: 1Gi
        # traefik.enable: "true"
        # traefik.basic.port: 8080
        # traefik.basic.protocol: "http"
        # traefik.basic.frontend.rule: "Host:${USER}-hasura.sharing.io"
    hasura:
      #image: hasura/graphql-engine:v1.0.0-beta.5
      #image: hasura/graphql-engine:v1.0.0-beta.5.cli-migrations
      image: "raiinbow/hasura:${TAG}"
      build: "./hasura"
      # build:
      #   dockerfile: hasura/Dockerfile
      #   context: .
      #   image: "raiinbow/hasura:${USER}"
      container_name: "${USER}-hasura"
      restart: always
      networks:
        - web
        - db
      environment:
        - HASURA_GRAPHQL_DATABASE_URL=postgres://${PGUSER}:${PGPASS}@postgres:5432/${PGDATABASE}
        - HASURA_GRAPHQL_ENABLE_CONSOLE=true
      # volumes:
      #   - ./hasura/migrations:/hasura-migrations:Z
      depends_on:
        - postgres
      ports: # exposed to docker host
        - "${HASURA_PORT}:8080"
      expose:
        - "8080"
      labels:
        kompose.controller.type: "deployment" # or daemonset or replicationcontroller
        kompose.service.type: "headless" # necessary for traefik
        # kompose.service.type: "clusterip" # nodeport / clusterip / loadbalancer / headless
        # kompose.service.type: "loadbalancer" # nodeport / clusterip / loadbalancer / headless
        # kompose.service.type: "nodeport" # nodeport / clusterip / loadbalancer / headless
        kompose.service.expose: "${USER}-hasura.apisnoop.io" # true / hostname
        ingress.kubernetes.io/protocol: "http"
        kubernetes.io/ingress.class: "traefik"
        # Maybe see if kompose can work with let's encrypt
        #- "kompose.service.expose.tls-secret="
        # kompose.volume.size: 1Gi
        traefik.docker.network: "web"
        traefik.enable: "true"
        traefik.basic.port: 8080
        traefik.basic.protocol: "http"
        traefik.basic.frontend.rule: "Host:${USER}-hasura.sharing.io"
    # pgadmin:
    #   container_name: "${USER}-pgadmin"
    #   image: dpage/pgadmin4:4.12
    #   restart: always
    #   networks:
    #     - db
    #     - web
    #   environment:
    #     - PGADMIN_DEFAULT_EMAIL=apisnoop@cncf.io
    #     - PGADMIN_DEFAULT_PASSWORD=${PGPASS}
    #     # python setup.py --dump-servers /tmp/servers.json --user apisnoop@cncf.io
    #     - PGADMIN_SERVER_JSON_FILE=/apisnoop/servers.json
    #     - PGADMIN_CONFIG_APP_NAME=APISnoopQL
    #     - PGADMIN_CONFIG_APP_COPYRIGHT="Copyright (C) 2019, The Cloud Native Compute Foundation"
    #     - PGADMIN_CONFIG_LOGIN_BANNER="Welcome to APISnoopQL!"
    #     - PGADMIN_CONFIG_ALLOW_SAVE_PASSWORD=True
    #     - PGADMIN_CONFIG_MAX_QUERY_HIST_STORED=1234
    #     - PGADMIN_CONFIG_SESSION_COOKIE_NAME=apisnoop_session
    #     - PGADMIN_CONFIG_UPGRADE_CHECK_ENABLED=False
    #     - PGADMIN_CONFIG_SESSION_EXPIRATION_TIME=7
    #   volumes:
    #    - ./pgadmin:/apisnoop:Z
    #   ports: # exposed to docker host
    #     - "${PGADMIN_PORT}:80"
    #   expose:
    #     - "80"
    #   labels:
    #     - "traefik.docker.network=web"
    #     - "traefik.enable=true"
    #     - "traefik.basic.port=80"
    #     - "traefik.basic.protocol=http"
    #     - "traefik.basic.frontend.rule=Host:${USER}-pgadmin.sharing.io"
  #volumes:
  #  migrations:
  networks:
    web:
      external: true
    db:
#+END_SRC

* Footnotes
** Local Variables

Force this instance of emacs to use the apisnoop server-name.
This allows us to tangle from the emacsclient cli.

# Local Variables:
# eval: (setq server-name "apisnoop")
# eval: (server-force-delete)
# eval: (server-start)
# End:
 
 
 
