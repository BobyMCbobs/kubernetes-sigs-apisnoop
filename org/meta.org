#+NAME: META
#+TODO: TODO(t) NEXT(n) IN-PROGRESS(i) BLOCKED(b) | TADA(d)

* Purpose
  This holds the authorative way to get setup and exploring with our hasura backend.

* Working with this repo/org file** Work happens in Org first
   Within ii, our emphasis is on the documentation/org-file first.  
   We can document and craft the queries for our db, then tangle them into our migration files.
   as such: 
   *NOTE: Don't commit the hasura/migrations, they should be tangled from the org file.*
   In the future, we may add a commit hook that tangles org => hasura
* Iteration Loop
** listing tables
#+BEGIN_SRC sql-mode
\conninfo
\d+
#+END_SRC

#+RESULTS:
#+begin_src sql-mode
You are connected to database "zz" as user "zz" on host "172.17.0.1" at port "5432".
SSL connection (protocol: TLSv1.3, cipher: TLS_AES_256_GCM_SHA384, bits: 256, compression: off)
Did not find any relations.
#+end_src

** dropping all data
#+NAME: do not run
#+BEGIN_SRC sql-mode :eval ask
  drop table raw_swaggers cascade;
  drop table raw_audit_events cascade;
  drop schema hdb_catalog cascade;
  drop schema hdb_views cascade;
#+END_SRC

#+RESULTS: do not run
#+begin_src sql-mode
ERROR:  table "raw_swaggers" does not exist
DROP TABLE
ERROR:  schema "hdb_catalog" does not exist
ERROR:  schema "hdb_views" does not exist
#+end_src

** Restart Hasura
   #+BEGIN_SRC tmate
     cd ~/ii/apisnoop_v3/hasura
     docker-compose down
     docker-compose up
   #+END_SRC

** setting up the hasura postgresql-permissions
   
Run the following as the postgres user via psql:
https://docs.hasura.io/1.0/graphql/manual/deployment/postgres-permissions.html

#+NAME: hasura-user
#+BEGIN_SRC shell :results silent
echo -n $USER
#+END_SRC

#+NAME: create database and granting all privs to a user
#+BEGIN_SRC sql-mode :noweb yes :tangle ../apps/hasura/db_setup.sql
create database <<hasura-user()>>;
-- create user myuser with encrypted password 'mypass';
grant all privileges on database <<hasura-user()>> to <<hasura-user()>>;
create role dba with superuser noinherit;
grant dba to <<hasura-user()>>;
\connect <<hasura-user()>>
-- we write python functions
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS plpython3u;
CREATE EXTENSION IF NOT EXISTS plsh;
CREATE EXTENSION IF NOT EXISTS pgcrypto;
CREATE SCHEMA IF NOT EXISTS hdb_catalog;
CREATE SCHEMA IF NOT EXISTS hdb_views;
-- make the user an owner of system schemas
ALTER SCHEMA hdb_catalog OWNER TO <<hasura-user()>>;
ALTER SCHEMA hdb_views OWNER TO <<hasura-user()>>;
GRANT SELECT ON ALL TABLES IN SCHEMA information_schema TO <<hasura-user()>>;
GRANT SELECT ON ALL TABLES IN SCHEMA pg_catalog TO <<hasura-user()>>;
GRANT USAGE ON SCHEMA public TO <<hasura-user()>>;
GRANT ALL ON ALL TABLES IN SCHEMA public TO <<hasura-user()>>;
GRANT ALL ON ALL SEQUENCES IN SCHEMA public TO <<hasura-user()>>;
GRANT pg_execute_server_program TO <<hasura-user()>>;
#+END_SRC

#+RESULTS: create database and granting all privs to a user
#+begin_src sql-mode
ERROR:  database "zz" already exists
WARNING:  no privileges were granted for "zz"
GRANT
ERROR:  must be superuser to create superusers
ERROR:  must be superuser to alter superusers
SSL connection (protocol: TLSv1.3, cipher: TLS_AES_256_GCM_SHA384, bits: 256, compression: off)
You are now connected to database "zz" as user "zz".
NOTICE:  extension "uuid-ossp" already exists, skipping
CREATE EXTENSION
NOTICE:  extension "plpython3u" already exists, skipping
CREATE EXTENSION
ERROR:  permission denied to create extension "plsh"
HINT:  Must be superuser to create this extension.
NOTICE:  extension "pgcrypto" already exists, skipping
CREATE EXTENSION
NOTICE:  schema "hdb_catalog" already exists, skipping
CREATE SCHEMA
NOTICE:  schema "hdb_views" already exists, skipping
CREATE SCHEMA
ALTER SCHEMA
ALTER SCHEMA
WARNING:  no privileges were granted for "sql_features"
WARNING:  no privileges were granted for "sql_implementation_info"
WARNING:  no privileges were granted for "sql_languages"
WARNING:  no privileges were granted for "sql_packages"
WARNING:  no privileges were granted for "sql_parts"
WARNING:  no privileges were granted for "sql_sizing"
WARNING:  no privileges were granted for "sql_sizing_profiles"
WARNING:  no privileges were granted for "collations"
WARNING:  no privileges were granted for "collation_character_set_applicability"
WARNING:  no privileges were granted for "column_domain_usage"
WARNING:  no privileges were granted for "constraint_column_usage"
WARNING:  no privileges were granted for "domains"
WARNING:  no privileges were granted for "constraint_table_usage"
WARNING:  no privileges were granted for "domain_constraints"
WARNING:  no privileges were granted for "role_column_grants"
WARNING:  no privileges were granted for "enabled_roles"
WARNING:  no privileges were granted for "referential_constraints"
WARNING:  no privileges were granted for "parameters"
WARNING:  no privileges were granted for "routine_privileges"
WARNING:  no privileges were granted for "role_routine_grants"
WARNING:  no privileges were granted for "routines"
WARNING:  no privileges were granted for "schemata"
WARNING:  no privileges were granted for "table_constraints"
WARNING:  no privileges were granted for "sequences"
WARNING:  no privileges were granted for "triggered_update_columns"
WARNING:  no privileges were granted for "table_privileges"
WARNING:  no privileges were granted for "role_table_grants"
WARNING:  no privileges were granted for "triggers"
WARNING:  no privileges were granted for "tables"
WARNING:  no privileges were granted for "transforms"
WARNING:  no privileges were granted for "role_udt_grants"
WARNING:  no privileges were granted for "udt_privileges"
WARNING:  no privileges were granted for "role_usage_grants"
WARNING:  no privileges were granted for "usage_privileges"
WARNING:  no privileges were granted for "user_defined_types"
WARNING:  no privileges were granted for "view_column_usage"
WARNING:  no privileges were granted for "view_routine_usage"
WARNING:  no privileges were granted for "view_table_usage"
WARNING:  no privileges were granted for "views"
WARNING:  no privileges were granted for "data_type_privileges"
WARNING:  no privileges were granted for "user_mapping_options"
WARNING:  no privileges were granted for "element_types"
WARNING:  no privileges were granted for "_pg_foreign_table_columns"
WARNING:  no privileges were granted for "column_options"
WARNING:  no privileges were granted for "_pg_foreign_data_wrappers"
WARNING:  no privileges were granted for "foreign_data_wrapper_options"
WARNING:  no privileges were granted for "user_mappings"
WARNING:  no privileges were granted for "foreign_data_wrappers"
WARNING:  no privileges were granted for "_pg_foreign_servers"
WARNING:  no privileges were granted for "foreign_server_options"
WARNING:  no privileges were granted for "foreign_servers"
WARNING:  no privileges were granted for "_pg_foreign_tables"
WARNING:  no privileges were granted for "key_column_usage"
WARNING:  no privileges were granted for 
#+end_src

#+NAME: as posgres admin, setup hasura user and db
#+BEGIN_SRC tmate
#+BEGIN_SRC shell  :var SUDO_ASKPASS="/usr/bin/ssh-askpass" :prologue "export SUDO_ASKPASS"
# :var DISPLAY=":0.0"
sudo su - postgres -c psql < ~/ii/apisnoop_v3/apps/hasura/db_setup.sql
#+END_SRC

#+RESULTS: as posgres admin, setup hasura user and db
#+begin_EXAMPLE
#+end_EXAMPLE

* Hasura
** config.yaml

Can be used by itself to run hasura cli or console from another host

#+BEGIN_SRC yaml :tangle ../apps/hasura/config.yaml
endpoint: http://sharing.io:8888
#+END_SRC

** docker-compose.yml
#+BEGIN_SRC yaml :tangle ../apps/hasura/docker-compose.yaml
  # hasura/docker-compose.yaml
  version: "3.7"

  services:
   hasura:
      #image: hasura/graphql-engine:v1.0.0-beta.3
      # append '.cli-migrations' to auto run 'hasura migrations apply'
      container_name: "${USER}-hasura"
      image: hasura/graphql-engine:v1.0.0-beta.4.cli-migrations
      restart: always
      networks:
        - web
      environment:
        # Should try and set database be read only for public
        #- HASURA_GRAPHQL_DATABASE_URL=postgres://non-priv-user@172.17.0.1:5432/database-name
        #- HASURA_GRAPHQL_DATABASE_URL=postgres://non-priv-user@172.17.0.1:5432/$OUTER-USER
        # https://docs.docker.com/compose/compose-file/#variable-substitution
        # https://docs.docker.com/compose/env-file/
        - "HASURA_GRAPHQL_DATABASE_URL=postgres://${USER}@172.17.0.1:5432/${USER}"
        - HASURA_GRAPHQL_ENABLE_CONSOLE=true
      volumes:
        - ./migrations:/hasura-migrations
      expose:
        - "8080"
      labels:
        - "traefik.docker.network=web"
        - "traefik.enable=true"
        - "traefik.basic.port=8080"
        - "traefik.basic.protocol=http"
        - "traefik.basic.frontend.rule=Host:${USER}-hasura.sharing.io"
  #volumes:
  #  migrations:
  networks:
    web:
      external: true
#+END_SRC

** start hasura

#+BEGIN_SRC shell :dir hasura
docker-compose up -d
#+END_SRC

#+RESULTS:
#+begin_EXAMPLE
#+end_EXAMPLE
** Watch hasura logs

#+BEGIN_SRC emacs-lisp
    (defun hasura-logs ()
      (interactive)
      (setq *hasura-buffer*
            (get-buffer-create "hasura-logs"))
      (with-current-buffer *hasura-buffer*
        (ansi-color-for-comint-mode-on)
        (comint-mode)
        (spacemacs/toggle-line-numbers-on)
       ;; (linum-mode t)
        )
      (let ((default-directory (file-name-directory (concat (file-name-directory buffer-file-name) "../hasura/")))
            (logs-command "docker-compose logs -f --no-color")
            ;; (logs-command "tail -f /var/log/messages")
            ;;(logs-command "docker-compose logs -f --no-color 2>/dev/null | sed 's:hasura_1  | ::g' | grep '^{' | jq .")
            )
        (setq *hasura-process*
              (start-file-process-shell-command
               "hasura" *hasura-buffer* logs-command))
        (set-process-filter *hasura-process* 'comint-output-filter)
  )
      )
    (hasura-logs)
    ;; unsure how to display
    ;; (add-to-list 'display-buffer-alist
    ;;            '("hasura-logs" . ((display-buffer-pop-up-window) .
    ;;                               ((inhibit-same-window . t)))))
    ;; (
    ;; display-buffer (get-buffer "hasura-logs") nil)
    ;; "docker-compose logs -f| jq .")
#+END_SRC

#+RESULTS:
#+begin_src emacs-lisp
comint-output-filter
#+end_src

* OpenAPI / Swagger Table
** swagger.json

#+NAME: raw_swaggers
#+BEGIN_SRC sql-mode :tangle ../apps/hasura/migrations/100_table_raw_swaggers.up.sql
CREATE TABLE raw_swaggers (
    id int GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    ingested_at timestamp DEFAULT CURRENT_TIMESTAMP,
    -- version text NOT NULL,
    -- definition_id text NOT NULL,
    data jsonb NOT NULL
);
#+END_SRC

#+RESULTS: raw_swaggers
#+begin_src sql-mode
ERROR:  relation "raw_swaggers" already exists
#+end_src

#+NAME: track raw_swaggers
#+BEGIN_SRC yaml :tangle ../apps/hasura/migrations/100_table_raw_swaggers.up.yaml
- type: track_table
  args:
    schema: public
    name: raw_swaggers
#+END_SRC

** load swagger via curl

#+NAME: load_swagger_via_curl.py
#+BEGIN_SRC python :eval never
  # should probably sanitize branch_or_tag
  try:
      from string import Template
      sql = Template("copy raw_swaggers (data) FROM PROGRAM '$curl' (DELIMITER e'\x02', FORMAT 'csv', QUOTE e'\x01');").substitute(
          curl =  f'curl https://raw.githubusercontent.com/kubernetes/kubernetes/{branch_or_tag}/api/openapi-spec/swagger.json | jq -c .'
      )
      rv = plpy.execute(sql)
      return "it worked"
  except:
      return "something went wrong"
#+END_SRC

#+NAME: load_swagger_via_curl.sql
#+BEGIN_SRC sql-mode :noweb yes :tangle ../apps/hasura/migrations/120_function_load_swagger_via_curl.up.sql
  set role dba;
  CREATE OR REPLACE FUNCTION load_swagger_via_curl(branch_or_tag text)
  RETURNS text AS $$
  <<load_swagger_via_curl.py>>
  $$ LANGUAGE plpython3u ;
  reset role;
#+END_SRC

#+RESULTS: load_swagger_via_curl.sql
#+begin_src sql-mode
SET
hh$# hh$# hh$# hh$# hh$# hh$# hh$# hh$# hh$# hh$# hh$# CREATE FUNCTION
RESET
#+end_src

#+BEGIN_SRC sql-mode :noweb yes :tangle ../apps/hasura/migrations/130_populate_swaggers.up.sql
  delete from raw_swaggers;
  select * from load_swagger_via_curl('master');
  -- select * from load_swagger_via_curl('release-1.15');
  -- select * from load_swagger_via_curl('release-1.14');
  -- select * from load_swagger_via_curl('release-1.13');
  -- select * from load_swagger_via_curl('release-1.12');
  -- select * from load_swagger_via_curl('release-1.11');
  -- select * from load_swagger_via_curl('release-1.10');
#+END_SRC

#+RESULTS:
#+begin_src sql-mode
DELETE 1
#+end_src

#+BEGIN_SRC sql-mode
  select count(*) from raw_swaggers;
#+END_SRC

#+RESULTS:
#+begin_src sql-mode
 count 
-------
     1
(1 row)

#+end_src

#+BEGIN_SRC sql-mode
\dt+
#+END_SRC

#+RESULTS:
#+begin_src sql-mode
                      List of relations
 Schema |     Name     | Type  | Owner | Size  | Description 
--------+--------------+-------+-------+-------+-------------
 public | raw_swaggers | table | zz    | 13 MB | 
(1 row)

#+end_src

* Audit Events JSONB Table
** raw_audit_events

#+NAME: raw_audit_events
#+BEGIN_SRC sql-mode :tangle ../apps/hasura/migrations/220_table_raw_audit_events.up.sql
DROP TABLE raw_audit_events;
CREATE TABLE raw_audit_events (
    id int GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    ingested_at timestamp DEFAULT CURRENT_TIMESTAMP,
    bucket text,
    job text,
    data jsonb NOT NULL
);
#+END_SRC

#+RESULTS: raw_audit_events
#+begin_src sql-mode
DROP TABLE
#+end_src

#+NAME: track raw_audit_events
#+BEGIN_SRC yaml :tangle ../apps/hasura/migrations/220_table_raw_audit_events.up.yaml
- type: track_table
  args:
    schema: public
    name: raw_audit_events
#+END_SRC

** load audit_events_via local cli

#+BEGIN_SRC sql-mode
  \d raw_audit_events;
  -- delete from raw_audit_events;
#+END_SRC

#+RESULTS:
#+begin_src sql-mode
                                 Table "public.raw_audit_events"
   Column    |            Type             | Collation | Nullable |           Default            
-------------+-----------------------------+-----------+----------+------------------------------
 id          | integer                     |           | not null | generated always as identity
 ingested_at | timestamp without time zone |           |          | CURRENT_TIMESTAMP
 bucket      | text                        |           |          | 
 job         | text                        |           |          | 
 data        | jsonb                       |           | not null | 
Indexes:
    "raw_audit_events_pkey" PRIMARY KEY, btree (id)

#+end_src


#+NAME: load_audit_events.sh
#+BEGIN_SRC shell :var AUDIT_LOG="../data/artifacts/ci-kubernetes-e2e-gci-gce/1134962072287711234/combined-audit.log"
  SQL="
  CREATE TEMPORARY TABLE raw_audit_events_import (data jsonb not null) ;
  copy raw_audit_events_import (data)
  FROM STDIN (DELIMITER e'\x02', FORMAT 'csv', QUOTE e'\x01');
  INSERT INTO raw_audit_events(data, bucket, job)
  SELECT data, 'ci-kubernetes-e2e-gci-gce', '1134962072287711234'
  FROM raw_audit_events_import;
  "
  cat $AUDIT_LOG | psql -c "$SQL"
#+END_SRC

#+RESULTS: load_audit_events.sh
#+begin_EXAMPLE
INSERT 0 313431
#+end_EXAMPLE

#+BEGIN_SRC sql-mode
  select distinct bucket, job from raw_audit_events;
#+END_SRC

#+RESULTS:
#+begin_src sql-mode
 bucket  | job  
---------+------
 bucket1 | job1
(1 row)

#+end_src

#+BEGIN_SRC sql-mode
\dt+
#+END_SRC

#+RESULTS:
#+begin_src sql-mode
                          List of relations
 Schema |       Name       | Type  | Owner |    Size    | Description 
--------+------------------+-------+-------+------------+-------------
 public | audit_events     | table | zz    | 8192 bytes | 
 public | raw_audit_events | table | zz    | 376 MB     | 
 public | raw_swaggers     | table | zz    | 1752 kB    | 
(3 rows)

#+end_src

* requestObjects
** columns
*** requestkind
#+NAME: requestObject.kind
#+BEGIN_SRC sql-mode
    requestkind text NOT NULL,
#+END_SRC

**** Examples
#+BEGIN_SRC json
"requestObject": {
    "kind": "SubjectAccessReview",
#+END_SRC

#+BEGIN_SRC shell
cat kube-apiserver-audit.log | jq  -r .requestObject.kind | sort | uniq > kinds.txt
cat kube-apiserver-audit.log | jq  -r .responseObject.kind | sort | uniq > rkinds.txt
diff kinds.txt rkinds.txt
#+END_SRC

Only requestObjects include Binding, DeleteOptions, and DeploymentRollback
Only responsesObjects include Status and TokenRequest

#+BEGIN_SRC diff
2d1
< Binding
12d10
< DeleteOptions
14d11
< DeploymentRollback
39a37
> Status
41a40
> TokenRequest
#+END_SRC

*** requestapiversion
#+NAME: requestObject.apiVersion
#+BEGIN_SRC sql-mode
  requestapiversion text NOT NULL,
#+END_SRC
Might be tied to level = request, response etc
**** examples
#+BEGIN_SRC json
"requestObject": {
    "apiVersion": "authorization.k8s.io/v1",
#+END_SRC

I'm not sure here, but I feel like we should only be looking at RequestResponse... not all three.
Huh, that was wrong.. the counts differ wildly:

*** requestmeta
#+NAME: requestObject.metadata
#+BEGIN_SRC sql-mode
  requestmeta jsonb NOT NULL,
#+END_SRC
**** examples
#+BEGIN_SRC json
"requestObject": {
    "metadata": {
      "creationTimestamp": null
    },
#+END_SRC
*** requestspec
#+NAME: requestObject.spec
#+BEGIN_SRC sql-mode
  requestspec jsonb NOT NULL,
#+END_SRC
**** examples
#+BEGIN_SRC json
"requestObject": {
    "spec": {
      "resourceAttributes": {
        "namespace": "kubernetes-dashboard-6069",
        "verb": "use",
        "group": "extensions",
        "resource": "podsecuritypolicies",
        "name": "e2e-test-privileged-psp"
      },
      "user": "system:serviceaccount:kubernetes-dashboard-6069:default"
    },
#+END_SRC
*** requeststatus
#+NAME: requestObject.status
#+BEGIN_SRC sql-mode
  requeststatus jsonb NOT NULL,
#+END_SRC
**** examples
#+BEGIN_SRC json
  "responseObject": {
    "status": {
      "allowed": true,
      "reason": "RBAC: allowed by RoleBinding \"kubernetes-dashboard-6069--e2e-test-privileged-psp/kubernetes-dashboard-6069\" of ClusterRole \"e2e-test-privileged-psp\" to ServiceAccount \"default/kubernetes-dashboard-6069\""
    }
#+END_SRC

** table

We'll just load these as jsonb into the main audit_events table.

From https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.15/

#+BEGIN_EXAMPLE
Resource objects typically have 3 components:

Resource ObjectMeta: This is metadata about the resource, such as its name, type, api version, annotations, and labels. This contains fields that maybe updated both by the end user and the system (e.g. annotations).

ResourceSpec: This is defined by the user and describes the desired state of system. Fill this in when creating or updating an object.

ResourceStatus: This is filled in by the server and reports the current state of the system. In most cases, users don't need to change this.
#+END_EXAMPLE



These have more information
#+BEGIN_SRC json
"requestObject": {
    "kind": "SubjectAccessReview",
    "apiVersion": "authorization.k8s.io/v1",
    "metadata": {
      "creationTimestamp": null
    },
    "spec": {
      "resourceAttributes": {
        "namespace": "kubernetes-dashboard-6069",
        "verb": "use",
        "group": "extensions",
        "resource": "podsecuritypolicies",
        "name": "e2e-test-privileged-psp"
      },
      "user": "system:serviceaccount:kubernetes-dashboard-6069:default"
    },
    "status": {
      "allowed": false
    }
  },
#+END_SRC

* responseObjects
** columns
*** responsekind
#+NAME: responseObject.kind
#+BEGIN_SRC sql-mode
    responsekind text NOT NULL,
#+END_SRC

**** Examples
#+BEGIN_SRC json
"responseObject": {
    "kind": "SubjectAccessReview",
#+END_SRC

#+BEGIN_SRC shell
cat kube-apiserver-audit.log | jq  -r .responseObject.kind | sort | uniq > kinds.txt
cat kube-apiserver-audit.log | jq  -r .responseObject.kind | sort | uniq > rkinds.txt
diff kinds.txt rkinds.txt
#+END_SRC

Only responseObjects include Binding, DeleteOptions, and DeploymentRollback
Only responsesObjects include Status and TokenResponse

#+BEGIN_SRC diff
2d1
< Binding
12d10
< DeleteOptions
14d11
< DeploymentRollback
39a37
> Status
41a40
> TokenResponse
#+END_SRC

*** responseapiversion
#+NAME: responseObject.apiVersion
#+BEGIN_SRC sql-mode
  responseapiversion text NOT NULL,
#+END_SRC
Might be tied to level = response, response etc
**** examples
#+BEGIN_SRC json
"responseObject": {
    "apiVersion": "authorization.k8s.io/v1",
#+END_SRC

I'm not sure here, but I feel like we should only be looking at ResponseResponse... not all three.
Huh, that was wrong.. the counts differ wildly:

*** responsemeta
#+NAME: responseObject.metadata
#+BEGIN_SRC sql-mode
  responsemeta jsonb NOT NULL,
#+END_SRC
**** examples
#+BEGIN_SRC json
"responseObject": {
    "metadata": {
      "creationTimestamp": null
    },
#+END_SRC
*** responsespec
#+NAME: responseObject.spec
#+BEGIN_SRC sql-mode
  responsespec jsonb NOT NULL,
#+END_SRC
**** examples
#+BEGIN_SRC json
"responseObject": {
    "spec": {
      "resourceAttributes": {
        "namespace": "kubernetes-dashboard-6069",
        "verb": "use",
        "group": "extensions",
        "resource": "podsecuritypolicies",
        "name": "e2e-test-privileged-psp"
      },
      "user": "system:serviceaccount:kubernetes-dashboard-6069:default"
    },
#+END_SRC
*** responsestatus
#+NAME: responseObject.status
#+BEGIN_SRC sql-mode
  responsestatus jsonb NOT NULL,
#+END_SRC
**** examples
#+BEGIN_SRC json
  "responseObject": {
    "status": {
      "allowed": true,
      "reason": "RBAC: allowed by RoleBinding \"kubernetes-dashboard-6069--e2e-test-privileged-psp/kubernetes-dashboard-6069\" of ClusterRole \"e2e-test-privileged-psp\" to ServiceAccount \"default/kubernetes-dashboard-6069\""
    }
#+END_SRC

** Notes
#+BEGIN_SRC json
  "responseObject": {
    "kind": "SubjectAccessReview",
    "apiVersion": "authorization.k8s.io/v1",
    "metadata": {
      "creationTimestamp": null
    },
    "spec": {
      "resourceAttributes": {
        "namespace": "kubernetes-dashboard-6069",
        "verb": "use",
        "group": "extensions",
        "resource": "podsecuritypolicies",
        "name": "e2e-test-privileged-psp"
      },
      "user": "system:serviceaccount:kubernetes-dashboard-6069:default"
    },
    "status": {
      "allowed": true,
      "reason": "RBAC: allowed by RoleBinding \"kubernetes-dashboard-6069--e2e-test-privileged-psp/kubernetes-dashboard-6069\" of ClusterRole \"e2e-test-privileged-psp\" to ServiceAccount \"default/kubernetes-dashboard-6069\""
    }
  },
#+END_SRC

* Operation Views
** api_operations view
*** regex_from_path function
#+NAME: regex_from_path.py
#+BEGIN_SRC python :eval never
  import re
  if path is None:
    return None
  K8S_PATH_VARIABLE_PATTERN = re.compile("{(path)}$")
  VARIABLE_PATTERN = re.compile("{([^}]+)}")
  path_regex = K8S_PATH_VARIABLE_PATTERN.sub("(.*)", path).rstrip('/')
  path_regex = VARIABLE_PATTERN.sub("([^/]*)", path_regex).rstrip('/')
  if not path_regex.endswith(")") and not path_regex.endswith("?"): 
      path_regex += "([^/]*)"
  if path_regex.endswith("proxy"): 
      path_regex += "/?$"
  else:
      path_regex += "$"
  return path_regex
#+END_SRC

#+NAME: regex_from_path.sql
#+BEGIN_SRC sql-mode :noweb yes :tangle ../apps/hasura/migrations/145_function_regex_from_path.up.sql
  set role dba;
  CREATE OR REPLACE FUNCTION regex_from_path(path text)
  RETURNS text AS $$
  <<regex_from_path.py>>
  $$ LANGUAGE plpython3u ;
  reset role;
#+END_SRC

*** api_operations view
    This grabs the 'paths' section of our swagger.json, where each path contains operation Id, tags, schemes, etc.
#+NAME: api_operations view
#+BEGIN_SRC sql-mode :eval never-export :tangle ../apps/hasura/migrations/150_view_api_operations.up.sql
  CREATE OR REPLACE VIEW "public"."api_operations" AS 
    SELECT raw_swaggers.id AS raw_swagger_id,
           paths.key AS path,
           regex_from_path(paths.key) as regex,
           d.key AS method,
           (d.value ->> 'operationId'::text) AS operation_id,
           ((d.value -> 'x-kubernetes-group-version-kind'::text) ->> 'group'::text) AS k8s_group,
           ((d.value -> 'x-kubernetes-group-version-kind'::text) ->> 'version'::text) AS k8s_version,
           ((d.value -> 'x-kubernetes-group-version-kind'::text) ->> 'kind'::text) AS k8s_kind,
           (d.value ->> 'description'::text) AS description,
           (d.value ->> 'x-kubernetes-action'::text) AS x_kubernetes_action,
           (d.value -> 'consumes'::text) AS consumes,
           (d.value -> 'responses'::text) AS responses,
           (d.value -> 'parameters'::text) AS parameters,
           (lower((d.value ->> 'description'::text)) ~~ '%deprecated%'::text) AS deprecated,
           split_part((cat_tag.value ->> 0), '_'::text, 1) AS category,
           string_agg(btrim((jsonstring.value)::text, '"'::text), ', '::text) AS tags,
           string_agg(btrim((schemestring.value)::text, '"'::text), ', '::text) AS schemes
      FROM raw_swaggers
      , jsonb_each((raw_swaggers.data -> 'paths'::text)) paths(key, value)
      , jsonb_each(paths.value) d(key, value)
      , jsonb_array_elements((d.value -> 'tags'::text)) cat_tag(value)
      , jsonb_array_elements((d.value -> 'tags'::text)) jsonstring(value)
      , jsonb_array_elements((d.value -> 'schemes'::text)) schemestring(value)
     GROUP BY raw_swaggers.id, paths.key, d.key, d.value, cat_tag.value
     ORDER BY paths.key;
#+END_SRC

#+RESULTS: api_operations view
#+begin_src sql-mode
CREATE VIEW
#+end_src

#+NAME: track api_operations
#+BEGIN_SRC yaml :tangle ../apps/hasura/migrations/150_view_api_operations.up.yaml
- type: track_table
  args:
    schema: public
    name: api_operations
#+END_SRC


#+NAME: possible indexes
#+BEGIN_SRC sql-mode :eval never
create index api_operations_id on api_operations(id);
create index api_operations_method on api_operations(method);
create index api_operations_regexp on api_operations(regexp);
#+END_SRC

** api_operations_parameters view
Using our api_operations view, look into the parameters field in each one.     
#+NAME: api_operations_parameters view
#+BEGIN_SRC sql-mode :eval no-export :tangle ../apps/hasura/migrations/160_view_api_operations_parameters.up.sql
  CREATE OR REPLACE VIEW "public"."api_operations_parameters" AS 
    SELECT (param.entry ->> 'name'::text) AS name,
           (param.entry ->> 'in'::text) AS "in",
           -- for resource:
           -- if param is body in body, take its $ref from its schema
           -- otherwise, take its type
           replace(
             CASE
             WHEN ((param.entry ->> 'in'::text) = 'body'::text) 
              AND ((param.entry -> 'schema'::text) is not null)
               THEN ((param.entry -> 'schema'::text) ->> '$ref'::text)
             ELSE (param.entry ->> 'type'::text)
             END, '#/definitions/','') AS resource,
           (param.entry ->> 'description'::text) AS description,
           CASE
           WHEN ((param.entry ->> 'required'::text) = 'true') THEN true
           ELSE false
            END AS required,
           CASE
           WHEN ((param.entry ->> 'uniqueItems'::text) = 'true') THEN true
           ELSE false
           END AS unique_items,
           api_operations.raw_swagger_id,
           param.entry as entry,
           api_operations.operation_id
      FROM api_operations
           , jsonb_array_elements(api_operations.parameters) WITH ORDINALITY param(entry, index)
            WHERE api_operations.parameters IS NOT NULL;
#+END_SRC

#+RESULTS: api_operations_parameters view
#+begin_src sql-mode
CREATE VIEW
#+end_src

#+NAME: track api_operations_parameters
#+BEGIN_SRC yaml :eval no-export :tangle ../apps/hasura/migrations/160_view_api_operations_parameters.up.yaml
- type: track_table
  args:
    schema: public
    name: api_operations_parameters
#+END_SRC

** api_operations_responses view
   Similar to parameters, within each of the paths of the swagger.json, there is a responses field.  We are listing the values within this field.
   
#+NAME: Responses View
#+BEGIN_SRC sql-mode :eval no-export :tangle ../apps/hasura/migrations/180_view_api_operations_responses.up.sql
  CREATE OR REPLACE VIEW "public"."api_operations_responses" AS 
    SELECT d.key AS code,
           (d.value ->> 'description'::text) AS description,
           replace(
             CASE
             WHEN (((d.value -> 'schema'::text) IS NOT NULL) AND (((d.value -> 'schema'::text) -> 'type'::text) IS NOT NULL))
               THEN ((d.value -> 'schema'::text) ->> 'type'::text)
             WHEN (((d.value -> 'schema'::text) IS NOT NULL) AND (((d.value -> 'schema'::text) -> '$ref'::text) IS NOT NULL))
               THEN ((d.value -> 'schema'::text) ->> '$ref'::text)
             ELSE NULL::text
             END, '#/definitions/','') AS resource,
             api_operations.operation_id,
             api_operations.raw_swagger_id
      FROM (api_operations
            JOIN LATERAL jsonb_each(api_operations.responses) d(key, value) ON (true))
     ORDER BY (uuid_generate_v1());
#+END_SRC

#+RESULTS: Responses View
#+begin_src sql-mode
CREATE VIEW
#+end_src

#+NAME: track api_operations_responses
#+BEGIN_SRC yaml :tangle ../apps/hasura/migrations/180_view_api_operations_responses.up.yaml
- type: track_table
  args:
    schema: public
    name: api_operations_responses
#+END_SRC

* Resource Views
** api_resources view
#+NAME: api_resources view
#+BEGIN_SRC sql-mode :eval never-export :tangle ../apps/hasura/migrations/190_view_api_resources.up.sql
  CREATE VIEW "public"."api_resources" AS 
   SELECT 
      raw_swaggers.id AS raw_swagger_id,
      d.key AS name,
      (d.value ->> 'type'::text) AS resource_type,
      (((d.value -> 'x-kubernetes-group-version-kind'::text) -> 0) ->> 'group'::text) AS k8s_group,
      (((d.value -> 'x-kubernetes-group-version-kind'::text) -> 0) ->> 'version'::text) AS k8s_version,
      (((d.value -> 'x-kubernetes-group-version-kind'::text) -> 0) ->> 'kind'::text) AS k8s_kind,
      string_agg(btrim((reqstring.value)::text, '"'::text), ', '::text) AS required_params,
      (d.value ->> 'required'::text) as required_params_text,
      (d.value -> 'properties'::text) AS properties,
      d.value
     FROM raw_swaggers
       , jsonb_each((raw_swaggers.data -> 'definitions'::text)) d(key, value)
       , jsonb_array_elements((d.value -> 'required'::text)) reqstring(value)
     GROUP BY raw_swaggers.id, d.key, d.value;

#+END_SRC

#+RESULTS: api_resources view
#+begin_src sql-mode
ERROR:  relation "raw_swaggers" does not exist
LINE 13:    FROM raw_swaggers
                 ^
#+end_src

#+NAME: track api_resources
#+BEGIN_SRC yaml :tangle ../apps/hasura/migrations/190_view_api_resources.up.yaml
- type: track_table
  args:
    schema: public
    name: api_resources
#+END_SRC

** api_resources_fields view
#+NAME: Older Properties View
#+BEGIN_SRC sql-mode :eval never-export :notangle ../apps/hasura/migrations/200_view_api_resources_fields.up.sql
  -- DROP VIEW api_resources_properties;
  -- DROP MATERIALIZED VIEW api_resources_properties;
  CREATE VIEW "public"."api_resources_fields" AS 
    SELECT api_resources.id AS type_id,
           d.key AS property,
           CASE
           WHEN ((d.value ->> 'type'::text) IS NULL) THEN 'subtype'::text
           ELSE (d.value ->> 'type'::text)
             END AS param_type,
           replace(
             CASE
             WHEN ((d.value ->> 'type'::text) = 'string'::text) THEN 'string'::text
             WHEN ((d.value ->> 'type'::text) IS NULL) THEN (d.value ->> '$ref'::text)
             WHEN ((d.value ->> 'type'::text) = 'array'::text)
              AND ((d.value -> 'items'::text) ->> 'type'::text) IS NULL
               THEN ((d.value -> 'items'::text) ->> '$ref'::text)
             WHEN ((d.value ->> 'type'::text) = 'array'::text)
              AND ((d.value -> 'items'::text) ->> '$ref'::text) IS NULL
               THEN ((d.value -> 'items'::text) ->> 'type'::text)
             ELSE 'integer'::text
             END, '#/definitions/','') AS param_kind,
           (d.value ->> 'description'::text) AS description,
           (d.value ->> 'format'::text) AS format,
           (d.value ->> 'x-kubernetes-patch-merge-key'::text) AS merge_key,
           (d.value ->> 'x-kubernetes-patch-strategy'::text) AS patch_strategy,
           -- CASE
           --   WHEN d.key is null THEN false
           --   WHEN (api_resources.required_params ? d.key) THEN true
           --   ELSE false
           --     END
           --   AS required,
           -- with param type also containing array, we don't need array as a boolean
           -- CASE
           -- WHEN ((d.value ->> 'type'::text) = 'array'::text) THEN true
           -- ELSE false
           --  END AS "array"
           d.value
      FROM (api_resources
            JOIN LATERAL jsonb_each(api_resources.properties) d(key, value) ON (true))
     ORDER BY api_resources.id;
#+END_SRC

#+NAME: api_resources_fields view
#+BEGIN_SRC sql-mode :eval never-export :tangle ../apps/hasura/migrations/200_view_api_resources_fields.up.sql
  CREATE VIEW "public"."api_resources_fields" AS 
    SELECT api_resources.name as api_resource_name,
           api_resources.raw_swagger_id,
           d.key AS resource_field,
           CASE
           WHEN ((d.value ->> 'type'::text) IS NULL) THEN 'subtype'::text
           ELSE (d.value ->> 'type'::text)
             END AS param_type,
           replace(
             CASE
             WHEN ((d.value ->> 'type'::text) = 'string'::text) THEN 'string'::text
             WHEN ((d.value ->> 'type'::text) IS NULL) THEN (d.value ->> '$ref'::text)
             WHEN ((d.value ->> 'type'::text) = 'array'::text)
              AND ((d.value -> 'items'::text) ->> 'type'::text) IS NULL
               THEN ((d.value -> 'items'::text) ->> '$ref'::text)
             WHEN ((d.value ->> 'type'::text) = 'array'::text)
              AND ((d.value -> 'items'::text) ->> '$ref'::text) IS NULL
               THEN ((d.value -> 'items'::text) ->> 'type'::text)
             ELSE 'integer'::text
             END, '#/definitions/','') AS param_kind,
           (d.value ->> 'description'::text) AS description,
           (d.value ->> 'format'::text) AS format,
           (d.value ->> 'x-kubernetes-patch-merge-key'::text) AS merge_key,
           (d.value ->> 'x-kubernetes-patch-strategy'::text) AS patch_strategy,
           d.value
      FROM (api_resources
            JOIN LATERAL jsonb_each(api_resources.properties) d(key, value) ON (true));
#+END_SRC

#+NAME: track api_resources_fields
#+BEGIN_SRC yaml :tangle ../apps/hasura/migrations/200_view_api_resources_fields.up.yaml
- type: track_table
  args:
    schema: public
    name: api_resources_fields
#+END_SRC

* Over View
** TODO opname => op_param_name
** TODO opdescription => op_param_description
#+NAME: over view
#+BEGIN_SRC sql-mode :eval never-export :tangle ../apps/hasura/migrations/210_view_over.up.sql
  CREATE OR REPLACE VIEW "public"."over" AS
    SELECT
      op.name as opname,
      op.required,
      op.description as opdescription,
      o.operation_id,
      op.resource,
      r.name as resource_name,
      r.k8s_group,
      r.k8s_version,
      r.k8s_kind,
      rf.resource_field,
      rf.param_type,
      rf.param_kind,
      rf.description,
      rf.format,
      rf.merge_key,
      rf.patch_strategy
      FROM 
          api_operations_parameters op
          JOIN api_operations o ON (
            o.raw_swagger_id = op.raw_swagger_id
            AND
            o.operation_id = op.operation_id
          )
          LEFT JOIN api_resources r ON (
            op.resource = r.name
            AND
            op.raw_swagger_id = r.raw_swagger_id
            )
          LEFT JOIN api_resources_fields rf ON (
            rf.api_resource_name = r.name
            AND
            rf.raw_swagger_id = r.raw_swagger_id
          )
     ORDER BY op.name;
#+END_SRC

#+RESULTS: over view
#+begin_src sql-mode
CREATE VIEW
#+end_src

#+NAME: track over
#+BEGIN_SRC yaml :tangle ../apps/hasura/migrations/210_view_over.up.yaml
- type: track_table
  args:
    schema: public
    name: over
#+END_SRC

* IN-PROGRESS Remove interim 'operations with parameters' view
* NEXT Finish the Over View
* TODO Create Import for CSV view
  We have a file started here: [[file:test_gen.org][test_gen.org]] 
  that brings in the work devan and caleb did to pull all the tests used in a specific/commit version of k8s.
  If we can build a script for this, then we can have:
  - A test name
  - its description
  - its link to official k8s definition
  - a link to the lines of go code that define it.
  
    We can then use this as a cross refernece for any audit event that references a test.
* TODO Creating/Editing Views
* FOOTNOTES
# Local Variables:
# eval: (sql-connect "hasura" (concat "*SQL: postgres:data*"))
# End:
  
  

  

** Original Audit Events Table
*** columns
**** audit_id

 #+NAME: audit_id
 #+BEGIN_SRC sql-mode
     audit_id uuid NOT NULL,
 #+END_SRC

 This is a UUID!
 But there are multiple occurences in a single log file.

***** Examples
 #+BEGIN_SRC json
   auditID: "c0793350-e7fe-42ce-93e6-8436a0eb3b39",
 #+END_SRC
***** 285593 times each one occurs once
 #+BEGIN_SRC shell
 cat kube-apiserver-audit.log | jq .auditID | sort | uniq -c | grep -v '2 "' | wc -l
 #+END_SRC
***** 8141 times a single uuid shows up twice
 #+BEGIN_SRC shell
 cat kube-apiserver-audit.log | jq .auditID | sort | uniq -c | grep -v '1 "' | wc -l
 #+END_SRC
***** When a UUID shows up twice, the only diff is stage and stageTimestamp
 #+BEGIN_SRC shell
  cat kube-apiserver-audit.log | jq -c '. | select( .auditID | contains("ffe9adb2-6917-49ed-b823-72c4fe4355e0"))' | jq 
 #+END_SRC

   "stage": "ResponseStarted => ResponseComplete"
   "stageTimestamp": "2019-06-17T05:19:17.898138Z",

 #+BEGIN_SRC shell
 cat kube-apiserver-audit.log | jq .auditID | sort | uniq -c | grep -v '1 "' | wc -l
 #+END_SRC

**** testrun_id
 We need something to differentiate test run
 #+NAME: testrun_id
 #+BEGIN_SRC sql-mode
     testrun_id text,
 #+END_SRC
**** op_id
 #+NAME: op_id
 #+BEGIN_SRC sql-mode
     op_id text,
 #+END_SRC
**** stage
     "stage"
 #+NAME: stage
 #+BEGIN_SRC sql-mode
   stage text NOT NULL,
 #+END_SRC
**** level
 #+NAME: level
 #+BEGIN_SRC sql-mode
   level text NOT NULL,
 #+END_SRC

 level: "Request", "Metadata", "RequestResponse"

 I'm not sure here, but I feel like we should only be looking at RequestResponse... not all three.
 Huh, that was wrong.. the counts differ wildly:

***** 171724 Requests
 #+BEGIN_SRC shell
 cat kube-apiserver-audit.log | jq -c '. | select( .level | contains("Request"))' | jq -r .auditID | sort | uniq | wc -l
 #+END_SRC
***** 122010 Metadata
 #+BEGIN_SRC shell
 cat kube-apiserver-audit.log | jq -c '. | select( .level | contains("RequestResponse"))' | jq -r .auditID | sort | uniq | wc -l
 #+END_SRC

***** 26016 RequestResponse
 #+BEGIN_SRC shell
 cat kube-apiserver-audit.log | jq -c '. | select( .level | contains("RequestResponse"))' | jq -r .auditID | sort | uniq | wc -l
 #+END_SRC

**** verb
 #+NAME: verb
 #+BEGIN_SRC sql-mode
   verb text NOT NULL,
 #+END_SRC
 An http verb != endpoint verb:
 stage has quite a few values
 - create
 - delete
 - deletecollection,
 - get
 - list
 - patch
 - update
 - watch
**** request_uri
 #+NAME: request_uri
 #+BEGIN_SRC sql-mode
   request_uri text NOT NULL,
 #+END_SRC

 We'll need to use this to match against the OpenAPISpec to find the endpoint.

 request_uri: "/api/v1/namespaces/kube-system/pods/etcd-empty-dir-cleanup-bootstrap-e2e-master",
**** user_agent
 #+NAME: user_agent
 #+BEGIN_SRC sql-mode
   user_agent text,
 #+END_SRC
 For e2e.test we added support to append -- and the test name at that point it time:

 userAgent: "kubelet/v1.16.0 (linux/amd64) kubernetes/0e499be",

 It may make sense to split on '--' an store what follows as the testName.
**** test_name
 #+NAME: test_name
 #+BEGIN_SRC sql-mode
   test_name text,
 #+END_SRC

 This isn't a direct mapping, we create it if the userAgent contains '--' followed by the test name.
 For now we only see this with e2e.test.
**** request_ts
     "requestReceivedTimestamp"
 #+NAME: request_ts
 #+BEGIN_SRC sql-mode
   request_ts timestamp with time zone,
 #+END_SRC
**** stage_ts

 Noting that when we have a responseComplete, it's always paid with a responseStarted.
 The UUID and everything else is the same, other than the timestamp.
 I suspect this is only generated for requests that take a while.

 stage: "ResponseComplete", "ResponseStarted"
 #+NAME: stage_ts
 #+BEGIN_SRC sql-mode
   stage_ts timestamp with time zone,
 #+END_SRC
**** Kind / apiVersion                                               :unused:

 For every singe one the values are the same:
 kind: "Event"
 apiVersion: "audit.k8s.io/v1"

 #+NAME: kind
 #+BEGIN_SRC sql-mode
   kind text,
   "apiVersion" text,
 #+END_SRC
**** annotations                                                     :unused:

 This is a json blog... not sure how to handle yet
 https://blog.hasura.io/postgres-json-and-jsonb-type-support-on-graphql-41f586e47536/

 Unsure we need annotations for now as they may be good for understanding a
 specific test, the data doesn't aggregate well.

 #+BEGIN_SRC shell
 cat kube-apiserver-audit.log | jq -r .annotations | sort | uniq
 #+END_SRC

 A good number of them seem to be allow or deny + reason:

 #+BEGIN_SRC json
   "annotations": {
     "authorization.k8s.io/decision": "allow",
     "authorization.k8s.io/reason": ""
   }
 #+END_SRC

 #+BEGIN_SRC sql-mode
   annotations jsonb,
 #+END_SRC
**** sourceIPs                                                       :unused:
 #+BEGIN_SRC sql-mode
   "sourceIP" text,
 #+END_SRC

 Could likely identify pods in this way, but not useful at this time.
 sourceIPs: ["1.1.1.1"],
**** Unused Fields                                                   :unused:
 The id could probably be dropped in favor of UUID, if we only capture ResponseStarted.
 #+BEGIN_SRC sql-mode
   -- I'm unsure what this is
   -- This is to point back to the job that created these logs
   job_log_id integer NOT NULL
   -- should it be an iteger?
   -- maybe get rid of it completely?
   id integer NOT NULL,
 #+END_SRC

*** table

 #+BEGIN_SRC tmate
   cd ~/ii/apisnoop_v3
   python3 import_entries.py
 #+END_SRC

**** SQL VIEW for JSON BLOBS
 This has one column... event which is a jsonb.

 #+NAME: CREATE TABLE audit_events
 #+BEGIN_SRC sql-mode :noweb yes :notangle ../apps/hasura/migrations/230_table_audit_events.up.sql
   CREATE TABLE public.audit_events (
     <<audit_id>>
     <<testrun_id>>
     <<op_id>>
     <<stage>>
     <<level>>
     <<verb>>
     <<request_uri>>
     <<user_agent>>
     <<test_name>>
     <<requestObject.kind>>
     <<requestObject.apiVersion>>
     <<requestObject.metadata>>
     <<requestObject.spec>>
     <<requestObject.status>>
     <<responseObject.kind>>
     <<responseObject.apiVersion>>
     <<responseObject.metadata>>
     <<responseObject.spec>>
     <<responseObject.status>>
     <<request_ts>>
     <<stage_ts>>
     CONSTRAINT audit_id_stage PRIMARY KEY (audit_id, stage)
   );
   -- Indexes
   create index audit_events_op_id on audit_events(op_id);
   create index audit_events_testrun_id on audit_events(testrun_id);
   --  create index audit_events_stage on audit_events(stage);
   create index audit_events_user_agent on audit_events(user_agent);
   create index audit_events_test_name on audit_events(test_name);
   create index audit_events_verb on audit_events(verb);
   create index audit_events_request_uri on audit_events(request_uri);
 #+END_SRC

 #+RESULTS: CREATE TABLE audit_events
 #+begin_src sql-mode
 CREATE TABLE
 CREATE INDEX
 CREATE INDEX
 CREATE INDEX
 #+end_src

 #+NAME: track_table audit_events
 #+BEGIN_SRC sql-mode :noweb yes :notangle ../apps/hasura/migrations/230_track_audit_events.up.yaml
 - type: track_table
   args:
     schema: public
     name: audit_events
 #+END_SRC

 After creating the table, we have to go to the console:
 hasura.$USER.sharing.io
 http://localhost:8080/console/data/schema/public
 And click on [Track All] or [Track] for the table.

 I also tracked the following in network traffic, but have yet to execute them
 via a directy grahpql query.

 #+BEGIN_SRC shell :directory ~/apisnoop_v3
 hasura init --endpoint http://localhost:8080/v1/graphql
 export HASURA_GRAPHQL_ADMIN_SECRET=X
 # --admin-secret "X"
 #+END_SRC

 #+BEGIN_SRC sql-mode
   CREATE OR REPLACE VIEW "public"."events" AS 
    SELECT audit_events.auditID AS uuid,
       audit_events.level AS level,
       audit_events.verb AS verb,
       audit_events.requestURI AS uri,
       audit_events.userAgent AS useragent,
       audit_events.testName AS testName,
       -- ((audit_events.event -> 'requestObject'::text) ->> 'apiVersion'::text) AS apiversion,
       ((audit_events.event -> 'requestObject'::text) ->> 'kind'::text) AS kind,
       ((audit_events.event -> 'requestObject'::text) ->> 'metadata'::text) AS metadata,
       ((audit_events.event -> 'requestObject'::text) ->> 'spec'::text) AS spec,
       ((audit_events.event -> 'requestObject'::text) ->> 'status'::text) AS requeststatus,
       ((audit_events.event -> 'responseObject'::text) ->> 'status'::text) AS status,
       ((audit_events.event -> 'responseObject'::text) ->> 'kind'::text) AS responsekind,
       ((audit_events.event -> 'responseObject'::text) ->> 'metadata'::text) AS responsemetadata,
       ((audit_events.event -> 'responseObject'::text) ->> 'spec'::text) AS responsespec
      FROM audit_events;
 #+END_SRC

 #+RESULTS:
 #+begin_src sql-mode
 ERROR:  column audit_events.event does not exist
 LINE 2:  SELECT (audit_events.event -> 'auditID'::text) AS uuid,
                  ^
 #+end_src

*** sequence

 #+BEGIN_SRC sql-mode
 CREATE SEQUENCE public.audit_events_id_seq
     AS integer
     START WITH 1
     INCREMENT BY 1
     NO MINVALUE
     NO MAXVALUE
     CACHE 1;
 ALTER SEQUENCE public.audit_events_id_seq OWNED BY public.audit_events.id;
 #+END_SRC

 #+RESULTS:
 : CREATE SEQUENCE
 : ALTER SEQUENCE
*** constraints

 #+BEGIN_SRC sql-mode
 ALTER TABLE ONLY public.audit_events
     ADD CONSTRAINT "audit_events_auditID_key" UNIQUE ("auditID");
 ALTER TABLE ONLY public.audit_events
     ADD CONSTRAINT audit_events_pkey PRIMARY KEY (id);
 #+END_SRC

 #+RESULTS:
 : ALTER TABLE
 : ALTER TABLE
